{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a837d78-5dff-48d9-9753-37e382d9f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core/')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_support as fls\n",
    "import flg_runner\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import ISLP\n",
    "import ISLP.models\n",
    "import subprocess\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e78e80-b19e-4851-8c03-78e42d5f091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "fls.download_kaggle_dataset('jeroencottaar/byu-many-models-abbreviated/', fls.result_dir + '/many_abbr_res/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05531fec-39cb-4c86-8c24-8566705f459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/flagellar/results//many_abbr_res\\Baseline_0_1542ec49_504 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1_1542ec49_556 _a.pickle\n"
     ]
    }
   ],
   "source": [
    "# Read results from vast.ai\n",
    "files = glob.glob(fls.result_dir + '/many_abbr_res/' + '*.pickle')\n",
    "dicts = []\n",
    "dicts_kaggle_comp = []\n",
    "for f in files:    \n",
    "    print(f)\n",
    "    data = fls.dill_load(f)    \n",
    "    d = data.modifier_values\n",
    "    d['label'] = data.label\n",
    "    d['git_commit_id'] = data.git_commit_id\n",
    "    d['use_missing_value'] = data.use_missing_value\n",
    "    d['cv_score'] = fls.score_competition_metric(data.inferred_test_data, data.test_data)\n",
    "\n",
    "    d_kaggle_comp = dict()\n",
    "    d_kaggle_comp['label'] = data.label\n",
    "    d_kaggle_comp['git_commit_id'] = d['git_commit_id']\n",
    "    d_kaggle_comp['use_missing_value'] = d['use_missing_value']\n",
    "    d_kaggle_comp['seed'] = d['seed']   \n",
    "    d_kaggle_comp['cv_score'] = d['cv_score']\n",
    "    d_kaggle_comp['k_score'] = np.nan\n",
    "\n",
    "    dicts_kaggle_comp.append(d_kaggle_comp)\n",
    "\n",
    "    # First set\n",
    "    #if not (d['seed']<26 or d['use_missing_value']): print('skip'); continue\n",
    "\n",
    "    # New\n",
    "    #if not (d['seed']>=26 or d['use_missing_value']): print('skip'); continue\n",
    "    #if d['label']=='Test ensemble': continue\n",
    "    \n",
    "    for partial in fls.DataSelector().datasets:\n",
    "        data_selector = fls.DataSelector()\n",
    "        data_selector.datasets = [partial]\n",
    "        d['cv_score_' + partial] = fls.score_competition_metric(data_selector.select(data.inferred_test_data), data_selector.select(data.test_data))\n",
    "    d['k_score']= np.nan\n",
    "\n",
    "    dicts.append(d)    \n",
    "p = pd.DataFrame(dicts)\n",
    "p.sort_values(['seed', 'git_commit_id'], inplace=True);\n",
    "\n",
    "p_kaggle_comp = pd.DataFrame(dicts_kaggle_comp)\n",
    "p_kaggle_comp.sort_values(['seed', 'git_commit_id'], inplace=True);\n",
    "\n",
    "# First set\n",
    "# p = p[np.logical_or(p['seed']<26, p['use_missing_value'])]\n",
    "\n",
    "# New\n",
    "#p = p[np.logical_or(p['seed']>=26, p['use_missing_value'])]\n",
    "\n",
    "p = p.reset_index()\n",
    "p_kaggle_comp = p_kaggle_comp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe01969-295e-4908-9b7a-b53552e56272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kaggle results\n",
    "p_kaggle_results = pd.read_csv(fls.code_dir + '../kaggle_results.csv').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c769be2d-6ceb-4ef6-8daf-cf65e5974907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add competition results\n",
    "csv = subprocess.run('kaggle competitions submissions -q -csv -c byu-locating-bacterial-flagellar-motors-2025', encoding = 'utf-8', shell=True, stdout=subprocess.PIPE)\n",
    "lines = csv.stdout.split('\\n')[1:]\n",
    "data_str = \"\\n\".join(lines)\n",
    "p_submissions = pd.read_fwf(io.StringIO(data_str), skiprows=[1])\n",
    "for i_i in range(len(p_kaggle_results)):\n",
    "    mv_str = 'Ma' if p_kaggle_results.loc[i_i, 'use_missing_value'] else ''\n",
    "    name_str = p_kaggle_results.loc[i_i, 'label'] + '_' + str(p_kaggle_results.loc[i_i, 'seed']) + mv_str + '_' + p_kaggle_results.loc[i_i, 'git_commit_id'][:8]\n",
    "    for i_k in range(len(p_submissions)):\n",
    "        if name_str == p_submissions.loc[i_k, 'description']:\n",
    "            score = p_submissions.loc[i_k, 'publicScore']\n",
    "            if not np.isnan(score):\n",
    "                if np.isnan(p_kaggle_results.loc[i_i, 'k_score']):\n",
    "                    p_kaggle_results.loc[i_i, 'k_score'] = score\n",
    "                    print(f'Added score of {score:1.3} for {name_str}')\n",
    "                else:\n",
    "                    if not score == p_kaggle_results.loc[i_i, 'k_score']:\n",
    "                        raise Exception(f'Mismatch for {name_str}: {score:1.3} vs {p_kaggle_results.loc[i_i, \"k_score\"]:1.3}')\n",
    "            else:\n",
    "                print('NaN score found for ', name_str)            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aac4bfd-038a-466b-a8cc-8992c05900b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(p_kaggle_results)\n",
    "for i_k in range(len(p_kaggle_results)):\n",
    "    for i_i in range(len(p_kaggle_comp)):\n",
    "        if p_kaggle_results['seed'][i_k] == p_kaggle_comp['seed'][i_i] and p_kaggle_results['git_commit_id'][i_k] == p_kaggle_comp['git_commit_id'][i_i] and  p_kaggle_results['use_missing_value'][i_k] == p_kaggle_comp['use_missing_value'][i_i] and  p_kaggle_results['label'][i_k] == p_kaggle_comp['label'][i_i]:\n",
    "            p_kaggle_comp.loc[i_i,'k_score'] = p_kaggle_results['k_score'][i_k]\n",
    "for i_k in range(len(p_kaggle_results)):\n",
    "    for i_i in range(len(p)):\n",
    "        if p_kaggle_results['seed'][i_k] == p['seed'][i_i] and p_kaggle_results['git_commit_id'][i_k] == p['git_commit_id'][i_i] and  p_kaggle_results['use_missing_value'][i_k] == p['use_missing_value'][i_i] and  p_kaggle_results['label'][i_k] == p['label'][i_i]:\n",
    "            p.loc[i_i,'k_score'] = p_kaggle_results['k_score'][i_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5029a62e-5188-469a-a11d-cb7b935976ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to Kaggle results file\n",
    "p_kaggle_cache = copy.deepcopy(p_kaggle_comp[['label', 'git_commit_id', 'use_missing_value', 'seed', 'cv_score', 'k_score']])\n",
    "p_kaggle_cache.to_csv(fls.code_dir + '../kaggle_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d1564af-5249-4b79-8279-6e5ec608c0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_ensemble</th>\n",
       "      <th>scale_percentile_value</th>\n",
       "      <th>img_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>model_name</th>\n",
       "      <th>use_pretrained_weights</th>\n",
       "      <th>box_size</th>\n",
       "      <th>trust</th>\n",
       "      <th>...</th>\n",
       "      <th>ycw</th>\n",
       "      <th>label</th>\n",
       "      <th>git_commit_id</th>\n",
       "      <th>use_missing_value</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>cv_score_tom</th>\n",
       "      <th>cv_score_ycw</th>\n",
       "      <th>cv_score_aba</th>\n",
       "      <th>cv_score_mba</th>\n",
       "      <th>k_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.547847</td>\n",
       "      <td>768</td>\n",
       "      <td>29</td>\n",
       "      <td>yolov8m</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>1542ec4929a5056c13c3b9b3aa0985df903485b6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.901163</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.194585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.047286</td>\n",
       "      <td>832</td>\n",
       "      <td>40</td>\n",
       "      <td>yolov8m</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>1542ec4929a5056c13c3b9b3aa0985df903485b6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.556769</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.726496</td>\n",
       "      <td>0.218855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  seed  n_ensemble  scale_percentile_value  img_size  n_epochs  \\\n",
       "0      0     0           4                3.547847       768        29   \n",
       "1      1     1           4                3.047286       832        40   \n",
       "\n",
       "  model_name  use_pretrained_weights  box_size  trust  ...    ycw     label  \\\n",
       "0    yolov8m                   False        20      3  ...  False  Baseline   \n",
       "1    yolov8m                    True        21      3  ...   True  Baseline   \n",
       "\n",
       "                              git_commit_id  use_missing_value  cv_score  \\\n",
       "0  1542ec4929a5056c13c3b9b3aa0985df903485b6              False  0.504386   \n",
       "1  1542ec4929a5056c13c3b9b3aa0985df903485b6              False  0.556769   \n",
       "\n",
       "   cv_score_tom  cv_score_ycw  cv_score_aba  cv_score_mba  k_score  \n",
       "0      0.901163      0.744681      0.575221      0.194585      NaN  \n",
       "1      0.900901      0.833333      0.726496      0.218855      NaN  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.to_csv(fls.code_dir + '../results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011731dc-ea00-4033-9115-7246df73beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = copy.deepcopy(p).columns.to_list()[2:-9]\n",
    "main = np.logical_not(p['use_missing_value'])\n",
    "#main = p['tom']\n",
    "for x_val in ['cv_score', 'cv_score_tom', 'cv_score_ycw', 'cv_score_aba', 'cv_score_mba']:\n",
    "    plt.figure()\n",
    "    plt.scatter(p[x_val][main], p['k_score'][main])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(x_val)\n",
    "    plt.ylabel('Kaggle score')\n",
    "ncols = 4\n",
    "nrows = len(to_plot)//ncols+2\n",
    "for y_val in p.columns[-6:][[5,0,1,2,3,4]].to_list():\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14,14/ncols*nrows))\n",
    "    plt.suptitle(y_val)\n",
    "    for idx,d in enumerate(to_plot):\n",
    "        row = idx // ncols\n",
    "        col = idx % ncols\n",
    "        ax = axes[row, col]\n",
    "        plt.sca(ax)        \n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.grid(True)\n",
    "        plt.scatter(p[d][main], p[y_val][main])\n",
    "        plt.scatter(p[d][np.logical_not(main)], p[y_val][np.logical_not(main)])\n",
    "       \n",
    "        # fit\n",
    "        pp = copy.deepcopy(p)\n",
    "        if not pd.api.types.is_numeric_dtype(pp[d]) or pd.api.types.is_bool_dtype(pp[d]):\n",
    "            pp[d] = pp[d].astype('category').cat.codes\n",
    "        X = pp[[d]][main]\n",
    "        X['intercept'] = 1.\n",
    "        y = p[y_val][main]\n",
    "        to_keep = np.logical_not(np.isnan(y))\n",
    "        X = X[to_keep]; y=y[to_keep];\n",
    "        model = sm.OLS(y,X)\n",
    "        results=model.fit()\n",
    "        p_val = results.pvalues[d]\n",
    "        plt.title(f'{d} (p={p_val:.3})')\n",
    "        \n",
    "        # if d == 'mask_sizes0':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][0] for m in model_list]\n",
    "        # elif d == 'mask_sizes1':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][1] for m in model_list]\n",
    "        # elif d == 'mask_sizes2':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][2] for m in model_list]\n",
    "        # else:\n",
    "        #     x_vals = [getattr(m, d)[model.particles_to_do[0]] for m in model_list]\n",
    "        # if len(np.unique(x_vals))<8:\n",
    "        #     #pass\n",
    "        #     violin_plot(x_vals,score_vals)\n",
    "        # else:\n",
    "        #     plt.scatter(x_vals, score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1933d6c-d395-401e-8baa-11df85e0fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "isSourceIdPinned": false,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 6925042,
     "sourceId": 11204341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6949538,
     "sourceId": 11204343,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211097053,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 229283084,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
