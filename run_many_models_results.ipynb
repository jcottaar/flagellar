{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c6ac2c-05db-48ab-98ff-ab2eb7e18cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core/')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_support as fls\n",
    "import flg_runner\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import ISLP\n",
    "import ISLP.models\n",
    "import subprocess\n",
    "import io\n",
    "import shutil\n",
    "import flg_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e78e80-b19e-4851-8c03-78e42d5f091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:/flagellar/results//many_abbr_res/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dir = fls.result_dir + '/many_abbr_res/'\n",
    "temp_dir = fls.temp_dir + '/temptemp/'\n",
    "fls.remove_and_make_dir(res_dir)\n",
    "fls.remove_and_make_dir(temp_dir)\n",
    "fls.download_kaggle_dataset('jeroencottaar/byu-many-models-abbreviated/', temp_dir)\n",
    "shutil.copytree(temp_dir, res_dir, dirs_exist_ok=True)\n",
    "fls.download_kaggle_dataset('jeroencottaar/byu-many-models-abbreviated-2/', temp_dir)\n",
    "shutil.copytree(temp_dir, res_dir, dirs_exist_ok=True)\n",
    "fls.download_kaggle_dataset('jeroencottaar/byu-many-models-abbreviated-3/', temp_dir)\n",
    "shutil.copytree(temp_dir, res_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9dda0c-1280-4eeb-8bd6-1d0b0353dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/flagellar/results//many_abbr_res\\Baseline_0_ca1865f2_940 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1000_ca1865f2_911 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1001_ca1865f2_893 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1002_ca1865f2_892 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1003_ca1865f2_883 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1004_ca1865f2_878 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1005_ca1865f2_876 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1006_ca1865f2_897 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1007_ca1865f2_882 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1008_ca1865f2_884 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1009_ca1865f2_879 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1010_ca1865f2_875 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1011_ca1865f2_891 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1012_ca1865f2_897 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1013_ca1865f2_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1014_ca1865f2_901 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1015_ca1865f2_906 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1016_ca1865f2_886 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1017_ca1865f2_905 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1018_ca1865f2_907 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1019_ca1865f2_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1020_ca1865f2_930 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1021_ca1865f2_898 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1022_ca1865f2_897 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1023_ca1865f2_852 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1024_ca1865f2_916 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1025_ca1865f2_920 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1026_ca1865f2_803 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_10_ca1865f2_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_11_ca1865f2_878 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_12_ca1865f2_931 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_13_ca1865f2_907 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_14_ca1865f2_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_15_ca1865f2_906 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1_ca1865f2_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2000_ca1865f2_910 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2001_ca1865f2_88 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2002_ca1865f2_91 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2003_ca1865f2_906 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2004_ca1865f2_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2005_ca1865f2_910 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2006_ca1865f2_916 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2007_ca1865f2_896 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2008_ca1865f2_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2009_ca1865f2_921 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2010_ca1865f2_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2011_ca1865f2_920 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2012_ca1865f2_93 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2013_ca1865f2_882 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2_ca1865f2_915 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_3_ca1865f2_887 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_4_ca1865f2_936 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_5_ca1865f2_931 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_6_ca1865f2_911 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_7_ca1865f2_871 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_8_ca1865f2_92 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_9_ca1865f2_876 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1027_0ac15770_888 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1028_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1029_0ac15770_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1030_0ac15770_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1031_0ac15770_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1032_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1033_0ac15770_900 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1034_0ac15770_916 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1035_0ac15770_911 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1036_0ac15770_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1037_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1038_0ac15770_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1039_0ac15770_922 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1040_0ac15770_912 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1041_0ac15770_941 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1042_0ac15770_945 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1043_0ac15770_863 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1044_0ac15770_815 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1045_0ac15770_93 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1046_0ac15770_840 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_1047_0ac15770_868 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_16_0ac15770_936 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_17_0ac15770_921 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_18_0ac15770_915 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_19_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2020_0ac15770_930 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2021_0ac15770_900 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2022_0ac15770_886 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2023_0ac15770_896 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2024_0ac15770_893 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2025_0ac15770_932 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2026_0ac15770_848 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2027_0ac15770_837 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2028_0ac15770_94 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2029_0ac15770_89 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2030_0ac15770_906 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2031_0ac15770_930 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2032_0ac15770_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2033_0ac15770_891 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2034_0ac15770_903 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2035_0ac15770_868 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_2036_0ac15770_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_20_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_21_0ac15770_900 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_22_0ac15770_916 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_23_0ac15770_930 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_24_0ac15770_916 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_25_0ac15770_850 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_26_0ac15770_930 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_27_0ac15770_858 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_28_0ac15770_906 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_29_0ac15770_867 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_30_0ac15770_874 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_31_0ac15770_935 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_32_0ac15770_902 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_33_0ac15770_936 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_34_0ac15770_845 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_35_0ac15770_910 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_36_0ac15770_875 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_37_0ac15770_925 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_38_0ac15770_891 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_39_0ac15770_926 _a.pickle\n",
      "d:/flagellar/results//many_abbr_res\\Baseline_40_0ac15770_881 _a.pickle\n"
     ]
    }
   ],
   "source": [
    "# Read results from vast.ai\n",
    "files = glob.glob(res_dir + 'Baseline*ca1*.pickle') + glob.glob(res_dir + 'Baseline*0ac1*.pickle')\n",
    "data_list = []\n",
    "missing_values = dict()\n",
    "modifier_values_list = []\n",
    "for f in files:    \n",
    "    if 'L_' in f:\n",
    "        continue\n",
    "    print(f)\n",
    "    data_list.append(fls.dill_load(f)    )\n",
    "    #if not (data_list[-1].modifier_values['seed']>=5): print('skip'); continue\n",
    "    data_list[-1].modifier_values['local_mode'] = ('L_' in f)\n",
    "    modifier_values_list.append(data_list[-1].modifier_values)\n",
    "    #print(modifier_values_list[-1])\n",
    "    for key,value in data_list[-1].modifier_dict.items():\n",
    "        missing_values[key] = value.missing_value\n",
    "    if not data_list[-1].exception == 0:\n",
    "        print(data_list[-1].exception)\n",
    "        del data_list[-1]\n",
    "        del modifier_values_list[-1]\n",
    "    #print(modifier_values_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c30fc7-f140-49f0-a3dc-ad0e0f43eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5664739884393064, 0.98, 0.8551483420593369)\n",
      "1000 (0.5335276967930029, 0.915, 0.800524934383202)\n",
      "1001 (0.5043731778425656, 0.865, 0.7567804024496938)\n",
      "1002 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1003 (0.5086705202312138, 0.88, 0.7678883071553229)\n",
      "1004 (0.4812680115273775, 0.835, 0.7279860505666957)\n",
      "1005 (0.501466275659824, 0.855, 0.7493426818580193)\n",
      "1006 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1007 (0.4827586206896552, 0.84, 0.7317073170731707)\n",
      "1008 (0.501466275659824, 0.855, 0.7493426818580193)\n",
      "1009 (0.5043731778425656, 0.865, 0.7567804024496938)\n",
      "1010 (0.501466275659824, 0.855, 0.7493426818580193)\n",
      "1011 (0.5072463768115942, 0.875, 0.7641921397379913)\n",
      "1012 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1013 (0.5575221238938053, 0.945, 0.8296751536435469)\n",
      "1014 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1015 (0.530791788856305, 0.905, 0.7931638913234005)\n",
      "1016 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1017 (0.5114942528735632, 0.89, 0.7752613240418118)\n",
      "1018 (0.5348837209302325, 0.92, 0.8041958041958042)\n",
      "1019 (0.5402298850574713, 0.94, 0.818815331010453)\n",
      "1020 (0.5415472779369628, 0.945, 0.8224543080939948)\n",
      "1021 (0.528023598820059, 0.895, 0.7857769973661106)\n",
      "1022 (0.5100864553314121, 0.885, 0.7715780296425457)\n",
      "1023 (0.4797687861271676, 0.83, 0.7242582897033158)\n",
      "1024 (0.5362318840579711, 0.925, 0.8078602620087336)\n",
      "1025 (0.5402298850574713, 0.94, 0.818815331010453)\n",
      "1026 (0.40476190476190477, 0.68, 0.5985915492957746)\n",
      "10 (0.5402298850574713, 0.94, 0.818815331010453)\n",
      "11 (0.49852507374631266, 0.845, 0.7418788410886743)\n",
      "12 (0.5562130177514792, 0.94, 0.8260105448154658)\n",
      "13 (0.5321637426900585, 0.91, 0.7968476357267951)\n",
      "14 (0.5415472779369628, 0.945, 0.8224543080939948)\n",
      "15 (0.530791788856305, 0.905, 0.7931638913234005)\n",
      "1 (0.5389048991354467, 0.935, 0.8151700087183958)\n",
      "2000 (0.5142857142857142, 0.9, 0.782608695652174)\n",
      "2001 (0.4857142857142857, 0.85, 0.7391304347826086)\n",
      "2002 (0.5142857142857142, 0.9, 0.782608695652174)\n",
      "2003 (0.530791788856305, 0.905, 0.7931638913234005)\n",
      "2004 (0.5402298850574713, 0.94, 0.818815331010453)\n"
     ]
    }
   ],
   "source": [
    "import flg_model\n",
    "dicts = []\n",
    "dicts_kaggle_comp = []\n",
    "for data, modifier_values in zip(data_list, modifier_values_list):\n",
    "    d = copy.deepcopy(missing_values)\n",
    "    #print(modifier_values)\n",
    "    for key,value in modifier_values.items():\n",
    "        d[key] = value\n",
    "        #print(d)\n",
    "\n",
    "    if d['n_ensemble']==4 and d['concentration']==2:\n",
    "        raise Exception('obsolete')\n",
    "        d['concentration']=1\n",
    "        data.inferred_test_data = fls.dill_load(fls.result_dir + '/reinfer/' + str(d['seed']) + '.pickle')\n",
    "        print('reloaded ', d['seed'])\n",
    "    d['lr0_times_nepochs'] = d['lr0']*d['n_epochs']\n",
    "    #print(d)\n",
    "    #raise 'stop'\n",
    "    # if predict_all:\n",
    "    #     data.trained_model.data_after_step2 = data.inferred_test_data     \n",
    "    #     data.trained_model.step3Output.threshold=-1\n",
    "    #     data.inferred_test_data = data.trained_model.infer(data.test_data)\n",
    "        \n",
    "    d['label'] = data.label\n",
    "    d['git_commit_id'] = data.git_commit_id\n",
    "    d['use_missing_value'] = data.use_missing_value\n",
    "\n",
    "    # Reinfer\n",
    "    \n",
    "\n",
    "    # false_conf = []\n",
    "    # true_conf = []\n",
    "    # for dd,r in zip(data.inferred_test_data, data.test_data):\n",
    "    #     if len(r.labels)>0:\n",
    "    #         true_conf.append(dd.labels['confidence'][0])\n",
    "    #     else:\n",
    "    #         false_conf.append(dd.labels['confidence'][0])\n",
    "    # plt.figure()\n",
    "    # plt.hist(true_conf,alpha=0.5)\n",
    "    # plt.hist(false_conf,alpha=0.5)\n",
    "\n",
    "    if data.inferred_test_data==0:\n",
    "        d['cv_score'] = np.nan\n",
    "    else:\n",
    "        # model = data.untrained_model\n",
    "        # model.state = 1\n",
    "        # model.data_after_step2 = data.inferred_test_data\n",
    "        # import io\n",
    "        # import contextlib\n",
    "        # model.step2Motors = flg_model.FindClustersMultiZ()\n",
    "        # model.step2Motors.z_range = 4\n",
    "        # model.run_in_parallel = False\n",
    "        # with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "        #     data.inferred_test_data = model.infer(data.test_data) \n",
    "        dat, test_data = flg_diagnostics.expand_and_reinfer(data.inferred_test_data, data.test_data, data.untrained_model.step3Output.select_motors, 0.7)\n",
    "        metric = fls.score_competition_metric(dat, test_data)\n",
    "        print(d['seed'], metric)\n",
    "        d['cv_score'] = metric[2]\n",
    "    #print(d['cv_score'])\n",
    "\n",
    "    d_kaggle_comp = dict()\n",
    "    d_kaggle_comp['label'] = data.label\n",
    "    d_kaggle_comp['git_commit_id'] = d['git_commit_id']\n",
    "    d_kaggle_comp['use_missing_value'] = d['use_missing_value']\n",
    "    d_kaggle_comp['seed'] = d['seed']   \n",
    "    d_kaggle_comp['cv_score'] = d['cv_score']\n",
    "    d_kaggle_comp['k_score'] = np.nan\n",
    "    d_kaggle_comp['local_mode'] = d['local_mode']\n",
    "\n",
    "    #print(len(data.test_data))\n",
    "\n",
    "    \n",
    "\n",
    "    # if not d['cos_lr'] or not d['trust_neg']==1 or d['use_pretrained_weights']:\n",
    "    #     print('skip')\n",
    "    #     continue\n",
    "    # First set\n",
    "    #if not (d['seed']<26 or d['use_missing_value']): print('skip'); continue\n",
    "\n",
    "    # New\n",
    "    #if not (d['seed']>=26 or d['use_missing_value']): print('skip'); continue\n",
    "    #if d['label']=='Test ensemble': continue\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for partial in fls.DataSelector().datasets:\n",
    "        try:\n",
    "            data_selector = fls.DataSelector()\n",
    "            data_selector.datasets = [partial]\n",
    "            d['cv_score_' + partial] = fls.score_competition_metric(data_selector.select(data.inferred_test_data), data_selector.select(data.test_data))[2]\n",
    "        except:\n",
    "            d['cv_score_' + partial] = np.nan\n",
    "\n",
    "    try:\n",
    "        data_selector = fls.DataSelector()\n",
    "        data_selector.datasets = ['ycw', 'mba', 'aba']\n",
    "        d['cv_score_other'] = fls.score_competition_metric(data_selector.select(data.inferred_test_data), data_selector.select(data.test_data))[2]\n",
    "    except:\n",
    "        d['cv_score_other'] = np.nan\n",
    "\n",
    "    dicts_kaggle_comp.append(d_kaggle_comp)\n",
    "    d['k_score']= np.nan\n",
    "\n",
    "    dicts.append(d)    \n",
    "p = pd.DataFrame(dicts)\n",
    "p.sort_values(['seed', 'git_commit_id'], inplace=True);\n",
    "\n",
    "p_kaggle_comp = pd.DataFrame(dicts_kaggle_comp)\n",
    "p_kaggle_comp.sort_values(['seed', 'git_commit_id'], inplace=True);\n",
    "\n",
    "# First set\n",
    "# p = p[np.logical_or(p['seed']<26, p['use_missing_value'])]\n",
    "\n",
    "# New\n",
    "#p = p[np.logical_or(p['seed']>=26, p['use_missing_value'])]\n",
    "\n",
    "p = p.reset_index()\n",
    "p_kaggle_comp = p_kaggle_comp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae3500-c140-41a7-b407-960992c7aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kaggle results\n",
    "#if predict_all:\n",
    "#    kaggle_results_file = fls.code_dir + '../kaggle_results_predict_all.csv'\n",
    "#else:\n",
    "kaggle_results_file = fls.code_dir + '../kaggle_results.csv'\n",
    "p_kaggle_results = pd.read_csv(kaggle_results_file).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769be2d-6ceb-4ef6-8daf-cf65e5974907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add competition results\n",
    "csv = subprocess.run('kaggle competitions submissions -q -csv -c byu-locating-bacterial-flagellar-motors-2025', encoding = 'utf-8', shell=True, stdout=subprocess.PIPE)\n",
    "lines = csv.stdout.split('\\n')[1:]\n",
    "data_str = \"\\n\".join(lines)\n",
    "p_submissions = pd.read_fwf(io.StringIO(data_str), skiprows=[1])\n",
    "for i_i in range(len(p_kaggle_results)):\n",
    "    mv_str = 'Ma' if p_kaggle_results.loc[i_i, 'use_missing_value'] else ''\n",
    "    name_str = p_kaggle_results.loc[i_i, 'label'] + '_' + str(p_kaggle_results.loc[i_i, 'seed']) + mv_str + '_' + p_kaggle_results.loc[i_i, 'git_commit_id'][:8]\n",
    "    #if predict_all:\n",
    "    #    name_str = name_str + ' predict all'\n",
    "    for i_k in range(len(p_submissions)):\n",
    "        if name_str == p_submissions.loc[i_k, 'description']:\n",
    "            score = p_submissions.loc[i_k, 'publicScore']\n",
    "            if not np.isnan(score):\n",
    "                if np.isnan(p_kaggle_results.loc[i_i, 'k_score']):\n",
    "                    p_kaggle_results.loc[i_i, 'k_score'] = score\n",
    "                    print(f'Added score of {score:1.3} for {name_str}')\n",
    "                else:\n",
    "                    if not score == p_kaggle_results.loc[i_i, 'k_score']:\n",
    "                        raise Exception(f'Mismatch for {name_str}: {score:1.3} vs {p_kaggle_results.loc[i_i, \"k_score\"]:1.3}')\n",
    "            else:\n",
    "                print('NaN score found for ', name_str)            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac4bfd-038a-466b-a8cc-8992c05900b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(p_kaggle_results)\n",
    "for i_k in range(len(p_kaggle_results)):\n",
    "    for i_i in range(len(p_kaggle_comp)):\n",
    "        if p_kaggle_results['seed'][i_k] == p_kaggle_comp['seed'][i_i] and p_kaggle_results['git_commit_id'][i_k] == p_kaggle_comp['git_commit_id'][i_i] and  p_kaggle_results['use_missing_value'][i_k] == p_kaggle_comp['use_missing_value'][i_i] and  p_kaggle_results['label'][i_k] == p_kaggle_comp['label'][i_i] and not p_kaggle_comp['local_mode'][i_i]:\n",
    "            p_kaggle_comp.loc[i_i,'k_score'] = p_kaggle_results['k_score'][i_k]\n",
    "for i_k in range(len(p_kaggle_results)):\n",
    "    for i_i in range(len(p)):\n",
    "        if p_kaggle_results['seed'][i_k] == p['seed'][i_i] and p_kaggle_results['git_commit_id'][i_k] == p['git_commit_id'][i_i] and  p_kaggle_results['use_missing_value'][i_k] == p['use_missing_value'][i_i] and  p_kaggle_results['label'][i_k] == p['label'][i_i] and not p['local_mode'][i_i]:\n",
    "            p.loc[i_i,'k_score'] = p_kaggle_results['k_score'][i_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa9e4c-7a9d-484e-a57e-7abed23f93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to Kaggle results file\n",
    "p_kaggle_cache = copy.deepcopy(p_kaggle_comp[['label', 'git_commit_id', 'use_missing_value', 'seed', 'cv_score', 'k_score']])\n",
    "p_kaggle_cache.to_csv(kaggle_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef8623-ef54-4211-ad80-21118fa8d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_i in range(len(p)):\n",
    "#     if p['seed'][i_i] in [0,2,3,4,5,7,8,10]:\n",
    "#         p.loc[i_i,'k_score']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da18aca-a815-4a6a-afa6-bb7080ec3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv(fls.code_dir + '../results.csv')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72512490-b605-4e90-bc1f-731da0a25371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_part = p[p['n_ensemble']==4]\n",
    "# print(p_part['cv_score'])\n",
    "# print(np.mean(p_part['cv_score']), np.std(p_part['cv_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65dbbc-7fe3-4bc5-9243-9c01576d7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = copy.deepcopy(p).columns.to_list()[1:-7]\n",
    "main = np.logical_and(np.logical_not(p['use_missing_value']), p['degrees']>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0bde6-14ce-438d-b0ad-7a357b268e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_k_cv(cv_score, name):\n",
    "    plt.figure()\n",
    "    y = p['k_score'][main]\n",
    "    todo = np.logical_not(np.isnan(y[main]))\n",
    "    plt.scatter(cv_score[main][todo], y[main][todo])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Kaggle score')\n",
    "    XX = pd.DataFrame({'x':cv_score[main][todo]})\n",
    "    XX_const = sm.add_constant(XX)\n",
    "    model = sm.OLS((y[todo]).astype(float).reset_index().drop('index',axis=1), XX_const.astype(float).reset_index().drop('index',axis=1)).fit()\n",
    "    print(model.summary())\n",
    "    return model.predict(XX_const.astype(float))\n",
    "\n",
    "    \n",
    "pred=compare_k_cv(p['cv_score'][main], 'CV score')\n",
    "#compare_k_cv(y_pred, 'CV score pred')\n",
    "\n",
    "p['k_score_res'] = np.nan\n",
    "p['k_score_res'][main] = p['k_score'][main]-pred\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9a153-3344-40e6-92e6-afe34b3de6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[['seed','k_score']][np.logical_and(np.logical_and(np.logical_and(p['degrees']>0, p['degrees']<=10), p['translate']==0.),['0ac' in x for x in p['git_commit_id']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778da17-888b-4096-8004-4badf09464cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "\n",
    "which='k_score_res'\n",
    "todo = np.logical_and(main, np.logical_not(np.isnan(p[which].to_numpy())))\n",
    "#y = p[[which]][todo].to_numpy()-p[['cv_score']][todo].to_numpy()\n",
    "y = p[[which]][todo]\n",
    "\n",
    "# n_ensemble = 1\n",
    "# X = p[['degrees', 'scale_moving_std_size_fac', 'n_epochs', 'trust_extra', 'absolute_threshold', 'z_range', 'concentration', 'erasing', 'scale_moving_std']][todo]\n",
    "# X.loc[np.logical_not(p['scale_moving_std'][todo]), 'scale_moving_std_size_fac'] = np.mean(X.loc[(p['scale_moving_std'][todo]), 'scale_moving_std_size_fac'])\n",
    "# X['trust_neg2'] = (p['trust_neg']==2)[todo]\n",
    "\n",
    "# n_ensemble = 4 offline\n",
    "# X = p[['fliplr']][todo]\n",
    "# X['trust_extra0'] = (p['trust_extra']==0)[todo]\n",
    "# #X['trust_extra'] = (p['trust_extra']==0)[todo]\n",
    "# X['yolov8'] = np.logical_or(p['model_name']=='yolov8m',p['model_name']=='yolov8s')\n",
    "\n",
    "# online\n",
    "# X = p[['fliplr']][todo]\n",
    "\n",
    "# ca1 offline\n",
    "X = p[['mixup', 'flipud', 'adjust_clip_value']][todo]\n",
    "#X['lr0_times_nepochs2'] = X['lr0_times_nepochs']**2\n",
    "X['trust_extra0'] = (p['trust_extra']==0)[todo]\n",
    "X['degrees0'] = (p['degrees']==0)[todo]\n",
    "#X['img_size2'] = (p['img_size']**2)[todo]\n",
    "X['z_range_m1'] = (p['z_range']==-1)[todo]\n",
    "X['trust_neg0'] = (p['trust_neg']==0)[todo]\n",
    "X['model_8'] = (['8' in x for x in p['model_name'][todo]])\n",
    "#X['model_11'] = (['11' in x for x in p['model_name']])\n",
    "\n",
    "# online\n",
    "X = p[['translate', 'degrees', 'lrf', 'z_range', 'fliplr', 'flipud', 'absolute_threshold']][todo]\n",
    "#X['trust_neg0'] = (p['trust_neg']==0)[todo]\n",
    "\n",
    "# Define candidate alphas (lambdas)\n",
    "alphas = np.logspace(-6, 1, 8)\n",
    "\n",
    "# Define pipeline explicitly with named steps\n",
    "pipeline = sklearn.pipeline.Pipeline([\n",
    "    (\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"ridge\", sklearn.linear_model.Lasso())\n",
    "])\n",
    "\n",
    "# Define parameter grid (for Ridge alpha)\n",
    "param_grid = {\n",
    "    \"ridge__alpha\": alphas\n",
    "}\n",
    "\n",
    "# GridSearchCV with 5-fold cross-validation\n",
    "grid_search = sklearn.model_selection.GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=len(y),\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Extract results\n",
    "results = grid_search.cv_results_\n",
    "mean_test_scores = -results['mean_test_score']  # Convert to positive MSE\n",
    "alphas_tested = results['param_ridge__alpha'].data.astype(float)\n",
    "\n",
    "# Plot CV error as function of alpha\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.semilogx(alphas_tested, mean_test_scores, marker='o')\n",
    "plt.xlabel(\"Alpha (L2 Regularization Strength)\")\n",
    "plt.ylabel(\"Mean CV MSE\")\n",
    "plt.title(\"Cross-Validation Error vs Alpha\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Report best alpha\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "print(\"Best alpha (lambda):\", best_alpha)\n",
    "print(\"Best CV Mean RMSE:\", np.sqrt(-grid_search.best_score_))\n",
    "\n",
    "# Create a new pipeline with the best alpha\n",
    "final_model = sklearn.pipeline.Pipeline([\n",
    "    (\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"lasso\", sklearn.linear_model.Lasso(alpha=best_alpha))\n",
    "])\n",
    "\n",
    "# Fit to full dataset\n",
    "final_model.fit(X, y)\n",
    "\n",
    "y_pred = final_model.predict(X)\n",
    "p['residual'] = np.nan\n",
    "#p.loc[todo,'residual'] = (y-y_pred).to_numpy()\n",
    "p.loc[todo,'residual'] = (np.ravel(y)-y_pred)\n",
    "\n",
    "# (Optional) Print final coefficients and intercept\n",
    "lasso_model = final_model.named_steps['lasso']\n",
    "print(\"Final coefficients:\", lasso_model.coef_)\n",
    "print(X.columns)\n",
    "print(\"Final intercept:\", lasso_model.intercept_)\n",
    "\n",
    "print(np.std(p['residual'][todo]))\n",
    "print(np.std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54907b09-21bd-4e51-b684-5be2970f20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X_norm = (X - X.mean()) / X.std(ddof=0)\n",
    "#X_norm = X\n",
    "X_const = sm.add_constant(X_norm)\n",
    "model = sm.OLS(y[main].astype(float), X_const.astype(float)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8554df6-a9c6-4187-8a4f-7ef7b2d8302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_k_cv(y_pred, 'CV score pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f16ed-15bf-416e-9dbe-d138a1f2e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_alt = copy.deepcopy(X)\n",
    "# for c in X_alt.columns:\n",
    "#     X_alt[c] = 0\n",
    "# X_alt['lr0_times_nepochs'] = X['lr0_times_nepochs']\n",
    "# X_alt['lr0_times_nepochs2'] = X['lr0_times_nepochs']**2\n",
    "# y_pred_alt = final_model.predict(X_alt)\n",
    "# plt.scatter(X_alt['lr0_times_nepochs'], y_pred_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896a494-d23b-4a08-a0b5-293dbbda6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = len(to_plot)//ncols+1\n",
    "figs = []\n",
    "r = np.random.default_rng(seed=0)\n",
    "#main = p['model_name']=='yolov8l'\n",
    "for y_val in p.columns[[-1,-6,-3,-2]].to_list():\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18,18/ncols*nrows))\n",
    "    plt.tight_layout(pad=10.0,h_pad=1,w_pad=1)\n",
    "    figs.append(fig)\n",
    "    plt.suptitle(y_val)\n",
    "    for idx,d in enumerate(to_plot):\n",
    "        row = idx // ncols\n",
    "        col = idx % ncols\n",
    "        ax = axes[row, col]\n",
    "        plt.sca(ax)        \n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.grid(True)\n",
    "        #p[y_val] = r.normal(size=p[y_val].shape)\n",
    "        plt.scatter(p[d][main], p[y_val][main])\n",
    "        #if y_val == 'k_score':\n",
    "         #   plt.scatter(p[d][np.logical_not(main)], p[y_val][np.logical_not(main)])\n",
    "       \n",
    "        # fit\n",
    "        if len(np.unique(p[d][main]))>1:\n",
    "            pp = copy.deepcopy(p)\n",
    "            if not pd.api.types.is_numeric_dtype(pp[d]) or pd.api.types.is_bool_dtype(pp[d]):\n",
    "                pp[d] = pp[d].astype('category').cat.codes\n",
    "            X = pp[[d]][main]\n",
    "            X['intercept'] = 1.\n",
    "            y = p[y_val][main]\n",
    "            to_keep = np.logical_not(np.isnan(y))\n",
    "            X = X[to_keep]; y=y[to_keep];\n",
    "            model = sm.OLS(y,X)\n",
    "            results=model.fit()\n",
    "            p_val = results.pvalues[d]\n",
    "            plt.title(f'{d} (p={p_val:.3})')\n",
    "        else:\n",
    "            plt.title(d)\n",
    "        \n",
    "        # if d == 'mask_sizes0':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][0] for m in model_list]\n",
    "        # elif d == 'mask_sizes1':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][1] for m in model_list]\n",
    "        # elif d == 'mask_sizes2':\n",
    "        #     x_vals = [m.mask_sizes[model.particles_to_do[0]][2] for m in model_list]\n",
    "        # else:\n",
    "        #     x_vals = [getattr(m, d)[model.particles_to_do[0]] for m in model_list]\n",
    "        # if len(np.unique(x_vals))<8:\n",
    "        #     #pass\n",
    "        #     violin_plot(x_vals,score_vals)\n",
    "        # else:\n",
    "        #     plt.scatter(x_vals, score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa12e6-7a5a-42dc-8866-a2df4cd95c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pptx import Presentation\n",
    "# from pptx.util import Inches\n",
    "\n",
    "# prs = Presentation()\n",
    "# blank = prs.slide_layouts[6]  # a blank slide layout\n",
    "\n",
    "# for i, fig in enumerate(figs):\n",
    "#     # save each figure to disk\n",
    "#     img_path = f\"figure_{i+1}.png\"\n",
    "#     fig.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "#     # add a new slide, then add the image to it\n",
    "#     slide = prs.slides.add_slide(blank)\n",
    "#     slide.shapes.add_picture(\n",
    "#         img_path,\n",
    "#         Inches(1), Inches(1),          # left, top margins\n",
    "#         width=Inches(8)                # scale width (height auto)\n",
    "#     )\n",
    "\n",
    "#     os.remove(img_path)\n",
    "\n",
    "# prs.save(\"run_many_models_results.pptx\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "isSourceIdPinned": false,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 6925042,
     "sourceId": 11204341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6949538,
     "sourceId": 11204343,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211097053,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 229283084,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
