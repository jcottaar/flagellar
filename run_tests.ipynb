{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcddf786-c0f5-4eb6-b5f2-97278c1def1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665bda1-916a-495e-aa3b-0d73dd1d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40f34e23482416e8e000b2ce7ec839d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587cec8d89534403979a64a625c4f079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 115 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 14 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 5.22.5 MB/s, size: 24.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train... 290 images, 206 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.33.0 MB/s, size: 32.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   9.45e-05     0.0833   5.47e-05   5.47e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00104      0.583    0.00454   0.000547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00264      0.583     0.0348    0.00996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00162      0.583     0.0244    0.00711\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 329.976.4 MB/s, size: 28.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 290 images, 206 backgrounds, 0 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 403.7111.0 MB/s, size: 33.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12     0.0679     0.0833     0.0114    0.00145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00852     0.0833    0.00158    0.00038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12     0.0272     0.0833    0.00554   0.000718\n",
      "Speed: 0.6ms preprocess, 10.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "\n",
      "Training complete!\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    297  858  912    0.491455\n",
      "1    283  940  419    0.461914\n",
      "2      7  940   90    0.434326\n",
      "3     17   28   70    0.406494\n",
      "4    297  940  110    0.405273\n",
      "..   ...  ...  ...         ...\n",
      "230  298  941  837    0.098694\n",
      "231   78  458  929    0.098389\n",
      "232  109  273  929    0.098389\n",
      "233  205  468  930    0.098389\n",
      "234  222   38  879    0.098389\n",
      "\n",
      "[235 rows x 4 columns]\n",
      "\n",
      "tomo_081a2d total infer time: 18.5770525932312\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   261  737  852    0.363281\n",
      "1   229  737  941    0.335205\n",
      "2   280  850  761    0.324707\n",
      "3   439  923  956    0.310303\n",
      "4   314  818  194    0.300049\n",
      "..  ...  ...  ...         ...\n",
      "61  220   39  891    0.074768\n",
      "62  256  736  957    0.074280\n",
      "63  256  924  884    0.073792\n",
      "64  232   30  421    0.073059\n",
      "65  439  850  956    0.072815\n",
      "\n",
      "[66 rows x 4 columns]\n",
      "\n",
      "tomo_08446f total infer time: 43.83656358718872\n",
      "         z    y    x  confidence  i_model\n",
      "26136    0  899  891    0.881836        1\n",
      "26137    0  919  900    0.873047        1\n",
      "26138    0  910  900    0.868164        1\n",
      "26139    0  931  890    0.868164        1\n",
      "26140    0  910  891    0.866211        1\n",
      "...    ...  ...  ...         ...      ...\n",
      "46454  299  960  920    0.209473        1\n",
      "46455  299  920   48    0.207520        1\n",
      "46456  299  785  928    0.205566        1\n",
      "46457  299   17  717    0.203125        1\n",
      "46458  299  839  888    0.201172        1\n",
      "\n",
      "[14088 rows x 5 columns]\n",
      "         z    y    x  confidence  i_model\n",
      "28560    1   22  283    0.316650        1\n",
      "28561    1   22  290    0.208130        1\n",
      "28562    1   13  284    0.187134        1\n",
      "29026   16  793  956    0.188965        1\n",
      "29027   16  794  949    0.158691        1\n",
      "...    ...  ...  ...         ...      ...\n",
      "40958  439  916  949    0.171631        1\n",
      "40959  439  930  956    0.166626        1\n",
      "40960  439  898  958    0.154541        1\n",
      "40961  439  908  778    0.151001        1\n",
      "40962  439  850  956    0.145630        1\n",
      "\n",
      "[630 rows x 5 columns]\n",
      "[   index    z    y    x  confidence     value\n",
      "0      0  297  858  912    0.491455  0.491455, Empty DataFrame\n",
      "Columns: [index, z, y, x, confidence, value]\n",
      "Index: []]\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2cd0b0121346bfb2c68eb21c6e718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bb51e97f464c6d8caa92ef54c8e7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 115 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 14 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.82.0 MB/s, size: 24.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 290 images, 206 backgrounds, 0 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 7.31.6 MB/s, size: 32.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   9.45e-05     0.0833   5.47e-05   5.47e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00104      0.583    0.00454   0.000547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00264      0.583     0.0348    0.00996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00162      0.583     0.0244    0.00711\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 284.9105.6 MB/s, size: 28.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 290 images, 206 backgrounds, 0 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 396.2100.1 MB/s, size: 33.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12     0.0679     0.0833     0.0114    0.00145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00852     0.0833    0.00158    0.00038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12     0.0272     0.0833    0.00554   0.000718\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "\n",
      "Training complete!\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    297  858  912    0.491455\n",
      "1    283  940  419    0.461914\n",
      "2      7  940   90    0.434326\n",
      "3     17   28   70    0.406494\n",
      "4    297  940  110    0.405273\n",
      "..   ...  ...  ...         ...\n",
      "230  298  941  837    0.098694\n",
      "231   78  458  929    0.098389\n",
      "232  109  273  929    0.098389\n",
      "233  205  468  930    0.098389\n",
      "234  222   38  879    0.098389\n",
      "\n",
      "[235 rows x 4 columns]\n",
      "\n",
      "tomo_081a2d total infer time: 18.390130758285522\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   261  737  852    0.363281\n",
      "1   229  737  941    0.335205\n",
      "2   280  850  761    0.324707\n",
      "3   439  923  956    0.310303\n",
      "4   314  818  194    0.300049\n",
      "..  ...  ...  ...         ...\n",
      "61  220   39  891    0.074768\n",
      "62  256  736  957    0.074280\n",
      "63  256  924  884    0.073792\n",
      "64  232   30  421    0.073059\n",
      "65  439  850  956    0.072815\n",
      "\n",
      "[66 rows x 4 columns]\n",
      "\n",
      "tomo_08446f total infer time: 43.78067088127136\n",
      "         z    y    x  confidence  i_model\n",
      "26136    0  899  891    0.881836        1\n",
      "26137    0  919  900    0.873047        1\n",
      "26138    0  910  900    0.868164        1\n",
      "26139    0  931  890    0.868164        1\n",
      "26140    0  910  891    0.866211        1\n",
      "...    ...  ...  ...         ...      ...\n",
      "46454  299  960  920    0.209473        1\n",
      "46455  299  920   48    0.207520        1\n",
      "46456  299  785  928    0.205566        1\n",
      "46457  299   17  717    0.203125        1\n",
      "46458  299  839  888    0.201172        1\n",
      "\n",
      "[14088 rows x 5 columns]\n",
      "         z    y    x  confidence  i_model\n",
      "28560    1   22  283    0.316650        1\n",
      "28561    1   22  290    0.208130        1\n",
      "28562    1   13  284    0.187134        1\n",
      "29026   16  793  956    0.188965        1\n",
      "29027   16  794  949    0.158691        1\n",
      "...    ...  ...  ...         ...      ...\n",
      "40958  439  916  949    0.171631        1\n",
      "40959  439  930  956    0.166626        1\n",
      "40960  439  898  958    0.154541        1\n",
      "40961  439  908  778    0.151001        1\n",
      "40962  439  850  956    0.145630        1\n",
      "\n",
      "[630 rows x 5 columns]\n",
      "[   index    z    y    x  confidence     value\n",
      "0      0  297  858  912    0.491455  0.491455, Empty DataFrame\n",
      "Columns: [index, z, y, x, confidence, value]\n",
      "Index: []]\n",
      "Clearing pytorch\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(flg_test)\n",
    "flg_test.test_yolo(update_reference=True)\n",
    "flg_test.run_all_tests(update_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c3ba-6c07-4761-ad4f-c3078a3a57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_support as fls\n",
    "ref_name = fls.code_dir + 'ref_yolo.pickle';\n",
    "str(fls.dill_load(ref_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b4516-35a7-4a48-a757-26033301e074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
