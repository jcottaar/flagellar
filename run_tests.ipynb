{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcddf786-c0f5-4eb6-b5f2-97278c1def1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665bda1-916a-495e-aa3b-0d73dd1d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d0ba8c7f094a269d31431800b52a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset 0\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d391cf915ca471387a5c20de5dc499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "offset 0\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 115 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 14 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.143 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.82.1 MB/s, size: 23.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train... 297 images, 206 backgrounds, 3 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0198.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0203.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 5.42.0 MB/s, size: 31.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 58 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13   5.75e-05     0.0769   3.37e-05   6.75e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13   0.000533      0.231    0.00103   0.000116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13   0.000577     0.0769   0.000322   3.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13    0.00508      0.231    0.00448   0.000461\n",
      "Speed: 0.3ms preprocess, 12.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "New https://pypi.org/project/ultralytics/8.3.143 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 471.1311.3 MB/s, size: 26.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 297 images, 206 backgrounds, 3 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0198.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0203.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 396.7112.3 MB/s, size: 33.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 58 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13     0.0448      0.154     0.0112    0.00115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         58         13     0.0251      0.154    0.00631    0.00068\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "\n",
      "Training complete!\n",
      "False False\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "0\n",
      "    z    y    x  confidence  i_model\n",
      "16  3  557  474         1.0        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "1\n",
      "         z    y    x  confidence  i_model\n",
      "67469  264  307  712    0.098083        0\n",
      "        z    y    x  confidence  i_model\n",
      "0       0  277  191    0.619629        0\n",
      "1       0  277  234    0.523438        0\n",
      "2       0  274  891    0.329346        0\n",
      "3       0   14  892    0.328613        0\n",
      "4       1  277  237    0.984375        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "8434  299  140  253    0.021164        1\n",
      "8435  299  171  233    0.021118        1\n",
      "8436  299  119  264    0.020416        1\n",
      "8437  299  601  551    0.020248        1\n",
      "8438  299  602  540    0.020142        1\n",
      "\n",
      "[8439 rows x 5 columns]\n",
      "FINAL\n",
      "        z    y    x  confidence\n",
      "0       3  557  474    0.500000\n",
      "1       3  553  442    0.500000\n",
      "2       3  605  504    0.500000\n",
      "3       3  646  535    0.500000\n",
      "4       3  667  602    0.500000\n",
      "...   ...  ...  ...         ...\n",
      "2551  291  431  662    0.100586\n",
      "2552  266   21  174    0.100464\n",
      "2553  274  728  805    0.100281\n",
      "2554  222  281  255    0.100098\n",
      "2555  290   26  267    0.100098\n",
      "\n",
      "[2556 rows x 4 columns]\n",
      "\n",
      "tomo_081a2d total infer time: 24.25741219520569\n",
      "False False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "0\n",
      "        z    y    x  confidence  i_model\n",
      "7812  281  772  707    0.996582        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "1\n",
      "        z    y    x  confidence  i_model\n",
      "13071  88  238  750     0.36377        0\n",
      "        z    y    x  confidence  i_model\n",
      "0       4  284  227    0.426270        0\n",
      "1       4  299  255    0.237183        0\n",
      "2       5  284  251    0.481445        0\n",
      "3       5  291  281    0.204712        0\n",
      "4       6  284  222    0.312256        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "3474  499  148   76    0.103760        1\n",
      "3475  499  546  856    0.092346        1\n",
      "3476  499  156   84    0.084473        1\n",
      "3477  499  553  856    0.083862        1\n",
      "3478  499   92  336    0.076660        1\n",
      "\n",
      "[3479 rows x 5 columns]\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    281  772  707    0.498291\n",
      "1    281  771  668    0.497070\n",
      "2    281  771  760    0.495850\n",
      "3    281  771  639    0.487549\n",
      "4    275  757  724    0.480225\n",
      "..   ...  ...  ...         ...\n",
      "207    5  291  281    0.102356\n",
      "208  174  302  377    0.101868\n",
      "209  241   52  287    0.101868\n",
      "210  205  678  678    0.100586\n",
      "211  274  728  856    0.100586\n",
      "\n",
      "[212 rows x 4 columns]\n",
      "\n",
      "tomo_08446f total infer time: 53.09235119819641\n",
      "        z    y    x  confidence  i_model\n",
      "0       0  277  191    0.619629        0\n",
      "1       0  277  234    0.523438        0\n",
      "2       0  274  891    0.329346        0\n",
      "3       0   14  892    0.328613        0\n",
      "4       1  277  237    0.984375        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "3827  296  175  335    0.464844        0\n",
      "3828  296  615  524    0.429199        0\n",
      "3829  296  346  382    0.417725        0\n",
      "3830  298   22  857    0.221313        0\n",
      "3831  298  268  892    0.208130        0\n",
      "\n",
      "[3832 rows x 5 columns]\n",
      "        z    y    x  confidence  i_model\n",
      "0       4  284  227    0.426270        0\n",
      "1       4  299  255    0.237183        0\n",
      "2       5  284  251    0.481445        0\n",
      "3       5  291  281    0.204712        0\n",
      "4       6  284  222    0.312256        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "2715  265  124  385    0.263672        1\n",
      "2796  270  707   68    0.228149        1\n",
      "3191  310  587  117    0.224731        1\n",
      "3214  312  587  116    0.340820        1\n",
      "3215  312  587  108    0.319092        1\n",
      "\n",
      "[556 rows x 5 columns]\n",
      "[   index  z    y    x  confidence  value\n",
      "0      0  3  557  474         0.5    0.5, Empty DataFrame\n",
      "Columns: [index, z, y, x, confidence, value]\n",
      "Index: []]\n",
      "Clearing pytorch\n",
      "42\n",
      "0 1 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cupy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n",
      "Clearing cupy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(flg_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#flg_test.test_yolo(update_reference=True)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mflg_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:128\u001b[0m, in \u001b[0;36mrun_all_tests\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m    126\u001b[0m test_yolo(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)\n\u001b[0;32m    127\u001b[0m test_unet(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)\n\u001b[1;32m--> 128\u001b[0m \u001b[43mtest_unet_alt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_reference\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll tests passed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:79\u001b[0m, in \u001b[0;36mtest_unet_alt\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m     77\u001b[0m     fls\u001b[38;5;241m.\u001b[39mdill_save(ref_name, np\u001b[38;5;241m.\u001b[39mstd(heatmap))\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(heatmap) \u001b[38;5;241m==\u001b[39m fls\u001b[38;5;241m.\u001b[39mdill_load(ref_name)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(flg_test)\n",
    "#flg_test.test_yolo(update_reference=True)\n",
    "flg_test.run_all_tests(update_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c3ba-6c07-4761-ad4f-c3078a3a57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_support as fls\n",
    "ref_name = fls.code_dir + 'ref_yolo.pickle';\n",
    "str(fls.dill_load(ref_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b4516-35a7-4a48-a757-26033301e074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
