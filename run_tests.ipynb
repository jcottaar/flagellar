{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcddf786-c0f5-4eb6-b5f2-97278c1def1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665bda1-916a-495e-aa3b-0d73dd1d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1881649221ad4f6babb4691f743a0edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "[140, 141, 142, 143, 144, 145, 146, 147, 148]\n",
      "[148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "[179, 180, 181, 182, 183, 184, 185, 186, 187]\n",
      "[137, 138, 139, 140, 141, 142, 143, 144, 145]\n",
      "[152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
      "[131, 132, 133, 134, 135, 136, 137, 138, 139]\n",
      "[99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
      "[117, 118, 119, 120, 121, 122, 123, 124, 125]\n",
      "[128, 129, 130, 131, 132, 133, 134, 135, 136]\n",
      "[121, 122, 123, 124, 125, 126, 127, 128, 129]\n",
      "[162, 163, 164, 165, 166, 167, 168, 169, 170]\n",
      "[171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "[102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[182, 183, 184, 185, 186, 187, 188, 189, 190]\n",
      "[133, 134, 135, 136, 137, 138, 139, 140, 141]\n",
      "[69, 70, 71, 72, 73, 74, 75, 76, 77]\n",
      "[104, 105, 106, 107, 108, 109, 110, 111, 112]\n",
      "[126, 127, 128, 129, 130, 131, 132, 133, 134]\n",
      "[181, 182, 183, 184, 185, 186, 187, 188, 189]\n",
      "[175, 176, 177, 178, 179, 180, 181, 182, 183]\n",
      "[134, 135, 136, 137, 138, 139, 140, 141, 142]\n",
      "[203, 204, 205, 206, 207, 208, 209, 210, 211]\n",
      "[61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[97, 98, 99, 100, 101, 102, 103, 104, 105]\n",
      "[122, 123, 124, 125, 126, 127, 128, 129, 130]\n",
      "[141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "[63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92]\n",
      "[138, 139, 140, 141, 142, 143, 144, 145, 146]\n",
      "[121, 122, 123, 124, 125, 126, 127, 128, 129]\n",
      "[171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[93, 94, 95, 96, 97, 98, 99, 100, 101]\n",
      "[93, 94, 95, 96, 97, 98, 99, 100, 101]\n",
      "[164, 165, 166, 167, 168, 169, 170, 171, 172]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72]\n",
      "[155, 156, 157, 158, 159, 160, 161, 162, 163]\n",
      "[57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[145, 146, 147, 148, 149, 150, 151, 152, 153]\n",
      "[162, 163, 164, 165, 166, 167, 168, 169, 170]\n",
      "[139, 140, 141, 142, 143, 144, 145, 146, 147]\n",
      "[123, 124, 125, 126, 127, 128, 129, 130, 131]\n",
      "[165, 166, 167, 168, 169, 170, 171, 172, 173]\n",
      "[247, 248, 249, 250, 251, 252, 253, 254, 255]\n",
      "[193, 194, 195, 196, 197, 198, 199, 200, 201]\n",
      "[46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
      "[157, 158, 159, 160, 161, 162, 163, 164, 165]\n",
      "[149, 150, 151, 152, 153, 154, 155, 156, 157]\n",
      "[127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
      "[148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "[90, 91, 92, 93, 94, 95, 96, 97, 98]\n",
      "[145, 146, 147, 148, 149, 150, 151, 152, 153]\n",
      "[108, 109, 110, 111, 112, 113, 114, 115, 116]\n",
      "[12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[149, 150, 151, 152, 153, 154, 155, 156, 157]\n",
      "[168, 169, 170, 171, 172, 173, 174, 175, 176]\n",
      "[230, 231, 232, 233, 234, 235, 236, 237, 238]\n",
      "[259, 260, 261, 262, 263, 264, 265, 266, 267]\n",
      "[181, 182, 183, 184, 185, 186, 187, 188, 189]\n",
      "[143, 144, 145, 146, 147, 148, 149, 150, 151]\n",
      "[139, 140, 141, 142, 143, 144, 145, 146, 147]\n",
      "[157, 158, 159, 160, 161, 162, 163, 164, 165]\n",
      "[119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
      "[51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "[200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[191, 192, 193, 194, 195, 196, 197, 198, 199]\n",
      "[143, 144, 145, 146, 147, 148, 149, 150, 151]\n",
      "[140, 141, 142, 143, 144, 145, 146, 147, 148]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4c51c4887e464d92b949551641927c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
      "[211, 212, 213, 214, 215, 216, 217, 218, 219]\n",
      "[56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "[170, 171, 172, 173, 174, 175, 176, 177, 178]\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96]\n",
      "[164, 165, 166, 167, 168, 169, 170, 171, 172]\n",
      "[135, 136, 137, 138, 139, 140, 141, 142, 143]\n",
      "[155, 156, 157, 158, 159, 160, 161, 162, 163]\n",
      "[108, 109, 110, 111, 112, 113, 114, 115, 116]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 74 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 9 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=10, batch=12, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 86.124.8 MB/s, size: 344.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train... 666 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 57.710.8 MB/s, size: 374.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81     0.0536      0.037     0.0287    0.00567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81       0.25      0.123      0.102     0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81      0.408      0.407      0.387      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81      0.478      0.395        0.4      0.126\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=10, batch=12, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1995.6370.0 MB/s, size: 355.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 666 images, 0 backgrounds, 0 corrupt: 100%|███████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1714.5193.1 MB/s, size: 334.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81      0.289      0.257      0.185     0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81      0.756      0.296      0.419      0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         81         81      0.514      0.333      0.434      0.151\n",
      "Speed: 0.5ms preprocess, 9.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "\n",
      "Training complete!\n",
      "Clearing cupy\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   163  317  650    0.656982\n",
      "1   171  321  877    0.197510\n",
      "2   281  950  411    0.108459\n",
      "3   244    9  639    0.023170\n",
      "4    22   66   60    0.014824\n",
      "5    82  555  243    0.013229\n",
      "6    32   49  892    0.010605\n",
      "7   173  721  469    0.014038\n",
      "8   270  947  853    0.005867\n",
      "9   269  429  772    0.005646\n",
      "10   48   31  727    0.006430\n",
      "11  178  733  347    0.006907\n",
      "12  190  509  235    0.004189\n",
      "13  229  223  816    0.002043\n",
      "14  226  509  470    0.001868\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(flg_test)\n",
    "#flg_test.test_yolo(update_reference=True)\n",
    "flg_test.run_all_tests(update_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fae9a-5bb0-45c0-b50f-5cfcfa205221",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c3ba-6c07-4761-ad4f-c3078a3a57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_support as fls\n",
    "ref_name = fls.code_dir + 'ref_yolo.pickle';\n",
    "str(fls.dill_load(ref_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b4516-35a7-4a48-a757-26033301e074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
