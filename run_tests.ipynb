{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcddf786-c0f5-4eb6-b5f2-97278c1def1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665bda1-916a-495e-aa3b-0d73dd1d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8021b551477347079897096f480d4700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6531b6fa853743edbe45063b578ca024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 115 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 14 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.138 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3.71.1 MB/s, size: 29.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train... 326 images, 235 backgrounds, 3 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0198.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0203.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.12.0 MB/s, size: 33.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val... 63 images, 52 backgrounds, 0 corrupt: 100%|██████████| 63/63\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13   0.000892      0.462    0.00534   0.000566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13     0.0018      0.154    0.00329   0.000525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13   0.000744      0.462    0.00398   0.000424\n",
      "Speed: 0.3ms preprocess, 12.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "New https://pypi.org/project/ultralytics/8.3.138 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 576.4369.9 MB/s, size: 25.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 326 images, 235 backgrounds, 3 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0198.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\flagellar\\temp\\yolo_dataset\\images\\train\\mba2010-09-09-4_z0203.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 653.6192.4 MB/s, size: 36.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 63 images, 52 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13   0.000674      0.308    0.00186   0.000431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13   0.000508      0.538    0.00188   0.000932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         63         13   0.000452      0.538    0.00147   0.000728\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "\n",
      "Training complete!\n",
      "False False\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "0\n",
      "         z    y    x  confidence  i_model\n",
      "13775  203  635  763    0.034882        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "1\n",
      "         z   y    x  confidence  i_model\n",
      "26497  251  47  800    0.155029        0\n",
      "        z    y    x  confidence  i_model\n",
      "0       7  601  722    0.007404        0\n",
      "1       9  629  655    0.008575        0\n",
      "2       9  577  798    0.007431        0\n",
      "3       9  612  733    0.007122        0\n",
      "4      15  576  801    0.008125        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "1806  299    6  697    0.034485        1\n",
      "1807  299  945   60    0.033600        1\n",
      "1808  299    5  666    0.032959        1\n",
      "1809  299    6  707    0.032837        1\n",
      "1810  299   26  861    0.031143        1\n",
      "\n",
      "[1811 rows x 5 columns]\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   251   47  800    0.077515\n",
      "1   251   47  821    0.061249\n",
      "2     0  945   58    0.060211\n",
      "3     8  945   79    0.059387\n",
      "4   244   48  759    0.055054\n",
      "..  ...  ...  ...         ...\n",
      "89  289    5  860    0.015686\n",
      "90    0   17  851    0.015625\n",
      "91   11  620  481    0.015625\n",
      "92  141   26   83    0.015625\n",
      "93  299   26  861    0.015572\n",
      "\n",
      "[94 rows x 4 columns]\n",
      "\n",
      "tomo_081a2d total infer time: 30.400025129318237\n",
      "False False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "0\n",
      "        z    y    x  confidence  i_model\n",
      "7387  207  632  563    0.141968        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "1\n",
      "      z    y    x  confidence  i_model\n",
      "699  11  901  439    0.229492        0\n",
      "       z    y    x  confidence  i_model\n",
      "0     10  270  212    0.098083        0\n",
      "1     10  295  266    0.080811        0\n",
      "2     10  275  204    0.075317        0\n",
      "3     10  245  163    0.028702        0\n",
      "4     13  287  171    0.038910        0\n",
      "..   ...  ...  ...         ...      ...\n",
      "337  385  900   49    0.058228        1\n",
      "338  385  900   33    0.049957        1\n",
      "339  385  912   64    0.049500        1\n",
      "340  387  900   49    0.054199        1\n",
      "341  407  902   66    0.046021        1\n",
      "\n",
      "[342 rows x 5 columns]\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0     11  901  439    0.114746\n",
      "1     11  900  423    0.104736\n",
      "2    382  900   49    0.093262\n",
      "3    207  632  563    0.070984\n",
      "4    289  900   82    0.066284\n",
      "..   ...  ...  ...         ...\n",
      "104  105  886  195    0.023193\n",
      "105  407  902   66    0.023010\n",
      "106  173  676  310    0.022980\n",
      "107  356  744  286    0.022980\n",
      "108  112  900  342    0.022980\n",
      "\n",
      "[109 rows x 4 columns]\n",
      "\n",
      "tomo_08446f total infer time: 71.08962965011597\n",
      "        z    y    x  confidence  i_model\n",
      "856   203  635  763    0.034882        0\n",
      "997   234  849  109    0.034088        0\n",
      "1148  281  912  427    0.032715        0\n",
      "1216    0  945   58    0.120422        1\n",
      "1217    0  945   77    0.116333        1\n",
      "...   ...  ...  ...         ...      ...\n",
      "1806  299    6  697    0.034485        1\n",
      "1807  299  945   60    0.033600        1\n",
      "1808  299    5  666    0.032959        1\n",
      "1809  299    6  707    0.032837        1\n",
      "1810  299   26  861    0.031143        1\n",
      "\n",
      "[598 rows x 5 columns]\n",
      "       z    y    x  confidence  i_model\n",
      "0     10  270  212    0.098083        0\n",
      "1     10  295  266    0.080811        0\n",
      "2     10  275  204    0.075317        0\n",
      "6     39  627  286    0.066345        0\n",
      "11    43  677  648    0.087891        0\n",
      "..   ...  ...  ...         ...      ...\n",
      "337  385  900   49    0.058228        1\n",
      "338  385  900   33    0.049957        1\n",
      "339  385  912   64    0.049500        1\n",
      "340  387  900   49    0.054199        1\n",
      "341  407  902   66    0.046021        1\n",
      "\n",
      "[209 rows x 5 columns]\n",
      "[Empty DataFrame\n",
      "Columns: [index, z, y, x, confidence, value]\n",
      "Index: [],    index   z    y    x  confidence     value\n",
      "0      0  11  901  439    0.114746  0.114746]\n",
      "Clearing pytorch\n",
      "42\n",
      "0 1 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cupy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n",
      "Clearing cupy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(flg_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#flg_test.test_yolo(update_reference=True)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mflg_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:127\u001b[0m, in \u001b[0;36mrun_all_tests\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m    125\u001b[0m test_yolo(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)\n\u001b[0;32m    126\u001b[0m test_unet(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)\n\u001b[1;32m--> 127\u001b[0m \u001b[43mtest_unet_alt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_reference\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll tests passed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:79\u001b[0m, in \u001b[0;36mtest_unet_alt\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m     77\u001b[0m     fls\u001b[38;5;241m.\u001b[39mdill_save(ref_name, np\u001b[38;5;241m.\u001b[39mstd(heatmap))\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(heatmap) \u001b[38;5;241m==\u001b[39m fls\u001b[38;5;241m.\u001b[39mdill_load(ref_name)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(flg_test)\n",
    "#flg_test.test_yolo(update_reference=True)\n",
    "flg_test.run_all_tests(update_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c3ba-6c07-4761-ad4f-c3078a3a57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_support as fls\n",
    "ref_name = fls.code_dir + 'ref_yolo.pickle';\n",
    "str(fls.dill_load(ref_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b4516-35a7-4a48-a757-26033301e074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
