{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcddf786-c0f5-4eb6-b5f2-97278c1def1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665bda1-916a-495e-aa3b-0d73dd1d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960f6480a7af49519003ee97724e0866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6720688a048bb95cb11d67adef57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 115 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 14 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 6.51.4 MB/s, size: 24.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train... 290 images, 206 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 5.82.1 MB/s, size: 32.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████| 57/57\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   0.000141      0.167   9.01e-05    1.8e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   0.000943      0.417    0.00405   0.000938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12      0.173     0.0833     0.0235     0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12      0.161     0.0833     0.0231     0.0154\n",
      "Speed: 0.2ms preprocess, 15.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=d:/flagellar/temp/training.yaml, epochs=3, time=None, patience=0, batch=12, imgsz=320, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=100000, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=100000, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=1.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 288.445.1 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 290 images, 206 backgrounds, 0 corrupt: 100%|█████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 406.5111.1 MB/s, size: 33.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 57 images, 47 backgrounds, 0 corrupt: 100%|██████████|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.00046875), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12    0.00216     0.0833    0.00148   0.000593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   0.000175      0.167   0.000251   2.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         57         12   0.000912     0.0833   0.000607   0.000243\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\best.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\epoch0.pt, 15.2MB\n",
      "Optimizer stripped: d:/flagellar/temp/yolo_weights/motor_detector/weights\\last.pt, 15.2MB\n",
      "[]\n",
      "\n",
      "Training complete!\n",
      "False False\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "0\n",
      "        z    y    x  confidence  i_model\n",
      "5589  265  940  422    0.935547        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_081a2d (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "1\n",
      "        z    y   x  confidence  i_model\n",
      "13418  78  893  69    0.069031        0\n",
      "        z    y    x  confidence  i_model\n",
      "0       0  940  851    0.765625        0\n",
      "1       0  929  851    0.637695        0\n",
      "2       0  941  845    0.532227        0\n",
      "3       0  949  851    0.524414        0\n",
      "4       0  930  845    0.394287        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "3277  299  144  510    0.016159        1\n",
      "3278  299  163  662    0.015839        1\n",
      "3279  299  163  642    0.015717        1\n",
      "3280  299  172  672    0.015671        1\n",
      "3281  299  163  682    0.015251        1\n",
      "\n",
      "[3282 rows x 5 columns]\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   265  940  422    0.467773\n",
      "1   138  726  453    0.463867\n",
      "2     0  940  851    0.382812\n",
      "3   185  735  432    0.372070\n",
      "4   148  571  380    0.351562\n",
      "5     0  929  851    0.318848\n",
      "6   160  304  493    0.311768\n",
      "7    98  653  258    0.286377\n",
      "8   174  653  248    0.259277\n",
      "9   102  632  247    0.250000\n",
      "10    7  940  114    0.249512\n",
      "11  193  427  411    0.234375\n",
      "12  164  571  380    0.206055\n",
      "13  153  355  678    0.196655\n",
      "14  153  365  679    0.193848\n",
      "15  294  948  217    0.169922\n",
      "16  164  581  381    0.168213\n",
      "17  172  642  238    0.167725\n",
      "18  131  673  259    0.160889\n",
      "19    0  919  852    0.159180\n",
      "20   99  622  237    0.148682\n",
      "21  172  632  237    0.145874\n",
      "22  153  356  668    0.145142\n",
      "23  124  694  483    0.144287\n",
      "24  172  468  401    0.144287\n",
      "25  152  304  658    0.140747\n",
      "26  123  653  248    0.138306\n",
      "27  153  776  278    0.137207\n",
      "28  259  468  729    0.135254\n",
      "29  181  745  371    0.134521\n",
      "30   78  591  258    0.134033\n",
      "31  121  744  421    0.130249\n",
      "32  159  591  576    0.128784\n",
      "33  149  570  390    0.128418\n",
      "34  153  366  669    0.128052\n",
      "35  193  437  412    0.124023\n",
      "36  153  765  268    0.122925\n",
      "37  126   47  873    0.121826\n",
      "38  208  642  534    0.119690\n",
      "39  171  929  125    0.113403\n",
      "40  124  684  484    0.111694\n",
      "41  144  284  484    0.111023\n",
      "42  172  479  401    0.111023\n",
      "43    6  930  104    0.110352\n",
      "44  155  683  269    0.108032\n",
      "45    0  919  145    0.103455\n",
      "46  164  560  380    0.103455\n",
      "47  156  786  279    0.102783\n",
      "48  131  735  391    0.101196\n",
      "49  133   46  864    0.101196\n",
      "50  144  294  485    0.098694\n",
      "51  131  734  402    0.095947\n",
      "52  256  458  719    0.094788\n",
      "53  131  663  258    0.094177\n",
      "\n",
      "tomo_081a2d total infer time: 24.362682819366455\n",
      "False False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "0\n",
      "        z   y    x  confidence  i_model\n",
      "2531  154  46  854    0.736328        0\n",
      "True False\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Prepping\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "Processing tomogram tomo_08446f (1/1)\n",
      "Processing 500 out of 500 slices (CONCENTRATION=1)\n",
      "1\n",
      "         z    y    x  confidence  i_model\n",
      "10349  171  627  571    0.075439        0\n",
      "        z    y    x  confidence  i_model\n",
      "0      12   54  821    0.163940        0\n",
      "1      13   54  813    0.167725        0\n",
      "2      17   54  805    0.208130        0\n",
      "3      19   53  796    0.187744        0\n",
      "4      19   53  804    0.182983        0\n",
      "...   ...  ...  ...         ...      ...\n",
      "3773  496    8  249    0.015541        1\n",
      "3774  497  165  111    0.015778        1\n",
      "3775  498   83  144    0.017776        1\n",
      "3776  498   84  152    0.016983        1\n",
      "3777  499   84  152    0.016022        1\n",
      "\n",
      "[3778 rows x 5 columns]\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   154   46  854    0.368164\n",
      "1   297   53  878    0.276855\n",
      "2   314   70  919    0.267090\n",
      "3   279   54  846    0.249023\n",
      "4    82   54  878    0.248047\n",
      "5   228  135  806    0.185059\n",
      "6   119   54  822    0.178345\n",
      "7   268  882  853    0.167725\n",
      "8    49   70  902    0.153687\n",
      "9    40   62  911    0.148682\n",
      "10  308   53  918    0.143433\n",
      "11   61   62  886    0.139160\n",
      "12  249  866  147    0.132202\n",
      "13   42   86  821    0.131104\n",
      "14  220  143  789    0.130615\n",
      "15  189   46  821    0.127686\n",
      "16  211  144  903    0.123291\n",
      "17  483  525  870    0.122192\n",
      "18  449  890  781    0.121094\n",
      "19  278   86  829    0.109985\n",
      "20   42   14  846    0.109680\n",
      "21   17   54  805    0.104065\n",
      "22  343   53  853    0.103760\n",
      "23  174   54  895    0.103455\n",
      "24   36   53  804    0.097778\n",
      "25  224  889  585    0.094788\n",
      "26  294  914  522    0.091187\n",
      "27  341   69  934    0.090942\n",
      "28  225  217  854    0.090027\n",
      "29  276   53  894    0.086914\n",
      "30   76   38  788    0.084961\n",
      "31  352   13  935    0.083862\n",
      "32  477  842  773    0.081970\n",
      "33  306   53  903    0.081177\n",
      "34  198   37  813    0.080688\n",
      "35  204   70  894    0.079102\n",
      "36  224  298  886    0.075989\n",
      "37  222  257  862    0.075500\n",
      "38  231   46  886    0.074524\n",
      "\n",
      "tomo_08446f total infer time: 41.35368084907532\n",
      "       z    y    x  confidence  i_model\n",
      "0      0  940  851    0.765625        0\n",
      "1      0  929  851    0.637695        0\n",
      "2      0  941  845    0.532227        0\n",
      "3      0  949  851    0.524414        0\n",
      "4      0  930  845    0.394287        0\n",
      "..   ...  ...  ...         ...      ...\n",
      "711  293  941  216    0.197388        0\n",
      "712  294  948  217    0.339844        0\n",
      "713  294  941  217    0.280518        0\n",
      "714  295  948  217    0.264404        0\n",
      "715  295  941  217    0.222656        0\n",
      "\n",
      "[716 rows x 5 columns]\n",
      "       z    y    x  confidence  i_model\n",
      "0     12   54  821    0.163940        0\n",
      "1     13   54  813    0.167725        0\n",
      "2     17   54  805    0.208130        0\n",
      "3     19   53  796    0.187744        0\n",
      "4     19   53  804    0.182983        0\n",
      "..   ...  ...  ...         ...      ...\n",
      "286  449  898  781    0.182373        0\n",
      "287  449  882  781    0.172729        0\n",
      "288  477  842  773    0.163940        0\n",
      "289  483  525  870    0.244385        0\n",
      "290  483  533  870    0.214722        0\n",
      "\n",
      "[291 rows x 5 columns]\n",
      "[   index    z    y    x  confidence     value\n",
      "0      0  265  940  422    0.467773  0.467773, Empty DataFrame\n",
      "Columns: [index, z, y, x, confidence, value]\n",
      "Index: []]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(flg_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#flg_test.test_yolo(update_reference=True)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mflg_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:126\u001b[0m, in \u001b[0;36mrun_all_tests\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_tests\u001b[39m(update_reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 126\u001b[0m     \u001b[43mtest_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     test_unet(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)\n\u001b[0;32m    128\u001b[0m     test_unet_alt(update_reference\u001b[38;5;241m=\u001b[39mupdate_reference)    \n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:121\u001b[0m, in \u001b[0;36mtest_yolo\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(train_data, fls\u001b[38;5;241m.\u001b[39mload_all_train_data()[\u001b[38;5;241m216\u001b[39m:\u001b[38;5;241m230\u001b[39m])\n\u001b[0;32m    120\u001b[0m fls\u001b[38;5;241m.\u001b[39mdill_save(fls\u001b[38;5;241m.\u001b[39mtemp_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo_test.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[1;32m--> 121\u001b[0m \u001b[43mtest_yolo_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupdate_reference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_test.py:98\u001b[0m, in \u001b[0;36mtest_yolo_infer\u001b[1;34m(update_reference)\u001b[0m\n\u001b[0;32m     96\u001b[0m     fls\u001b[38;5;241m.\u001b[39mdill_save(ref_name, res)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(fls\u001b[38;5;241m.\u001b[39mdill_load(ref_name))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(flg_test)\n",
    "#flg_test.test_yolo(update_reference=True)\n",
    "flg_test.run_all_tests(update_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c3ba-6c07-4761-ad4f-c3078a3a57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_support as fls\n",
    "ref_name = fls.code_dir + 'ref_yolo.pickle';\n",
    "str(fls.dill_load(ref_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b4516-35a7-4a48-a757-26033301e074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
