{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678610de-f917-4276-86b8-9b468fc9adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#    raise 'stop'\n",
    "if not os.path.isdir('d:/flagellar/'):\n",
    "    deps_path = '/kaggle/usr/lib/flg_packages/'\n",
    "    !pip install --no-index --find-links {deps_path} --requirement {deps_path}/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9293528b-c494-4367-a5fe-13823c45c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/kaggle/code/core')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_support as fls\n",
    "import flg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89a01db-05de-429b-85df-4fbc9e640029",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = flg_model.ThreeStepModel()\n",
    "model.step1Heatmap = fls.dill_load(fls.model_dir + 'model_cv.pickle')\n",
    "model.run_in_parallel = False\n",
    "model.train(fls.load_all_train_data()) # dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d209f5-db85-4cc2-9da6-bdd3bc62ac9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = fls.load_all_test_data()\n",
    "if len(test_data)>3:\n",
    "    test_data = test_data\n",
    "else:\n",
    "    test_data = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8bfaf7-dfb5-4555-83ae-c8f2365f4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cupy\n",
      "[((0, 256), (0, 192), (0, 192)), ((128, 384), (64, 192), (192, 320)), ((244, 500), (64, 256), (308, 500))]\n",
      "[((0, 256), (0, 192), (0, 192)), ((128, 384), (64, 192), (192, 320)), ((256, 512), (64, 192), (320, 448)), ((384, 640), (64, 192), (448, 576)), ((512, 768), (64, 192), (576, 704)), ((640, 896), (64, 192), (704, 832)), ((768, 1024), (64, 192), (832, 960)), ((896, 1152), (64, 192), (960, 1088)), ((1024, 1280), (64, 192), (1088, 1216)), ((1152, 1408), (64, 192), (1216, 1344)), ((1280, 1536), (64, 192), (1344, 1472)), ((1408, 1664), (64, 192), (1472, 1600)), ((1536, 1792), (64, 192), (1600, 1728)), ((1656, 1912), (64, 256), (1720, 1912))]\n",
      "[((0, 256), (0, 192), (0, 192)), ((128, 384), (64, 192), (192, 320)), ((256, 512), (64, 192), (320, 448)), ((384, 640), (64, 192), (448, 576)), ((512, 768), (64, 192), (576, 704)), ((640, 896), (64, 192), (704, 832)), ((768, 1024), (64, 192), (832, 960)), ((896, 1152), (64, 192), (960, 1088)), ((1024, 1280), (64, 192), (1088, 1216)), ((1152, 1408), (64, 192), (1216, 1344)), ((1280, 1536), (64, 192), (1344, 1472)), ((1408, 1664), (64, 192), (1472, 1600)), ((1536, 1792), (64, 192), (1600, 1728)), ((1591, 1847), (64, 256), (1655, 1847))]\n",
      "torch.Size([500, 1912, 1847])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.58 GiB. GPU 0 has a total capacity of 11.99 GiB of which 4.16 GiB is free. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 3.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_support.py:390\u001b[0m, in \u001b[0;36mModel.infer\u001b[1;34m(self, test_data)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m test_data:\n\u001b[0;32m    389\u001b[0m     t\u001b[38;5;241m.\u001b[39mlabels  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m--> 390\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m test_data:\n\u001b[0;32m    392\u001b[0m     t\u001b[38;5;241m.\u001b[39mcheck_constraints()\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_support.py:410\u001b[0m, in \u001b[0;36mModel._infer\u001b[1;34m(self, test_data)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m was_loaded: x\u001b[38;5;241m.\u001b[39mload_to_memory()\n\u001b[0;32m    409\u001b[0m profile_print(x\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m loading: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt))\n\u001b[1;32m--> 410\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m was_loaded: x\u001b[38;5;241m.\u001b[39munload()\n\u001b[0;32m    412\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_model.py:102\u001b[0m, in \u001b[0;36mThreeStepModel._infer_single\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_infer_single\u001b[39m(\u001b[38;5;28mself\u001b[39m,data):\n\u001b[1;32m--> 102\u001b[0m     heatmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep1Heatmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     data\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep2Labels\u001b[38;5;241m.\u001b[39mmake_labels(heatmap)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_after_step2 \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_support.py:194\u001b[0m, in \u001b[0;36mprofile_each_line\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_each_line\u001b[39m(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profiling:\n\u001b[1;32m--> 194\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m     profiler \u001b[38;5;241m=\u001b[39m LineProfiler()\n\u001b[0;32m    196\u001b[0m     profiled_func \u001b[38;5;241m=\u001b[39m profiler(func)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_unet.py:304\u001b[0m, in \u001b[0;36mUNetModel.infer\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    302\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_probablity_map\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcombined_probablity_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.58 GiB. GPU 0 has a total capacity of 11.99 GiB of which 4.16 GiB is free. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 3.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inferred_data = model.infer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae048a08-eea9-4481-8140-7dd9ed1298be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferred_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fls\u001b[38;5;241m.\u001b[39mwrite_submission_file(\u001b[43minferred_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inferred_data' is not defined"
     ]
    }
   ],
   "source": [
    "fls.write_submission_file(inferred_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
