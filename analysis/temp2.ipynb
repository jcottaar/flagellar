{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b4b630-bd17-4d7f-97ef-001707dcf970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x27dfd626f80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flg-library/')\n",
    "import flg_support as fls\n",
    "import importlib\n",
    "import numpy as np\n",
    "import flg_diagnostics\n",
    "import flg_numerics\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import copy\n",
    "import flg_preprocess\n",
    "import os\n",
    "import flg_model\n",
    "fls.profiling=False\n",
    "plt.scatter([0,1],[1,2])\n",
    "#fls.download_kaggle_dataset('jeroencottaar/byu-many-models-3/', fls.result_dir + '/many_full_res/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758650f7-df3d-4e50-857a-b8d2c213fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 2001, 'n_ensemble': 1, 'n_epochs': 31, 'use_best_epoch': False, 'lr0': 0.0007852718891746083, 'cos_lr': True, 'mosaic': 1.0, 'concentration': 1, 'extra_data': True, 'trust_neg': 1, 'trust_extra': 1, 'model_name': 'yolov8s', 'use_pretrained_weights': False}\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(fls.result_dir + 'many_full_res/Baseline_2001_*')\n",
    "assert len(files)==1\n",
    "loaded_data = fls.dill_load(files[0])\n",
    "test_data = loaded_data.test_data\n",
    "print(loaded_data.modifier_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fb3b89-48ff-49e0-8bad-9e9183f449ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tomo_512f98', 'tomo_d0d9b6', 'tomo_53c71b', 'tomo_bcb115', 'tomo_1da0da', 'tomo_e1a034', 'tomo_b8595d', 'tomo_47d380', 'tomo_b4d9da', 'tomo_e764a7', 'tomo_04d42b', 'tomo_285454', 'tomo_f1bf2f', 'tomo_ac9fef', 'tomo_1fb6a7', 'tomo_b28579', 'tomo_91031e', 'tomo_b9de3e', 'tomo_35ec84', 'tomo_e9b7f2', 'tomo_bb5ac1', 'tomo_db6051', 'tomo_fe85f6', 'tomo_fd41c4', 'tomo_4f5a7b', 'tomo_499ee0', 'tomo_646049', 'tomo_e9fa5f', 'tomo_9ae65f', 'tomo_aeaf51']\n"
     ]
    }
   ],
   "source": [
    "print([d.name for d in test_data[:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeca404-9616-43a5-9bbf-23c3cb2f33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cupy\n",
      "YOLOv8s summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0      0  458  431  648    0.211426        0\n",
      "------------------\n",
      "------------------\n",
      "    index   z    y    x  confidence  i_model\n",
      "0       1  63  121  524    0.196167        0\n",
      "1       2  67  124  529    0.194336        0\n",
      "2       3  62  120  523    0.184814        0\n",
      "3       4  65  124  527    0.181274        0\n",
      "4       6  64  124  524    0.172729        0\n",
      "..    ...  ..  ...  ...         ...      ...\n",
      "63    129  63  119  531    0.046906        0\n",
      "64    135  75  119  530    0.045868        0\n",
      "65    137  64  115  527    0.045532        0\n",
      "66    143  55  125  521    0.044006        0\n",
      "67    145  65  114  528    0.043518        0\n",
      "\n",
      "[68 rows x 6 columns]\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0      5  119  376  536    0.176636        0\n",
      "------------------\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       7  540  368  505    0.167725        0\n",
      "1       9  535  372  512    0.159180        0\n",
      "2      11  535  376  511    0.140869        0\n",
      "3      19  541  369  506    0.119202        0\n",
      "4      24  536  380  510    0.112793        0\n",
      "5      28  535  367  513    0.102295        0\n",
      "6      30  536  375  511    0.101929        0\n",
      "7      31  541  367  510    0.101562        0\n",
      "8      32  533  378  511    0.100891        0\n",
      "9      39  540  367  509    0.086914        0\n",
      "10     59  534  378  511    0.071350        0\n",
      "11     60  540  376  505    0.070557        0\n",
      "12     77  541  377  505    0.063049        0\n",
      "13    113  541  367  504    0.050903        0\n",
      "14    114  536  369  508    0.050720        0\n",
      "15    118  541  376  509    0.048859        0\n",
      "16    120  534  372  509    0.048676        0\n",
      "17    128  535  363  509    0.047089        0\n",
      "18    134  539  369  507    0.046021        0\n",
      "19    140  535  370  505    0.045197        0\n",
      "20    141  544  367  505    0.044678        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z   y    x  confidence  i_model\n",
      "0     10  716  84  386    0.149536        0\n",
      "1     13  720  83  389    0.133911        0\n",
      "2     20  719  85  390    0.118774        0\n",
      "3     29  717  87  386    0.102295        0\n",
      "4     33  720  85  393    0.096375        0\n",
      "5     43  715  85  386    0.082397        0\n",
      "6    125  718  85  390    0.047607        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     16  626  326  621    0.131226        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     17  113  204  147    0.130737        0\n",
      "1     21  113  207  146    0.115540        0\n",
      "2     25  113  211  142    0.110107        0\n",
      "3     46  113  214  136    0.080078        0\n",
      "4     90  115  224  129    0.058777        0\n",
      "5     92  113  203  155    0.058563        0\n",
      "6    101  113  219  130    0.054413        0\n",
      "7    110  113  199  149    0.051270        0\n",
      "8    150  115  221  133    0.042389        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     18  296  589  686    0.125977        0\n",
      "1     51  296  590  690    0.073669        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     26  650  359  469    0.107056        0\n",
      "1     53  647  358  471    0.072876        0\n",
      "2    126  651  360  469    0.047424        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     34  576  355  236     0.09436        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     36  101  246  556    0.091736        0\n",
      "1    116  102  246  554    0.049591        0\n",
      "2    130  101  241  553    0.046722        0\n",
      "3    146  100  246  556    0.043213        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     49  160  250  629    0.074524        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     61  673  492  413    0.070312        0\n",
      "1     87  672  492  419    0.059418        0\n",
      "2    108  673  491  418    0.051666        0\n",
      "3    109  672  492  413    0.051453        0\n",
      "4    147  669  493  419    0.043213        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     62  600  348  469    0.070068        0\n",
      "1     66  599  348  471    0.068298        0\n",
      "2     85  591  349  474    0.059875        0\n",
      "3     97  592  349  473    0.056030        0\n",
      "4    107  590  349  473    0.051666        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     73  574  418  286    0.064392        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     75  670  373  468    0.063965        0\n",
      "1     78  670  376  465    0.061646        0\n",
      "------------------\n",
      "------------------\n",
      "   index   z    y    x  confidence  i_model\n",
      "0     76   9  116  456    0.063477        0\n",
      "1    104   9  115  451    0.053009        0\n",
      "2    111   9  117  461    0.050903        0\n",
      "3    127   9  110  449    0.047241        0\n",
      "4    131  10  116  458    0.046204        0\n",
      "5    138   9  111  455    0.045349        0\n",
      "6    139  11  116  458    0.045349        0\n",
      "7    142   9  120  459    0.044189        0\n",
      "8    144  11  115  450    0.043854        0\n",
      "9    149  10  116  464    0.042389        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     84  130  122  600    0.059875        0\n",
      "1     86  131  123  600    0.059418        0\n",
      "2    136  130  120  595    0.045685        0\n",
      "------------------\n",
      "------------------\n",
      "   index   z    y    x  confidence  i_model\n",
      "0     99  36  117  502    0.054596        0\n",
      "1    133  38  115  500    0.046021        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0    105  490  342  573    0.052826        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0    124  100  314  529    0.047607        0\n",
      "------------------\n",
      "------------------\n",
      "   index   z    y    x  confidence  i_model\n",
      "0    132  30  119  482    0.046021        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0    148  681  422  697    0.042725        0\n",
      "------------------\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   458  431  648    0.211426\n",
      "1    63  121  524    0.196167\n",
      "2   119  376  536    0.176636\n",
      "3   540  368  505    0.167725\n",
      "4   716   84  386    0.149536\n",
      "5   626  326  621    0.131226\n",
      "6   113  204  147    0.130737\n",
      "7   296  589  686    0.125977\n",
      "8   650  359  469    0.107056\n",
      "9   576  355  236    0.094360\n",
      "10  101  246  556    0.091736\n",
      "11  160  250  629    0.074524\n",
      "12  673  492  413    0.070312\n",
      "13  600  348  469    0.070068\n",
      "14  574  418  286    0.064392\n",
      "15  670  373  468    0.063965\n",
      "16    9  116  456    0.063477\n",
      "17  130  122  600    0.059875\n",
      "18   36  117  502    0.054596\n",
      "19  490  342  573    0.052826\n",
      "20  100  314  529    0.047607\n",
      "21   30  119  482    0.046021\n",
      "22  681  422  697    0.042725\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_d0d9b6 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       0  422  293  835    0.578613        0\n",
      "1       1  414  290  835    0.530273        0\n",
      "2       2  423  292  837    0.507812        0\n",
      "3       3  421  293  835    0.488281        0\n",
      "4       4  413  290  835    0.486328        0\n",
      "5       5  424  292  837    0.467773        0\n",
      "6       6  411  290  835    0.403564        0\n",
      "7       7  415  290  834    0.402588        0\n",
      "8       8  425  293  837    0.365723        0\n",
      "9       9  412  290  834    0.342529        0\n",
      "10     10  420  294  835    0.285400        0\n",
      "11     18  416  290  834    0.134277        0\n",
      "12     20  419  291  835    0.121704        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     11  479  288  827    0.235107        0\n",
      "1     14  480  288  827    0.152588        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     12  445  284  826    0.181885        0\n",
      "1     13  446  285  826    0.160278        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z   y   x  confidence  i_model\n",
      "0     15  249  10  69    0.145630        0\n",
      "1     19  250  10  69    0.122498        0\n",
      "------------------\n",
      "------------------\n",
      "   index  z    y    x  confidence  i_model\n",
      "0     16  6  918  258    0.142700        0\n",
      "1     17  7  918  257    0.137085        0\n",
      "2     22  7  919  252    0.115967        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     21  528  287  750    0.119629        0\n",
      "------------------\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  422  293  835    0.578613\n",
      "1  479  288  827    0.235107\n",
      "2  445  284  826    0.181885\n",
      "3  249   10   69    0.145630\n",
      "4    6  918  258    0.142700\n",
      "5  528  287  750    0.119629\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_53c71b (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       0  421  280  506    0.293457        0\n",
      "1       1  408  283  515    0.260498        0\n",
      "2       2  409  283  514    0.257568        0\n",
      "3       3  411  285  511    0.250977        0\n",
      "4       7  410  282  511    0.212036        0\n",
      "5       8  421  277  508    0.202393        0\n",
      "6      11  422  276  507    0.166138        0\n",
      "7      12  412  286  510    0.156128        0\n",
      "8      13  409  281  510    0.142212        0\n",
      "9      14  416  281  511    0.131226        0\n",
      "10     15  408  282  511    0.129883        0\n",
      "11     17  412  282  509    0.126831        0\n",
      "12     18  407  282  515    0.125488        0\n",
      "13     19  415  281  510    0.125488        0\n",
      "14     20  423  273  506    0.122498        0\n",
      "15     23  426  272  505    0.116333        0\n",
      "16     25  406  280  511    0.110840        0\n",
      "17     26  422  281  505    0.105591        0\n",
      "18     27  406  281  516    0.104858        0\n",
      "19     28  414  283  511    0.104858        0\n",
      "20     29  422  279  508    0.099121        0\n",
      "21     32  418  280  509    0.096680        0\n",
      "22     35  426  277  505    0.096375        0\n",
      "23     42  418  276  508    0.088196        0\n",
      "24     43  407  279  511    0.087891        0\n",
      "25     48  425  274  505    0.077515        0\n",
      "26     49  425  282  502    0.077515        0\n",
      "27     53  423  278  506    0.074524        0\n",
      "28     55  421  272  510    0.073425        0\n",
      "29     56  425  279  505    0.072876        0\n",
      "30     58  420  279  507    0.072083        0\n",
      "31     61  424  273  505    0.070801        0\n",
      "32     62  421  273  505    0.067810        0\n",
      "33     66  420  274  509    0.065125        0\n",
      "34     71  413  284  510    0.063232        0\n",
      "35     76  413  280  509    0.059662        0\n",
      "------------------\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       4  487  330  524    0.250244        0\n",
      "1       6  486  331  522    0.221313        0\n",
      "2       9  488  328  521    0.186523        0\n",
      "3      10  484  329  531    0.169922        0\n",
      "4      21  486  339  518    0.120422        0\n",
      "5      22  484  333  526    0.119202        0\n",
      "6      24  485  334  521    0.115540        0\n",
      "7      31  495  319  523    0.098083        0\n",
      "8      33  485  328  527    0.096680        0\n",
      "9      34  488  321  520    0.096680        0\n",
      "10     36  488  324  517    0.092346        0\n",
      "11     39  485  339  519    0.089111        0\n",
      "12     40  488  330  517    0.088806        0\n",
      "13     41  487  338  521    0.088501        0\n",
      "14     44  483  328  531    0.083313        0\n",
      "15     46  488  324  522    0.078918        0\n",
      "16     47  486  322  524    0.078064        0\n",
      "17     50  487  323  524    0.075867        0\n",
      "18     51  483  326  535    0.075562        0\n",
      "19     52  486  331  517    0.074768        0\n",
      "20     57  489  333  518    0.072388        0\n",
      "21     59  484  327  535    0.071838        0\n",
      "22     60  484  324  538    0.071350        0\n",
      "23     63  484  339  523    0.067078        0\n",
      "24     64  485  319  531    0.066101        0\n",
      "25     65  483  321  536    0.065613        0\n",
      "26     68  488  340  518    0.064636        0\n",
      "27     70  483  323  539    0.063477        0\n",
      "28     73  487  334  519    0.062103        0\n",
      "29     74  489  326  520    0.060974        0\n",
      "30     77  485  318  526    0.059418        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0      5  337  342  621    0.248047        0\n",
      "1     37  336  344  623    0.090393        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     16  441  285  489    0.127686        0\n",
      "1     45  441  290  489    0.080933        0\n",
      "2     54  439  290  489    0.073669        0\n",
      "3     67  441  281  488    0.064880        0\n",
      "4     69  442  284  490    0.064209        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     30  221  783  624    0.098083        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     38  263  752  240    0.090088        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     72  319  840  183    0.062805        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     75  463  281  510     0.06076        0\n",
      "------------------\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  421  280  506    0.293457\n",
      "1  487  330  524    0.250244\n",
      "2  337  342  621    0.248047\n",
      "3  441  285  489    0.127686\n",
      "4  221  783  624    0.098083\n",
      "5  263  752  240    0.090088\n",
      "6  319  840  183    0.062805\n",
      "7  463  281  510    0.060760\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_bcb115 (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       0  190  512  327    0.376709        0\n",
      "1       1  189  512  327    0.349609        0\n",
      "2       2  191  512  326    0.186523        0\n",
      "3       3  188  512  327    0.175537        0\n",
      "4       4  192  512  326    0.146606        0\n",
      "5       5  190  514  325    0.144653        0\n",
      "6       6  191  515  322    0.137939        0\n",
      "7       8  192  516  321    0.125977        0\n",
      "8       9  188  517  323    0.113953        0\n",
      "9      10  192  512  322    0.102661        0\n",
      "10     12  189  516  324    0.087585        0\n",
      "------------------\n",
      "------------------\n",
      "   index   z    y    x  confidence  i_model\n",
      "0      7  14  801  259    0.134766        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     11  102  620  373    0.098755        0\n",
      "------------------\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  190  512  327    0.376709\n",
      "1   14  801  259    0.134766\n",
      "2  102  620  373    0.098755\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_1da0da (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "------------------\n",
      "    index    z    y    x  confidence  i_model\n",
      "0       0  373  447  247    0.645020        0\n",
      "1       1  374  446  247    0.617676        0\n",
      "2       2  372  447  247    0.601074        0\n",
      "3       3  364  444  252    0.596191        0\n",
      "4       4  365  445  252    0.584961        0\n",
      "5       6  363  446  252    0.558105        0\n",
      "6       7  366  445  249    0.554688        0\n",
      "7       8  370  445  249    0.544922        0\n",
      "8       9  362  447  252    0.519531        0\n",
      "9      10  375  445  246    0.519531        0\n",
      "10     11  361  446  253    0.490234        0\n",
      "11     12  360  445  255    0.455078        0\n",
      "12     13  369  445  249    0.432129        0\n",
      "13     14  359  445  255    0.430176        0\n",
      "14     15  367  446  249    0.428223        0\n",
      "15     16  371  447  246    0.413086        0\n",
      "16     17  368  445  248    0.410156        0\n",
      "17     18  358  447  256    0.295898        0\n",
      "18     22  357  448  257    0.220703        0\n",
      "19     24  361  445  248    0.201172        0\n",
      "20     26  362  444  248    0.160278        0\n",
      "21     28  367  447  244    0.129395        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0      5  430  719  671    0.566895        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     19  379  552  280    0.237915        0\n",
      "1     21  376  550  283    0.228149        0\n",
      "2     25  378  552  281    0.196777        0\n",
      "3     27  377  550  281    0.145142        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     20  417  482  244    0.228882        0\n",
      "------------------\n",
      "------------------\n",
      "   index    z    y    x  confidence  i_model\n",
      "0     23  406  450  236    0.202393        0\n",
      "------------------\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  373  447  247    0.645020\n",
      "1  430  719  671    0.566895\n",
      "2  379  552  280    0.237915\n",
      "3  417  482  244    0.228882\n",
      "4  406  450  236    0.202393\n",
      "\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_e1a034 (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n"
     ]
    }
   ],
   "source": [
    "highest_false_score = []\n",
    "real_score = []\n",
    "data_list = []\n",
    "for i_type in range(2):\n",
    "    base_model = copy.deepcopy(loaded_data.trained_model)\n",
    "    #base_model.step1Labels.n_ensemble=1\n",
    "    #base_model.step1Labels.trained_model = base_model.step1Labels.trained_model[0:1]\n",
    "    base_model.step1Labels.concentration = 2\n",
    "    base_model.run_in_parallel=False\n",
    "    model = base_model\n",
    "    #model.step1Labels.n_epochs = 2\n",
    "    #m.step2Motors.distance_threshold = 10.\n",
    "    # if i_type == 0:\n",
    "    #     # baseline\n",
    "    #     pass     \n",
    "    # elif i_type==1:\n",
    "    #     # other seed\n",
    "    #     model.step1Labels.trained_model = loaded_data.trained_model.step1Labels.trained_model[1:2]\n",
    "    # elif i_type==2:\n",
    "    #     model.step1Labels.preprocessor.voxel_scale = 0.9\n",
    "    # elif i_type==3:\n",
    "    #     model.step1Labels.preprocessor.voxel_scale = 0.8\n",
    "    # elif i_type==4:\n",
    "    #     model.step1Labels.preprocessor.blur_xy *= 0.8\n",
    "    # elif i_type==5:\n",
    "    #     model.step1Labels.preprocessor.blur_xy *= 1.2   \n",
    "    # elif i_type==6:\n",
    "    #     model.step1Labels.preprocessor.clip_value = 2.5\n",
    "    # elif i_type==7:\n",
    "    #     model.step1Labels.preprocessor.clip_value = 3.5\n",
    "    # elif i_type==8:\n",
    "    #     model.step1Labels.preprocessor.apply_transpose = True\n",
    "    # elif i_type==9:\n",
    "    #     model.step1Labels.preprocessor.apply_flipud = True\n",
    "    if i_type == 0:\n",
    "        # conc1\n",
    "        model.step1Labels.concentration = 1     \n",
    "    elif i_type==1:\n",
    "        # conc2\n",
    "        model.step1Labels.concentration = 2\n",
    "    elif i_type==2:\n",
    "        model.step1Labels.concentration = 1\n",
    "        model.step1Labels.n_ensemble = 1\n",
    "        model.step1Labels.trained_model = model.step1Labels.trained_model[0:1]\n",
    "    elif i_type==3:\n",
    "        model.step1Labels.concentration = 2\n",
    "        model.step1Labels.n_ensemble = 1\n",
    "        model.step1Labels.trained_model = model.step1Labels.trained_model[0:1]\n",
    "    #model.step1Labels.relative_confidence_threshold = 0.01\n",
    "    data_file = fls.temp_dir + 'data_tta_' + str(i_type) + '.pickle'    \n",
    "    if not os.path.isfile(data_file):        \n",
    "        inferred_data = model.infer(test_data)\n",
    "        #for d in inferred_data:\n",
    "        #    d.labels_unfiltered = d.labels_unfiltered2 \n",
    "        fls.mark_tf_pn(inferred_data, test_data)\n",
    "        fls.dill_save(data_file, inferred_data)        \n",
    "    inferred_data = fls.dill_load(data_file)       \n",
    "    data_list.append(inferred_data)\n",
    "    this_highest_false_score = []\n",
    "    this_real_score = []\n",
    "    for i,r in zip(inferred_data, test_data):\n",
    "        false_positives = i.labels_unfiltered[i.labels_unfiltered['tf_pn']==1.]\n",
    "        if len(false_positives)>0:\n",
    "            this_highest_false_score.append(np.max(false_positives['confidence']))\n",
    "        else:\n",
    "            this_highest_false_score.append(0)\n",
    "        if len(r.labels)>0:\n",
    "            true_positives = i.labels_unfiltered[i.labels_unfiltered['tf_pn']==0.]\n",
    "            #print(true_positives)\n",
    "            if len(true_positives)>0:\n",
    "                this_real_score.append(np.max(true_positives['confidence']))\n",
    "            else:\n",
    "                this_real_score.append(0)\n",
    "    highest_false_score.append(this_highest_false_score)\n",
    "    real_score.append(this_real_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656287a8-0969-4cf8-a03d-3c9e7bdbaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_list:\n",
    "    n_corr=0\n",
    "    n_total=0\n",
    "    for i,r in zip(d,test_data):\n",
    "        if len(r.labels)>0:# and 'tom' in r.name:\n",
    "            n_total+=1\n",
    "            ind = np.argmax(i.labels_unfiltered['confidence'])\n",
    "            if (i.labels_unfiltered['tf_pn'].tolist()[ind])==0.:\n",
    "                n_corr += 1\n",
    "    print(n_corr/n_total)\n",
    "    #print(i.labels_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586a6b9-0f48-42c1-91a0-f3bbdb3b745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_baseline = 1\n",
    "for i_new in np.arange(1,len(highest_false_score)):\n",
    "    _,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "    plt.sca(ax[0])\n",
    "    plt.scatter(highest_false_score[i_baseline], highest_false_score[i_new])\n",
    "    plt.xlabel('Highest false score baseline')\n",
    "    plt.ylabel('Highest false score new')\n",
    "    plt.grid(True)\n",
    "    plt.axline((0,0),slope=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.scatter(real_score[i_baseline], real_score[i_new])\n",
    "    plt.xlabel('True score baseline')\n",
    "    plt.ylabel('True score new')\n",
    "    plt.grid(True)\n",
    "    plt.axline((0,0),slope=1)\n",
    "    plt.suptitle(str(i_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564ee93-8dd1-488f-83f4-49b9910ad43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=(np.argwhere(np.logical_and(np.array(real_score[0])>0.6, np.array(real_score[2])<0.05))).flatten()\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a071036-784f-4c6f-af09-a4fb8b0d3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_id = 0\n",
    "for ii in range(len(test_data)):\n",
    "    if len(test_data[ii].labels)>0:     \n",
    "        if cur_id in xx:\n",
    "            print(test_data[ii].name,ii,real_score[i_baseline][cur_id],real_score[i_new][cur_id])\n",
    "        cur_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab11153-dc13-40cf-9663-596e34d8690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest_false_score.append( (np.array(highest_false_score[0])+np.array(highest_false_score[-1])) /2)\n",
    "# real_score.append( (np.array(real_score[0])+np.array(real_score[-1])) /2)\n",
    "#highest_false_score.append( [min(a,b) for a,b in zip(highest_false_score[0],highest_false_score[-1])])\n",
    "#real_score.append( [min(a,b) for a,b in zip(real_score[0],real_score[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d0653-c667-4548-8d16-54b256b44eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i_baseline = 0\n",
    "for i_new in np.arange(1,len(highest_false_score)):\n",
    "    # flatten the two arrays into one to get global bin edges\n",
    "    all_scores = np.concatenate([highest_false_score[i_baseline], highest_false_score[i_new]])\n",
    "    # choose number of bins (e.g. 30) or compute automatically\n",
    "    bins = np.histogram_bin_edges(all_scores, bins=30)\n",
    "    \n",
    "    _,ax=plt.subplots(1,2,figsize=(10, 5))\n",
    "    plt.sca(ax[0])\n",
    "    plt.hist(highest_false_score[i_baseline], bins=bins, cumulative=True, alpha=0.5, label='Original')\n",
    "    plt.hist(highest_false_score[i_new], bins=bins, cumulative=True, alpha=0.5, label='New')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('False (we want to see orange)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # flatten the two arrays into one to get global bin edges\n",
    "    all_scores = np.concatenate([real_score[i_baseline], real_score[i_new]])\n",
    "    # choose number of bins (e.g. 30) or compute automatically\n",
    "    bins = np.histogram_bin_edges(all_scores, bins=30)\n",
    "\n",
    "    plt.sca(ax[1])\n",
    "    plt.hist(real_score[i_baseline], bins=bins, cumulative=True, alpha=0.5, label='Original')\n",
    "    plt.hist(real_score[i_new], bins=bins, cumulative=True, alpha=0.5, label='New')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('True (we want to see blue)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.suptitle(str(i_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f197e-1e29-4fcc-acd7-51519c970130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46917a-1b76-4815-bb1f-54901e1aaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fp_fn(data, threshold_fp, threshold_fn):\n",
    "\n",
    "    all_data = fls.load_all_train_data() + fls.load_all_extra_data()\n",
    "    def visualize_slice(name, z,y,x, color, title_str):\n",
    "        for d in all_data:\n",
    "            if d.name == name:\n",
    "                break\n",
    "        else:\n",
    "            raise 'Not found'\n",
    "        d = copy.deepcopy(d)\n",
    "        prep = flg_preprocess.Preprocessor2()\n",
    "        prep.load_and_preprocess(d, desired_original_slices = [z])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(d.data[0,:,:], cmap='bone')\n",
    "        plt.colorbar()\n",
    "        plt.title(title_str + ': ' + name + ', ' + str(z))\n",
    "\n",
    "        plt.scatter([x*d.resize_factor], [y*d.resize_factor], alpha=0.3, color=color, s=200)\n",
    "    \n",
    "    for d in data:  \n",
    "        if not 'tom' in d.name:\n",
    "            continue\n",
    "        lab = copy.deepcopy(d.labels_unfiltered).reset_index()\n",
    "\n",
    "        # false negatives\n",
    "        if not np.any(np.logical_and(lab['tf_pn']==0., lab['confidence']>threshold_fn)):\n",
    "            for r in all_data:\n",
    "                if r.name == d.name:\n",
    "                    break\n",
    "            else:\n",
    "                raise 'Not found'\n",
    "            if len(r.labels)>0:\n",
    "                attempts = lab[lab['tf_pn']==0.]\n",
    "                if len(attempts)>0:\n",
    "                    thresh = np.max(attempts['confidence'])\n",
    "                else:\n",
    "                    thresh = 0.\n",
    "                visualize_slice(d.name, np.round(r.labels['z'][0]).astype(int),r.labels['y'][0],r.labels['x'][0], 'blue', 'False negative: '+str(thresh))\n",
    "\n",
    "        # false positives\n",
    "        slices_done = []\n",
    "        for i_row in range(len(lab)):\n",
    "            if lab['tf_pn'][i_row]==1. and lab['confidence'][i_row]>threshold_fp and lab['z'][i_row] not in slices_done:\n",
    "                #print('fp', d.name, lab['z'][i_row], lab['confidence'][i_row])\n",
    "                visualize_slice(d.name, lab['z'][i_row],lab['y'][i_row],lab['x'][i_row], 'red', 'False positive ' + str(lab['confidence'][i_row]))\n",
    "                for ii in np.arange(lab['z'][i_row]-10, lab['z'][i_row]+11):\n",
    "                    slices_done.append(ii)\n",
    "#visualize_fp_fn(data_list[i_new], 0.8, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697fca6-5d4e-4488-8173-df424248dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transpose in [False,True]:\n",
    "    prep = model.step1Labels.preprocessor\n",
    "    prep.apply_flipud = transpose\n",
    "    dat = copy.deepcopy(test_data[0])\n",
    "    prep.load_and_preprocess(dat)\n",
    "    plt.figure()\n",
    "    plt.imshow(dat.data[dat.data.shape[0]//2,...], cmap='bone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9e6e6-e73d-4a5c-a40d-627664324863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778bba7a-d312-4f8a-9964-1ac0317bd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_slice(data, z_list):\n",
    "    # preprocessor = copy.deepcopy(models[0].trained_model.step1Labels.preprocessor)\n",
    "    # #preprocessor.blur_z = 5\n",
    "    # preprocessor.blur_xy = 1\n",
    "    # preprocessor.scale_moving_average = True\n",
    "    # preprocessor.scale_also_moving_std = True\n",
    "    # #preprocessor.moving_ratio = 0.\n",
    "    # data = copy.deepcopy(data)\n",
    "    # preprocessor.load_and_preprocess(data, desired_original_slices = z_list)\n",
    "    # dat = []\n",
    "    # for mm in range(1):\n",
    "    #     m = copy.deepcopy(models[mm].trained_model)\n",
    "    #     m.step1Labels.preprocessor = preprocessor\n",
    "    #     m.step1Labels.relative_confidence_threshold = 0.001\n",
    "    #     m.step2Motors.distance_threshold = 10.\n",
    "    #     m.run_in_parallel = False\n",
    "    #     dat.append (m.infer([data])[0])\n",
    "    m = copy.deepcopy(base_model)\n",
    "    m.step1Labels.concentration = 1\n",
    "    #m.step1Labels.preprocessor.blur_z = 60\n",
    "    #m.step1Labels.img_size //= 4\n",
    "    m.step1Labels.relative_confidence_threshold = 0.01\n",
    "    #m.step1Labels.preprocessor.apply_transpose = True\n",
    "    #m.step1Labels.concentration = 2\n",
    "    #m.step1Labels.prevent_ultralytics_resize = True\n",
    "    m.run_in_parallel = False\n",
    "    dat = []\n",
    "    dat.append (m.infer([data])[0])\n",
    "    data = copy.deepcopy(data)\n",
    "    m.preprocessor.load_and_preprocess(data, desired_original_slices = z_list)\n",
    "    #m.step1Labels.n_ensemble = 1\n",
    "    #m.step1Labels.trained_model = m.step1Labels.trained_model[0:1]\n",
    "    for i_z,z in enumerate(data.slices_present):\n",
    "    #     if data.slices_present[i_z]==z:\n",
    "    #         break\n",
    "    # else:\n",
    "    #     raise 'stop'\n",
    "        plt.figure()\n",
    "        plt.imshow(data.data[i_z,:,:], cmap='bone')\n",
    "        plt.colorbar()\n",
    "        plt.title(data.name + ', ' + str(z))\n",
    "        for d in dat:\n",
    "            print(d.labels)\n",
    "            print(d.labels_unfiltered)\n",
    "            print(d.labels_unfiltered2)\n",
    "            assert d.name == data.name\n",
    "            to_plot = d.labels_unfiltered2\n",
    "        \n",
    "            to_plot = to_plot[to_plot['z']==z]\n",
    "            print('z: ', z)\n",
    "            print(to_plot)\n",
    "    \n",
    "            plt.scatter(data.resize_factor*to_plot['x'], data.resize_factor*to_plot['y'])\n",
    "#             #print(dat)    \n",
    "    # for mm in range(1):\n",
    "    #     # m = copy.deepcopy(models[mm].trained_model)\n",
    "    #     # m.step1Labels.relative_confidence_threshold = 0.01\n",
    "    #     # m.step2Motors.distance_threshold = 10.\n",
    "    #     # m.run_in_parallel = False\n",
    "    #     # dat = m.infer([data])\n",
    "    #     dat = models[mm].inferred_test_data\n",
    "    #     for d in dat:\n",
    "    #         if d.name == data.name:\n",
    "    #             to_plot = d.labels_unfiltered2\n",
    "            \n",
    "    #             to_plot = to_plot[to_plot['z']==z]\n",
    "    #             print(to_plot)\n",
    "        \n",
    "    #             plt.scatter(to_plot['x'], to_plot['y'])\n",
    "    #             #print(dat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487f607-d978-43a0-916b-13749b271701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flg_yolo2\n",
    "importlib.reload(flg_yolo2)\n",
    "for ind in [89]:\n",
    "    dat= data_list[0][ind]\n",
    "    print(dat.labels)\n",
    "    #if len(dat.labels)>0:\n",
    "    #    visualize_slice(dat, [dat.labels['z'][0]])\n",
    "    visualize_slice(dat, [539])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f5027-fb4c-42b9-a0ec-51a5893e02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceb533-1880-4e8d-91a3-a2888da7a131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
