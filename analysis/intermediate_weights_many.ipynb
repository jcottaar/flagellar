{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b4b630-bd17-4d7f-97ef-001707dcf970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAc00lEQVR4nO3df5DU9X348dcBYY9M79bQ9OBOzoAaayIWMRZ7QZtgSQ041zL9QyoJP6ImMcLESJvo1URi0wZ1bKZtimZiE0lGIiOOMBllMFSKNxAcB+VmJKipvbOQcHepSb09UE7hPt8/HO6bi5zcHrf79s7HY2b/2A+fj/vad4j79LOf3a3IsiwLAIBExqQeAAB4dxMjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQ1LjUAwxGb29vHDx4MKqqqqKioiL1OADAIGRZFt3d3VFXVxdjxgx8/mNExMjBgwejvr4+9RgAwBAcOHAgpkyZMuCfj4gYqaqqiog3n0x1dXXiaQCAwSgUClFfX9/3Oj6QEREjx9+aqa6uFiMAMMKc7BILF7ACAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASGpEfOkZADD8jvVm8VTbb+JX3UeipqoyZk2bGGPHlP834Io6M7J69er44z/+46iqqoqamppYsGBBvPDCCyc9bsOGDXHuuedGZWVlnH/++bF58+YhDwwAnLote9vjkju2xVX3Phk3rG+Jq+59Mi65Y1ts2dte9lmKipEnnngili9fHk8++WRs3bo13njjjfjzP//zOHz48IDH/PSnP42rrroqrrnmmtizZ08sWLAgFixYEHv37j3l4QGA4m3Z2x5fuP+ZaO860m97R9eR+ML9z5Q9SCqyLMuGevD//u//Rk1NTTzxxBPxp3/6pyfcZ+HChXH48OF45JFH+rb9yZ/8SVxwwQXxne98Z1CPUygUIp/PR1dXl9+mAYBTcKw3i0vu2PaWEDmuIiIm5ytjx02XnfJbNoN9/T6lC1i7uroiImLixIkD7rNr166YO3duv22XX3557Nq1a8Bjenp6olAo9LsBAKfuqbbfDBgiERFZRLR3HYmn2n5TtpmGHCO9vb3xpS99KWbPnh3Tp08fcL+Ojo6YNGlSv22TJk2Kjo6OAY9ZvXp15PP5vlt9ff1QxwQAfsuvugcOkaHsNxyGHCPLly+PvXv3xvr164dznoiIaGpqiq6urr7bgQMHhv0xAODdqKaqclj3Gw5D+mjvihUr4pFHHonm5uaYMmXK2+47efLk6Ozs7Lets7MzJk+ePOAxuVwucrncUEYDAN7GrGkTozZfGR1dR+JEF40ev2Zk1rSBL8EYbkWdGcmyLFasWBEbN26Mbdu2xbRp0056TENDQzz++OP9tm3dujUaGhqKmxQAOGVjx1TEqsYPR8Sb4fHbjt9f1fjhsn7fSFExsnz58rj//vvjRz/6UVRVVUVHR0d0dHTEa6+91rfPkiVLoqmpqe/+DTfcEFu2bIl/+qd/iueffz6+/vWvx+7du2PFihXD9ywAgEH75PTauOfTF8bkfP+3YibnK+OeT18Yn5xeW9Z5ivpob0XFiSvpvvvui2XLlkVExMc//vGYOnVqrF27tu/PN2zYEF/96lfjpZdeig9+8INx5513xvz58wc9pI/2AsDwK/U3sA729fuUvmekXMQIAIw8ZfmeEQCAUyVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqaJjpLm5ORobG6Ouri4qKipi06ZNJz1m3bp1MWPGjHjve98btbW1cfXVV8evf/3rocwLAIwyRcfI4cOHY8aMGbFmzZpB7b9z585YsmRJXHPNNfGzn/0sNmzYEE899VR89rOfLXpYAGD0GVfsAfPmzYt58+YNev9du3bF1KlT44tf/GJEREybNi0+//nPxx133FHsQwMAo1DJrxlpaGiIAwcOxObNmyPLsujs7IyHHnoo5s+fX+qHBgBGgJLHyOzZs2PdunWxcOHCGD9+fEyePDny+fzbvs3T09MThUKh3w0AGJ1KHiP79u2LG264IW699dZ4+umnY8uWLfHSSy/FddddN+Axq1evjnw+33err68v9ZgAQCIVWZZlQz64oiI2btwYCxYsGHCfxYsXx5EjR2LDhg1923bs2BGXXnppHDx4MGpra99yTE9PT/T09PTdLxQKUV9fH11dXVFdXT3UcQGAMioUCpHP50/6+l30BazFevXVV2PcuP4PM3bs2IiIGKiDcrlc5HK5Uo8GALwDFP02zaFDh6KlpSVaWloiIqKtrS1aWlpi//79ERHR1NQUS5Ys6du/sbExHn744bjnnnuitbU1du7cGV/84hdj1qxZUVdXNzzPAgAYsYo+M7J79+6YM2dO3/2VK1dGRMTSpUtj7dq10d7e3hcmERHLli2L7u7u+Ld/+7f4m7/5mzjttNPisssu89FeACAiTvGakXIZ7HtOAMA7x2Bfv/02DQCQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkFTRMdLc3ByNjY1RV1cXFRUVsWnTppMe09PTE7fcckt84AMfiFwuF1OnTo3vf//7Q5kXABhlxhV7wOHDh2PGjBlx9dVXx1/91V8N6pgrr7wyOjs743vf+16cffbZ0d7eHr29vUUPCwCMPkXHyLx582LevHmD3n/Lli3xxBNPRGtra0ycODEiIqZOnVrswwIAo1TJrxn58Y9/HBdddFHceeedcfrpp8c555wTf/u3fxuvvfbagMf09PREoVDodwMARqeiz4wUq7W1NXbs2BGVlZWxcePGePnll+P666+PX//613Hfffed8JjVq1fHbbfdVurRAIB3gJKfGent7Y2KiopYt25dzJo1K+bPnx/f+ta34gc/+MGAZ0eampqiq6ur73bgwIFSjwkAJFLyMyO1tbVx+umnRz6f79v2oQ99KLIsi1/84hfxwQ9+8C3H5HK5yOVypR4NAHgHKPmZkdmzZ8fBgwfj0KFDfdt+/vOfx5gxY2LKlCmlfngA4B2u6Bg5dOhQtLS0REtLS0REtLW1RUtLS+zfvz8i3nyLZcmSJX37L1q0KH7/938/PvOZz8S+ffuiubk5vvzlL8fVV18dEyZMGJ5nAQCMWEXHyO7du2PmzJkxc+bMiIhYuXJlzJw5M2699daIiGhvb+8Lk4iI3/u934utW7fGK6+8EhdddFF86lOfisbGxvjXf/3XYXoKAMBIVpFlWZZ6iJMpFAqRz+ejq6srqqurU48DAAzCYF+//TYNAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKSKjpHm5uZobGyMurq6qKioiE2bNg362J07d8a4cePiggsuKPZhAYBRqugYOXz4cMyYMSPWrFlT1HGvvPJKLFmyJP7sz/6s2IcEAEaxccUeMG/evJg3b17RD3TdddfFokWLYuzYsUWdTQEARreyXDNy3333RWtra6xatWpQ+/f09EShUOh3AwBGp5LHyH/913/FzTffHPfff3+MGze4EzGrV6+OfD7fd6uvry/xlABAKiWNkWPHjsWiRYvitttui3POOWfQxzU1NUVXV1ff7cCBAyWcEgBIqehrRorR3d0du3fvjj179sSKFSsiIqK3tzeyLItx48bFT37yk7jsssveclwul4tcLlfK0QCAd4iSxkh1dXU8++yz/bbdfffdsW3btnjooYdi2rRppXx4AGAEKDpGDh06FC+++GLf/ba2tmhpaYmJEyfGGWecEU1NTfHLX/4yfvjDH8aYMWNi+vTp/Y6vqamJysrKt2wHAN6dio6R3bt3x5w5c/rur1y5MiIili5dGmvXro329vbYv3//8E0IAIxqFVmWZamHOJlCoRD5fD66urqiuro69TgAwCAM9vXbb9MAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASKroGGlubo7Gxsaoq6uLioqK2LRp09vu//DDD8cnPvGJ+IM/+IOorq6OhoaGeOyxx4Y6LwAwyhQdI4cPH44ZM2bEmjVrBrV/c3NzfOITn4jNmzfH008/HXPmzInGxsbYs2dP0cMCAKNPRZZl2ZAPrqiIjRs3xoIFC4o67rzzzouFCxfGrbfeOqj9C4VC5PP56Orqiurq6iFMCgCU22Bfv8eVcaaIiOjt7Y3u7u6YOHHigPv09PRET09P3/1CoVCO0QCABMp+Aetdd90Vhw4diiuvvHLAfVavXh35fL7vVl9fX8YJAYByKmuM/OhHP4rbbrstHnzwwaipqRlwv6ampujq6uq7HThwoIxTAgDlVLa3adavXx/XXnttbNiwIebOnfu2++ZyucjlcmWaDABIqSxnRh544IH4zGc+Ew888EBcccUV5XhIAGCEKPrMyKFDh+LFF1/su9/W1hYtLS0xceLEOOOMM6KpqSl++ctfxg9/+MOIePOtmaVLl8a//Mu/xMUXXxwdHR0RETFhwoTI5/PD9DQAgJGq6DMju3fvjpkzZ8bMmTMjImLlypUxc+bMvo/ptre3x/79+/v2/+53vxtHjx6N5cuXR21tbd/thhtuGKanAACMZKf0PSPl4ntGAGDkGezrt9+mAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMalHiCVY71ZPNX2m/hV95GoqaqMWdMmxtgxFanHAoB3naLPjDQ3N0djY2PU1dVFRUVFbNq06aTHbN++PS688MLI5XJx9tlnx9q1a4cw6vDZsrc9LrljW1x175Nxw/qWuOreJ+OSO7bFlr3tSecCgHejomPk8OHDMWPGjFizZs2g9m9ra4srrrgi5syZEy0tLfGlL30prr322njssceKHnY4bNnbHl+4/5lo7zrSb3tH15H4wv3PCBIAKLOKLMuyIR9cUREbN26MBQsWDLjPTTfdFI8++mjs3bu3b9tf//VfxyuvvBJbtmwZ1OMUCoXI5/PR1dUV1dXVQx03jvVmcckd294SIsdVRMTkfGXsuOkyb9kAwCka7Ot3yS9g3bVrV8ydO7fftssvvzx27do14DE9PT1RKBT63YbDU22/GTBEIiKyiGjvOhJPtf1mWB4PADi5ksdIR0dHTJo0qd+2SZMmRaFQiNdee+2Ex6xevTry+Xzfrb6+flhm+VX3wCEylP0AgFP3jvxob1NTU3R1dfXdDhw4MCz/3JqqymHdDwA4dSX/aO/kyZOjs7Oz37bOzs6orq6OCRMmnPCYXC4XuVxu2GeZNW1i1OYro6PrSJzoQpnj14zMmjZx2B8bADixkp8ZaWhoiMcff7zftq1bt0ZDQ0OpH/otxo6piFWNH46IN8Pjtx2/v6rxwy5eBYAyKjpGDh06FC0tLdHS0hIRb350t6WlJfbv3x8Rb77FsmTJkr79r7vuumhtbY2vfOUr8fzzz8fdd98dDz74YNx4443D8wyK9MnptXHPpy+Myfn+b8VMzlfGPZ++MD45vTbJXADwblX0R3u3b98ec+bMecv2pUuXxtq1a2PZsmXx0ksvxfbt2/sdc+ONN8a+fftiypQp8bWvfS2WLVs26Mccro/2/jbfwAoApTXY1+9T+p6RcilFjAAApfWO+Z4RAIC3I0YAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJFXyX+0dDse/JLZQKCSeBAAYrOOv2yf7svcRESPd3d0REVFfX594EgCgWN3d3ZHP5wf88xHx2zS9vb1x8ODBqKqqioqK4fsxu0KhEPX19XHgwAG/eVNi1ro8rHN5WOfysM7lUcp1zrIsuru7o66uLsaMGfjKkBFxZmTMmDExZcqUkv3zq6ur/UUvE2tdHta5PKxzeVjn8ijVOr/dGZHjXMAKACQlRgCApN7VMZLL5WLVqlWRy+VSjzLqWevysM7lYZ3LwzqXxzthnUfEBawAwOj1rj4zAgCkJ0YAgKTECACQlBgBAJIa9TGyZs2amDp1alRWVsbFF18cTz311Nvuv2HDhjj33HOjsrIyzj///Ni8eXOZJh35ilnre++9Ny699NJ43/veF+973/ti7ty5J/3fhjcV+3f6uPXr10dFRUUsWLCgtAOOEsWu8yuvvBLLly+P2trayOVycc455/j3xyAUu87//M//HH/4h38YEyZMiPr6+rjxxhvjyJEjZZp2ZGpubo7Gxsaoq6uLioqK2LRp00mP2b59e1x44YWRy+Xi7LPPjrVr15Z2yGwUW79+fTZ+/Pjs+9//fvazn/0s++xnP5uddtppWWdn5wn337lzZzZ27NjszjvvzPbt25d99atfzd7znvdkzz77bJknH3mKXetFixZla9asyfbs2ZM999xz2bJly7J8Pp/94he/KPPkI0ux63xcW1tbdvrpp2eXXnpp9pd/+ZflGXYEK3ade3p6sosuuiibP39+tmPHjqytrS3bvn171tLSUubJR5Zi13ndunVZLpfL1q1bl7W1tWWPPfZYVltbm914441lnnxk2bx5c3bLLbdkDz/8cBYR2caNG992/9bW1uy9731vtnLlymzfvn3Zt7/97Wzs2LHZli1bSjbjqI6RWbNmZcuXL++7f+zYsayuri5bvXr1Cfe/8sorsyuuuKLftosvvjj7/Oc/X9I5R4Ni1/p3HT16NKuqqsp+8IMflGrEUWEo63z06NHsox/9aPbv//7v2dKlS8XIIBS7zvfcc0925plnZq+//nq5RhwVil3n5cuXZ5dddlm/bStXrsxmz55d0jlHk8HEyFe+8pXsvPPO67dt4cKF2eWXX16yuUbt2zSvv/56PP300zF37ty+bWPGjIm5c+fGrl27TnjMrl27+u0fEXH55ZcPuD9vGspa/65XX3013njjjZg4cWKpxhzxhrrOf//3fx81NTVxzTXXlGPMEW8o6/zjH/84GhoaYvny5TFp0qSYPn16fPOb34xjx46Va+wRZyjr/NGPfjSefvrpvrdyWltbY/PmzTF//vyyzPxukeK1cET8UN5QvPzyy3Hs2LGYNGlSv+2TJk2K559//oTHdHR0nHD/jo6Oks05GgxlrX/XTTfdFHV1dW/5PwD/31DWeceOHfG9730vWlpayjDh6DCUdW5tbY1t27bFpz71qdi8eXO8+OKLcf3118cbb7wRq1atKsfYI85Q1nnRokXx8ssvxyWXXBJZlsXRo0fjuuuui7/7u78rx8jvGgO9FhYKhXjttddiwoQJw/6Yo/bMCCPH7bffHuvXr4+NGzdGZWVl6nFGje7u7li8eHHce++98f73vz/1OKNab29v1NTUxHe/+934yEc+EgsXLoxbbrklvvOd76QebVTZvn17fPOb34y77747nnnmmXj44Yfj0UcfjW984xupR+MUjdozI+9///tj7Nix0dnZ2W97Z2dnTJ48+YTHTJ48uaj9edNQ1vq4u+66K26//fb4j//4j/ijP/qjUo454hW7zv/93/8dL730UjQ2NvZt6+3tjYiIcePGxQsvvBBnnXVWaYcegYby97m2tjbe8573xNixY/u2fehDH4qOjo54/fXXY/z48SWdeSQayjp/7Wtfi8WLF8e1114bERHnn39+HD58OD73uc/FLbfcEmPG+O/r4TDQa2F1dXVJzopEjOIzI+PHj4+PfOQj8fjjj/dt6+3tjccffzwaGhpOeExDQ0O//SMitm7dOuD+vGkoax0Rceedd8Y3vvGN2LJlS1x00UXlGHVEK3adzz333Hj22WejpaWl7/YXf/EXMWfOnGhpaYn6+vpyjj9iDOXv8+zZs+PFF1/si72IiJ///OdRW1srRAYwlHV+9dVX3xIcxwMw8zNrwybJa2HJLo19B1i/fn2Wy+WytWvXZvv27cs+97nPZaeddlrW0dGRZVmWLV68OLv55pv79t+5c2c2bty47K677sqee+65bNWqVT7aO0jFrvXtt9+ejR8/PnvooYey9vb2vlt3d3eqpzAiFLvOv8unaQan2HXev39/VlVVla1YsSJ74YUXskceeSSrqanJ/uEf/iHVUxgRil3nVatWZVVVVdkDDzyQtba2Zj/5yU+ys846K7vyyitTPYURobu7O9uzZ0+2Z8+eLCKyb33rW9mePXuy//mf/8myLMtuvvnmbPHixX37H/9o75e//OXsueeey9asWeOjvafq29/+dnbGGWdk48ePz2bNmpU9+eSTfX/2sY99LFu6dGm//R988MHsnHPOycaPH5+dd9552aOPPlrmiUeuYtb6Ax/4QBYRb7mtWrWq/IOPMMX+nf5tYmTwil3nn/70p9nFF1+c5XK57Mwzz8z+8R//MTt69GiZpx55ilnnN954I/v617+enXXWWVllZWVWX1+fXX/99dn//d//lX/wEeQ///M/T/jv2+Nru3Tp0uxjH/vYW4654IILsvHjx2dnnnlmdt9995V0xoosc24LAEhn1F4zAgCMDGIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqf8Heq52G7iysQkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/kaggle/input/my-flg-library/')\n",
    "import flg_support as fls\n",
    "import importlib\n",
    "import numpy as np\n",
    "import flg_diagnostics\n",
    "import flg_numerics\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import copy\n",
    "import flg_preprocess\n",
    "import os\n",
    "import flg_model\n",
    "fls.profiling=False\n",
    "plt.scatter([0,1],[1,2])\n",
    "fastMode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0475e99a-2367-4e3e-ba35-7d24cb43d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare datasets\n",
    "# fls.download_kaggle_dataset('jeroencottaar/byu-many-models-2/', fls.result_dir + '/many_full_res/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6ec9b5-0a15-4644-99d4-5b70a66385c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1002, 'n_ensemble': 3, 'n_epochs': 45, 'use_best_epoch': False, 'extra_data': True, 'trust_neg': 0, 'model_name': 'yolov8m'}\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(fls.result_dir + '/many_full_res/Baseline_1002_*')\n",
    "assert len(files)==1\n",
    "loaded_data = fls.dill_load(files[0])\n",
    "print(loaded_data.modifier_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e6427a-95b0-4b6a-8b6c-0e69abae7be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = loaded_data.untrained_model\n",
    "model.step1Labels.use_best_epoch = False\n",
    "model.step1Labels.n_ensemble = 1\n",
    "model.step1Labels.n_epochs = 201\n",
    "model.train_data_selector.datasets = ['tom']\n",
    "model.step1Labels.mosaic=0.0\n",
    "model.step1Labels.close_mosaic = 100\n",
    "model.step1Labels.cos_lr = True\n",
    "model.step1Labels.lrf = 0.0\n",
    "model.step1Labels.patience = 0\n",
    "train_data = loaded_data.train_data\n",
    "test_data = loaded_data.test_data\n",
    "epoch_list = [50,100,125,150,200]\n",
    "if fastMode:\n",
    "    model.step1Labels.n_epochs = 15\n",
    "    model.step1Labels.trust = 0\n",
    "    train_data = train_data[::10]\n",
    "    test_data = test_data[::10]\n",
    "    epoch_list = [5,10]\n",
    "#model.step1Labels.mixup = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656287a8-0969-4cf8-a03d-3c9e7bdbaa8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c715d418d9f942a5a2e7a6436f82e99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\cupyx\\jit\\_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c67002788994acb89ae16daf7df4e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 76 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 4 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.130 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=d:/flagellar/temp/training.yaml, epochs=15, time=None, patience=0, batch=12, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=100, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 24.411.2 MB/s, size: 110.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 89 images, 30 backgrounds, 0 corrupt: 100%|███████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 21.91.9 MB/s, size: 94.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 3 images, 2 backgrounds, 0 corrupt: 100%|██████████| 3\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1     0.0186          1      0.249      0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1     0.0278          1     0.0474     0.0237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00658          1     0.0109    0.00547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00488          1     0.0524     0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00193          1     0.0355     0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00441          1     0.0622     0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1       0.26          1      0.497      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1      0.177          1      0.332      0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1      0.013          1      0.332      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1     0.0137          1      0.166     0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1     0.0116          1      0.142     0.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1      0.262          1      0.497      0.169\n",
      "Speed: 0.3ms preprocess, 56.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "\n",
      "Training complete!\n",
      "Clearing cupy\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9383b955b246188da72453a33688e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4a33e5caa8418ea1a475d8bb5a9784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 76 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 4 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.130 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=d:/flagellar/temp/training.yaml, epochs=15, time=None, patience=0, batch=12, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=1, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=100, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 17.62.8 MB/s, size: 101.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 89 images, 30 backgrounds, 0 corrupt: 100%|███████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 17.52.0 MB/s, size: 94.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 3 images, 2 backgrounds, 0 corrupt: 100%|██████████| 3\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00685          1    0.00754    0.00377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00392          1     0.0042     0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1     0.0034          1    0.00513    0.00205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00323          1    0.00599      0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00493          1     0.0061    0.00366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00541          1    0.00589    0.00412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00585          1    0.00592    0.00415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating d:\\flagellar\\temp\\yolo_weights\\motor_detector\\weights\\best.pt...\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1    0.00217          1    0.00737    0.00442\n",
      "Speed: 0.8ms preprocess, 26.7ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "\n",
      "Training complete!\n",
      "Clearing cupy\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c641c7c82b44dfb4ee25d12875c959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing pytorch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8235ca1c93db418c85c422345ded63d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 76 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 4 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: d:/flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: d:/flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at d:/flagellar/temp/training.yaml\n",
      "Using YAML file: d:/flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: d:/flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.130 available  Update with 'pip install -U ultralytics'\n",
      "WARNING  'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.110  Python-3.10.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=d:/flagellar/temp/training.yaml, epochs=15, time=None, patience=0, batch=12, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=4, project=d:/flagellar/temp//yolo_weights/, name=motor_detector, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=2, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=100, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.0, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=None, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=d:\\flagellar\\temp\\yolo_weights\\motor_detector\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 18.49.3 MB/s, size: 117.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mtrain: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\train.cache... 89 images, 30 backgrounds, 0 corrupt: 100%|███████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 17.53.9 MB/s, size: 94.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[34m\u001b[1mval: \u001b[0mScanning D:\\flagellar\\temp\\yolo_dataset\\labels\\val.cache... 3 images, 2 backgrounds, 0 corrupt: 100%|██████████| 3\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to d:\\flagellar\\temp\\yolo_weights\\motor_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1md:\\flagellar\\temp\\yolo_weights\\motor_detector\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          1          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      2/15      4.79G      5.068      121.1      2.322         10        640:  50%|█████     | 4/8 [00:02<00:02,  1.54"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model2 \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[0;32m      3\u001b[0m model2\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m seed\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m fls\u001b[38;5;241m.\u001b[39mremove_and_make_dir(fls\u001b[38;5;241m.\u001b[39mtemp_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/intermediate_weights/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_support.py:522\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, train_data, validation_data)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m validation_data:\n\u001b[0;32m    521\u001b[0m     d\u001b[38;5;241m.\u001b[39munload()\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[0;32m    524\u001b[0m     d\u001b[38;5;241m.\u001b[39munload()\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_model.py:330\u001b[0m, in \u001b[0;36mThreeStepModelLabelBased._train\u001b[1;34m(self, train_data, validation_data)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep1Labels\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep1Labels\u001b[38;5;241m.\u001b[39mtrained_model\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 330\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep1Labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibrate_step_3:\n\u001b[0;32m    333\u001b[0m     self_temp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_yolo2.py:586\u001b[0m, in \u001b[0;36mYOLOModel.train\u001b[1;34m(self, train_data, validation_data)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYAML contents:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting YOLO training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 586\u001b[0m \u001b[43mtrain_yolo_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_yolo2.py:518\u001b[0m, in \u001b[0;36mYOLOModel.train.<locals>.train_yolo_model\u001b[1;34m(yaml_path, batch_size, img_size)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_scale_training:\n\u001b[0;32m    516\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m--> 518\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myolo_weights_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmotor_detector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stop training if no improvement after 10 epochs\u001b[39;49;00m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save model every 5 epochs\u001b[39;49;00m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdamW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# AdamW optimizer for stability\u001b[39;49;00m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Initial learning rate\u001b[39;49;00m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Final learning rate factor\u001b[39;49;00m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcos_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use cosine learning rate decay\u001b[39;49;00m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Prevent overfitting\u001b[39;49;00m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Momentum for better gradient updates\u001b[39;49;00m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_scale_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclose_mosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose_mosaic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disable mosaic augmentation after 10 epochs\u001b[39;49;00m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Speed up data loading\u001b[39;49;00m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable additional augmentations\u001b[39;49;00m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Mixed precision training for faster performance\u001b[39;49;00m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mi_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhsv_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsv_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhsv_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsv_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsv_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperspective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperspective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflipud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflipud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfliplr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfliplr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbgr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmosaic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_paste\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_paste\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_augment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_augment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merasing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merasing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(yolo_weights_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotor_detector\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# If function is defined, plot loss curves for better insights\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\ultralytics\\engine\\model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\ultralytics\\engine\\trainer.py:394\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    391\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for seed in range(100000):\n",
    "    model2 = copy.deepcopy(model)\n",
    "    model2.seed = seed\n",
    "    model2.train(train_data, test_data)\n",
    "    fls.remove_and_make_dir(fls.temp_dir + '/intermediate_weights/')\n",
    "    import shutil\n",
    "    shutil.copytree(fls.temp_dir + '/yolo_weights/motor_detector/weights', fls.temp_dir + '/intermediate_weights/', dirs_exist_ok=True)\n",
    "    import ultralytics\n",
    "    data_list = []\n",
    "    for epoch in epoch_list:\n",
    "        model2.step1Labels.trained_model = [ultralytics.YOLO(fls.temp_dir + '/intermediate_weights/epoch' + str(epoch) + '.pt')]\n",
    "        model2.step1Labels.concentration = 2\n",
    "        model2.run_in_parallel=True\n",
    "        data_list.append(model2.infer(test_data))\n",
    "        fls.dill_save(fls.temp_dir + '/intermediate_weights/' + str(epoch) + '.pickle', data_list)\n",
    "    fls.dill_save(fls.temp_dir + 'intermediate_data' + str(seed) + '.pickle', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02aa7404-2380-4d10-a2bf-44c1f0d44e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:/flagellar/temp/intermediate_data2.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     data_list \u001b[38;5;241m=\u001b[39m \u001b[43mfls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdill_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mintermediate_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflg_diagnostics\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n",
      "File \u001b[1;32md:\\flagellar/code/core\\flg_support.py:168\u001b[0m, in \u001b[0;36mdill_load\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdill_load\u001b[39m(filename):\n\u001b[1;32m--> 168\u001b[0m     filehandler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[0;32m    169\u001b[0m     data \u001b[38;5;241m=\u001b[39m dill\u001b[38;5;241m.\u001b[39mload(filehandler)\n\u001b[0;32m    170\u001b[0m     filehandler\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:/flagellar/temp/intermediate_data2.pickle'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.grid(True)\n",
    "for seed in range(10000):\n",
    "    data_list = fls.dill_load(fls.temp_dir + 'intermediate_data' + str(seed) +'.pickle')\n",
    "    import flg_diagnostics\n",
    "    import importlib\n",
    "    importlib.reload(flg_diagnostics)\n",
    "    scores = []\n",
    "    for d in data_list:\n",
    "        a,b = flg_diagnostics.expand_and_reinfer(d, test_data, model.step3Output.select_motors, 0.7)\n",
    "        scores.append(fls.score_competition_metric(a,b)[2])\n",
    "    plt.plot(epoch_list,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e23bba-6a92-49b6-bf81-945eb14c83d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
