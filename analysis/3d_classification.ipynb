{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b4b630-bd17-4d7f-97ef-001707dcf970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n",
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/flagellar/input/my-flg-library/')\n",
    "import flg_support as fls\n",
    "import importlib\n",
    "import numpy as np\n",
    "import flg_diagnostics\n",
    "import flg_numerics\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import copy\n",
    "import flg_preprocess\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "importlib.reload(fls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eae514f-3620-46df-9b6b-455c0545ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = fls.load_all_train_data()\n",
    "#runner = fls.dill_load(fls.result_dir + '/many_abbr_res - Copy/Baseline_0_d7f7501f_.81 _a.pickle')\n",
    "# size = 128\n",
    "# voxel_target = 20.\n",
    "# def add_motor(dat,lab, is_motor, is_train):\n",
    "#     this_mat = mat[ pad_size+lab['z']-size_to_extract//2:pad_size+lab['z']+size_to_extract//2+1, \n",
    "#                     pad_size+lab['y']-size_to_extract//2:pad_size+lab['y']+size_to_extract//2+1 , \n",
    "#                     pad_size+lab['x']-size_to_extract//2:pad_size+lab['x']+size_to_extract//2+1]\n",
    "    \n",
    "\n",
    "#     this_mat = cp.array(this_mat, dtype=cp.float32)\n",
    "#     this_mat = (this_mat-cp.nanmean(this_mat))/cp.nanstd(this_mat)\n",
    "\n",
    "#     this_mat[cp.isnan(this_mat)] = 0.\n",
    "\n",
    "#     this_mat=flg_numerics.fourier_resample_nd(this_mat, (size,size,size))\n",
    "\n",
    "#     # plt.figure()\n",
    "#     # plt.imshow(cp.asnumpy(cp.mean(this_mat[this_mat.shape[0]//2-5:this_mat.shape[0]//2+6,...],axis=0)), cmap='bone')\n",
    "#     # plt.colorbar()\n",
    "#     # plt.title(is_motor)\n",
    "    \n",
    "#     # plt.pause(0.0001)\n",
    "\n",
    "#     this_mat = cp.asnumpy(this_mat)\n",
    "\n",
    "#     global i_file\n",
    "#     if is_train:\n",
    "#         d = train_dir\n",
    "#     else:\n",
    "#         d = test_dir\n",
    "#     filename = str(i_file)+'.npy'\n",
    "#     np.save(d+filename, this_mat)\n",
    "#     i_file += 1\n",
    "\n",
    "#     if is_train:\n",
    "#         train_labels['filename'].append(filename)\n",
    "#         train_labels['is_motor'].append(is_motor)\n",
    "#     else:\n",
    "#         test_labels['filename'].append(filename)\n",
    "#         test_labels['is_motor'].append(is_motor)\n",
    "        \n",
    "    \n",
    "\n",
    "# train_dir = 'd:/flagellar/3d/train/'\n",
    "# test_dir = 'd:/flagellar/3d/test/'\n",
    "# fls.remove_and_make_dir(train_dir)\n",
    "# fls.remove_and_make_dir(test_dir)\n",
    "# #dirs = glob.glob('D:/flagellar/data/train/*')\n",
    "# r = np.random.default_rng(seed=0)\n",
    "# train_labels = dict()\n",
    "# train_labels['filename'] = []\n",
    "# train_labels['is_motor'] = []\n",
    "# test_labels = dict()\n",
    "# test_labels['filename'] = []\n",
    "# test_labels['is_motor'] = []\n",
    "# train_names = [d.name for d in runner.train_data]\n",
    "# test_names = [d.name for d in runner.test_data]\n",
    "# fls.claim_gpu('cupy')\n",
    "# i_file = 0\n",
    "# for dat in tqdm(data):\n",
    "#     resize_factor = dat.voxel_spacing/voxel_target\n",
    "#     size_to_extract = np.round(size/resize_factor).astype(int)\n",
    "    \n",
    "#     dat.load_to_memory()   \n",
    "#     mat = copy.deepcopy(dat.data.astype(np.float16))\n",
    "#     dat.unload()\n",
    "#     pad_size = size_to_extract//2+3\n",
    "    \n",
    "#     mat = np.pad(mat, size_to_extract//2+3, constant_values=np.nan)\n",
    "\n",
    "    \n",
    "\n",
    "#     if dat.name in train_names:\n",
    "#         is_train = True\n",
    "#     else:\n",
    "#         is_train = False\n",
    "#         assert dat.name in test_names\n",
    "#     for lab in dat.labels.iterrows():\n",
    "#         if lab[1]['suspect']==0.0:\n",
    "#             add_motor(dat,lab[1],True,is_train)\n",
    "\n",
    "#     for lab in dat.negative_labels.iterrows():\n",
    "#         if lab[1]['suspect']==0.0:\n",
    "#             add_motor(dat,lab[1],False,is_train)\n",
    "\n",
    "#     # for f in files[::len(files)//scale_fac][1:-1]:\n",
    "#     #     fname = dat.name+'__'+os.path.basename(f)\n",
    "#     #     if dat.name in train_names:\n",
    "#     #         shutil.copyfile(f,train_dir+'/'+fname)\n",
    "#     #         train_labels['filename'].append(fname)\n",
    "#     #         train_labels['voxel_spacing'].append(dat.voxel_spacing)\n",
    "#     #     else:\n",
    "#     #         assert dat.name in test_names\n",
    "#     #         shutil.copyfile(f,test_dir+'/'+fname)\n",
    "#     #         test_labels['filename'].append(fname)\n",
    "#     #         test_labels['voxel_spacing'].append(dat.voxel_spacing)\n",
    "# pd.DataFrame(train_labels).to_csv(train_dir + '/labels.csv', index=False)\n",
    "# pd.DataFrame(test_labels).to_csv(test_dir + '/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7aaf19d-8179-413a-94e7-7d5a4a6f0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from glob import glob\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torchvision\n",
    "# from torchvision.models.video import r3d_18\n",
    "\n",
    "\n",
    "# class FlagellarDataset(Dataset):\n",
    "#     def __init__(self, data_dir, labels_csv, transform=None):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.labels = pd.read_csv(labels_csv)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.labels.iloc[idx]\n",
    "#         file_path = os.path.join(self.data_dir, row.filename)\n",
    "#         volume = np.load(file_path)  # shape: (128, 128, 128), float32\n",
    "#         label = int(row.is_motor)\n",
    "\n",
    "#         # add channel dim\n",
    "#         volume = np.expand_dims(volume, axis=0)  # (1, 128, 128, 128)\n",
    "#         volume = torch.from_numpy(volume)\n",
    "#         label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "#         if self.transform:\n",
    "#             volume = self.transform(volume)\n",
    "\n",
    "#         return volume, label\n",
    "\n",
    "\n",
    "# def set_bn_momentum(module: nn.Module):\n",
    "#     \"\"\"\n",
    "#     Recursively set momentum=0.01 for all BatchNorm3d layers in the model.\n",
    "#     \"\"\"\n",
    "#     for child in module.children():\n",
    "#         if isinstance(child, nn.BatchNorm3d):\n",
    "#             child.momentum = 0.01\n",
    "#         else:\n",
    "#             set_bn_momentum(child)\n",
    "\n",
    "\n",
    "# def build_resnet3d(num_classes=2):\n",
    "#     # Load a ResNet-18 3D model without pretrained weights\n",
    "#     model = r3d_18(pretrained=False)\n",
    "#     # Modify first conv layer to accept single channel input\n",
    "#     orig_conv = model.stem[0]\n",
    "#     model.stem[0] = nn.Conv3d(\n",
    "#         in_channels=1,\n",
    "#         out_channels=orig_conv.out_channels,\n",
    "#         kernel_size=orig_conv.kernel_size,\n",
    "#         stride=orig_conv.stride,\n",
    "#         padding=orig_conv.padding,\n",
    "#         bias=orig_conv.bias is not None\n",
    "#     )\n",
    "#     # Replace the final fully-connected layer\n",
    "#     in_features = model.fc.in_features\n",
    "#     model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "#     # Recursively update BatchNorm3d momentum\n",
    "#     set_bn_momentum(model)\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, targets in loader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "#     return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# def evaluate(model, loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     all_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             preds = outputs.argmax(dim=1)\n",
    "#             correct += (preds == targets).sum().item()\n",
    "#             all_preds.append(outputs)\n",
    "#     avg_loss = running_loss / len(loader.dataset)\n",
    "#     accuracy = correct / len(loader.dataset)\n",
    "#     error_rate = 1.0 - accuracy\n",
    "#     return avg_loss, accuracy, error_rate\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Paths\n",
    "#     train_dir = r\"D:\\flagellar\\3d\\train\"\n",
    "#     test_dir = r\"D:\\flagellar\\3d\\test\"\n",
    "#     train_csv = os.path.join(train_dir, \"labels.csv\")\n",
    "#     test_csv = os.path.join(test_dir, \"labels.csv\")\n",
    "\n",
    "#     # Hyperparameters\n",
    "#     epochs = 200\n",
    "#     batch_size = 4\n",
    "#     lr = 1e-3\n",
    "\n",
    "#     # Device\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Datasets and Loaders\n",
    "#     train_dataset = FlagellarDataset(train_dir, train_csv)\n",
    "#     test_dataset = FlagellarDataset(test_dir, test_csv)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "#     # Model, Loss, Optimizer\n",
    "#     model = build_resnet3d(num_classes=2).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#         test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "#         print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | \"\n",
    "#               f\"Test Acc: {test_acc:.4f} | Test Error: {test_err:.4f}\")\n",
    "#         print(predict(model,test_loader,device))\n",
    "\n",
    "#         model.to('cpu')\n",
    "#         fls.dill_save(fls.model_dir + '3d_model_n' + str(epoch) + '.pickle', model)\n",
    "#         model.to(device)\n",
    "        \n",
    "\n",
    "#     # Final evaluation\n",
    "#     test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "#     print(f\"\\nFinal Test Loss: {test_loss:.4f} | Final Test Acc: {test_acc:.4f} | \"\n",
    "#           f\"Final Test Error: {test_err:.4f}\")\n",
    "\n",
    "# def predict(model, loader, device):\n",
    "#     \"\"\"\n",
    "#     Runs the model on all data in `loader` and returns the probability of the positive class (is_motor)\n",
    "#     for each sample in the loader, in the same order.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     probabilities = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, _ in loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             outputs = model(inputs)                            # raw logits, shape (B, 2)\n",
    "#             probs = torch.softmax(outputs, dim=1)[:, 1]         # probability of class “1” (motor present)\n",
    "#             probabilities.extend(probs.cpu().tolist())\n",
    "#     return probabilities\n",
    "\n",
    "# # Claim GPU and run\n",
    "# fls.claim_gpu('pytorch')\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083722e2-714e-4332-943c-af59e89e51cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Train Loss: 0.7000 | Test Loss: 7.2744 | Test Acc: 0.7843 | Test Error: 0.2157\n",
      "[1.0, 0.9999997615814209, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5539844632148743, 1.0, 1.0, 1.0, 1.0, 0.33431684970855713, 0.34901246428489685, 1.0, 0.9999988079071045, 0.9999902248382568, 0.9997883439064026, 0.2939551770687103, 0.30829647183418274, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.26082125306129456, 0.2619380056858063, 0.26068562269210815, 0.2609303295612335, 1.0, 0.2962985634803772, 1.0, 1.0, 0.28346842527389526, 1.0, 1.0, 1.0, 0.9999995231628418, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2794458270072937, 1.0, 1.0, 0.27465468645095825, 0.2787899076938629, 0.2786825895309448, 0.26979053020477295, 1.0, 1.0, 1.0, 1.0, 0.9999765157699585, 1.0, 0.9921950101852417, 0.9999099969863892, 0.9999997615814209, 0.2763538956642151, 0.2655855119228363, 0.2759295105934143, 0.26039814949035645, 1.0, 1.0, 0.40196219086647034, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29264530539512634, 0.7628530263900757, 1.0, 1.0, 1.0, 0.3336440324783325, 0.27440208196640015, 0.321097195148468, 0.2751472592353821, 1.0, 1.0]\n",
      "Epoch 2/200 - Train Loss: 0.6240 | Test Loss: 0.5080 | Test Acc: 0.7941 | Test Error: 0.2059\n",
      "[0.6201347708702087, 0.5174853801727295, 0.5584039092063904, 0.551506519317627, 0.5997425317764282, 0.6597716808319092, 0.6976214647293091, 0.669590175151825, 0.505553126335144, 0.736754298210144, 0.7900348901748657, 0.5731148719787598, 0.5723828077316284, 0.23497307300567627, 0.23930060863494873, 0.7784849405288696, 0.5160409808158875, 0.43259021639823914, 0.4129563271999359, 0.21728253364562988, 0.22465036809444427, 0.4948529303073883, 0.8140420317649841, 0.6028080582618713, 0.7489209175109863, 0.6670315265655518, 0.9151989221572876, 0.6553197503089905, 0.22065502405166626, 0.220428466796875, 0.2205016314983368, 0.22242139279842377, 0.5658137202262878, 0.22828063368797302, 0.8679428100585938, 0.77926105260849, 0.22565506398677826, 0.7323671579360962, 0.741115152835846, 0.7867264747619629, 0.4869983196258545, 0.6147192120552063, 0.57098788022995, 0.8100815415382385, 0.7093300223350525, 0.6450080275535583, 0.807856559753418, 0.7214949727058411, 0.8849457502365112, 0.8677467703819275, 0.8949575424194336, 0.7041691541671753, 0.8377910256385803, 0.8448578715324402, 0.9041385054588318, 0.725461483001709, 0.8263881802558899, 0.9589764475822449, 0.9233124256134033, 0.6630070805549622, 0.8522472977638245, 0.2192351520061493, 0.6573289632797241, 0.789456307888031, 0.2236516922712326, 0.22422783076763153, 0.2241966277360916, 0.22220170497894287, 0.6719798445701599, 0.7137041091918945, 0.6962123513221741, 0.8262087106704712, 0.4120505750179291, 0.5480740070343018, 0.30976125597953796, 0.47933632135391235, 0.4606882333755493, 0.22547218203544617, 0.22275854647159576, 0.22517330944538116, 0.22082489728927612, 0.9322801232337952, 0.6408378481864929, 0.315904825925827, 0.5842157602310181, 0.641303539276123, 0.7023256421089172, 0.7945306301116943, 0.6990135908126831, 0.6464834809303284, 0.6036242842674255, 0.22714366018772125, 0.25792479515075684, 0.8246005773544312, 0.7326885461807251, 0.6184992790222168, 0.22914791107177734, 0.2193973958492279, 0.23155289888381958, 0.2190321683883667, 0.5288296937942505, 0.7948499321937561]\n",
      "Epoch 3/200 - Train Loss: 0.5807 | Test Loss: 0.6070 | Test Acc: 0.7157 | Test Error: 0.2843\n",
      "[0.4717666506767273, 0.657140851020813, 0.4858924448490143, 0.49392178654670715, 0.7704514861106873, 0.7655757069587708, 0.8281815648078918, 0.7702666521072388, 0.7447041273117065, 0.7478447556495667, 0.4100892245769501, 0.7312611937522888, 0.5893734097480774, 0.24439947307109833, 0.25985366106033325, 0.56940758228302, 0.758349597454071, 0.6485093832015991, 0.6575937271118164, 0.20761853456497192, 0.23829999566078186, 0.5272976756095886, 0.3806670308113098, 0.6034299731254578, 0.5975555777549744, 0.46364808082580566, 0.34781065583229065, 0.773184597492218, 0.20930780470371246, 0.2121007889509201, 0.2091142237186432, 0.2136780321598053, 0.5937171578407288, 0.22950246930122375, 0.5365972518920898, 0.549305260181427, 0.22005748748779297, 0.502257764339447, 0.4393869638442993, 0.41058313846588135, 0.6760104298591614, 0.5478052496910095, 0.6589421629905701, 0.73610919713974, 0.5159367322921753, 0.532997727394104, 0.32442930340766907, 0.7439960837364197, 0.428737074136734, 0.43999403715133667, 0.6283861994743347, 0.726867139339447, 0.4828290641307831, 0.4163292646408081, 0.2613471448421478, 0.5635149478912354, 0.6825090050697327, 0.058294110000133514, 0.1478952318429947, 0.5754276514053345, 0.6000446081161499, 0.20645010471343994, 0.4167945981025696, 0.557268500328064, 0.21000085771083832, 0.21176105737686157, 0.21246463060379028, 0.21020559966564178, 0.8498696684837341, 0.6277328133583069, 0.610536515712738, 0.6124181747436523, 0.6190920472145081, 0.6121155023574829, 0.4824006259441376, 0.7053414583206177, 0.628380298614502, 0.21551139652729034, 0.21181748807430267, 0.21492227911949158, 0.21193061769008636, 0.4233503043651581, 0.683558464050293, 0.5083821415901184, 0.6700007319450378, 0.8219726085662842, 0.5720030665397644, 0.8066046237945557, 0.7412363886833191, 0.6431919932365417, 0.5981992483139038, 0.2186746448278427, 0.23862959444522858, 0.3532765209674835, 0.41373708844184875, 0.6804977059364319, 0.24485370516777039, 0.20660924911499023, 0.2583251893520355, 0.20538289844989777, 0.517463207244873, 0.3929290473461151]\n",
      "Epoch 4/200 - Train Loss: 0.5857 | Test Loss: 0.8644 | Test Acc: 0.7647 | Test Error: 0.2353\n",
      "[0.9658001661300659, 0.8912791609764099, 0.930601954460144, 0.9258768558502197, 0.9726945161819458, 0.9778043627738953, 0.9797661900520325, 0.9801318049430847, 0.9206990599632263, 0.9831215143203735, 0.9903321862220764, 0.9619522094726562, 0.8900560140609741, 0.5405473113059998, 0.5954387187957764, 0.9893730282783508, 0.9576572179794312, 0.9289321899414062, 0.9283673763275146, 0.33965086936950684, 0.39593037962913513, 0.9386535882949829, 0.9725915789604187, 0.9582149982452393, 0.9549186825752258, 0.9644249677658081, 0.9926002025604248, 0.9713717103004456, 0.333370566368103, 0.33586937189102173, 0.3346420228481293, 0.3320101797580719, 0.95218825340271, 0.3617473244667053, 0.9947466254234314, 0.9820916056632996, 0.3501085937023163, 0.9782692790031433, 0.9655031561851501, 0.9695194363594055, 0.9228488206863403, 0.9714961647987366, 0.935607373714447, 0.9906759262084961, 0.9654225707054138, 0.9701106548309326, 0.9727200269699097, 0.9791967272758484, 0.9877603650093079, 0.9946931004524231, 0.9984267950057983, 0.9799378514289856, 0.9813872575759888, 0.9743269085884094, 0.9831356406211853, 0.9901244044303894, 0.9948574304580688, 0.9929966330528259, 0.9970672726631165, 0.9743977785110474, 0.9883262515068054, 0.346060574054718, 0.9526695609092712, 0.9823489785194397, 0.33770495653152466, 0.3440878093242645, 0.3485656976699829, 0.3330564796924591, 0.9826906323432922, 0.9769967198371887, 0.9787741303443909, 0.9928727149963379, 0.9098570346832275, 0.9417010545730591, 0.8256517052650452, 0.886702299118042, 0.8946793079376221, 0.3366162180900574, 0.333096444606781, 0.335958331823349, 0.3401127755641937, 0.9925596714019775, 0.9716538190841675, 0.8249335289001465, 0.9512404203414917, 0.9745627045631409, 0.9674814343452454, 0.9844304919242859, 0.9796195030212402, 0.9668813943862915, 0.9500055313110352, 0.36515775322914124, 0.42638349533081055, 0.9692087173461914, 0.9651731252670288, 0.962894856929779, 0.49659740924835205, 0.33824023604393005, 0.4612894058227539, 0.333151638507843, 0.8468239903450012, 0.9765554070472717]\n",
      "Epoch 5/200 - Train Loss: 0.5363 | Test Loss: 0.4804 | Test Acc: 0.8039 | Test Error: 0.1961\n",
      "[0.7852491736412048, 0.6240415573120117, 0.7114132642745972, 0.6758634448051453, 0.7128304839134216, 0.7457931041717529, 0.8770499229431152, 0.7468456029891968, 0.33011332154273987, 0.8247754573822021, 0.902243971824646, 0.7207087874412537, 0.7228745222091675, 0.14497217535972595, 0.14357903599739075, 0.8849925398826599, 0.562777578830719, 0.44850489497184753, 0.6426438093185425, 0.1109134629368782, 0.11740192770957947, 0.6096475720405579, 0.8623600006103516, 0.7489588260650635, 0.7930938005447388, 0.7593982815742493, 0.9306974411010742, 0.8435338735580444, 0.11498101055622101, 0.11665916442871094, 0.11688593775033951, 0.11519396305084229, 0.7303699851036072, 0.12334395200014114, 0.8565826416015625, 0.8720211386680603, 0.11857853084802628, 0.8452205657958984, 0.8608593940734863, 0.8713734149932861, 0.5514257550239563, 0.8376927971839905, 0.6825543642044067, 0.8256929516792297, 0.7634792327880859, 0.8221163749694824, 0.8554893136024475, 0.8127669095993042, 0.8814014792442322, 0.934856653213501, 0.9404667615890503, 0.7715681195259094, 0.8690508604049683, 0.8578503727912903, 0.8673050999641418, 0.825472354888916, 0.9244771003723145, 0.9202179908752441, 0.9652877449989319, 0.7950102686882019, 0.8444965481758118, 0.11563526093959808, 0.830715000629425, 0.8567100167274475, 0.1179443970322609, 0.11773305386304855, 0.11736523360013962, 0.11575796455144882, 0.7276862263679504, 0.7019993662834167, 0.8308299779891968, 0.8193531632423401, 0.5070189237594604, 0.6307801604270935, 0.309424489736557, 0.6625633239746094, 0.573824405670166, 0.12008827924728394, 0.11654962599277496, 0.1189664676785469, 0.11506745964288712, 0.8480713367462158, 0.7689535617828369, 0.17493018507957458, 0.692402184009552, 0.7120391130447388, 0.8105438947677612, 0.8393576145172119, 0.7561072707176208, 0.7023167014122009, 0.6622574925422668, 0.12515759468078613, 0.1684136986732483, 0.8770846128463745, 0.8498915433883667, 0.8223508596420288, 0.12991482019424438, 0.11372345685958862, 0.12416119873523712, 0.11272299289703369, 0.6356697082519531, 0.8805364966392517]\n",
      "Epoch 6/200 - Train Loss: 0.5742 | Test Loss: 0.8490 | Test Acc: 0.7843 | Test Error: 0.2157\n",
      "[0.9602226614952087, 0.8647083044052124, 0.9596093893051147, 0.954838752746582, 0.9518495202064514, 0.9663873910903931, 0.9749564528465271, 0.9675191640853882, 0.8510955572128296, 0.9850752353668213, 0.9947645664215088, 0.9597671627998352, 0.9626938700675964, 0.3642007112503052, 0.3765758275985718, 0.9933884143829346, 0.9207071661949158, 0.8773940205574036, 0.8772044777870178, 0.21588678658008575, 0.2753607928752899, 0.9055503010749817, 0.9956953525543213, 0.9624843001365662, 0.9930322170257568, 0.9842275977134705, 0.9980741739273071, 0.9679479002952576, 0.2190011590719223, 0.24925237894058228, 0.23608504235744476, 0.203033447265625, 0.950646162033081, 0.24231590330600739, 0.9838896989822388, 0.9940476417541504, 0.22077186405658722, 0.9924762845039368, 0.9910475611686707, 0.99382084608078, 0.8920745849609375, 0.959613025188446, 0.9544056057929993, 0.9841042757034302, 0.9890156388282776, 0.970078706741333, 0.9954631924629211, 0.9734708070755005, 0.9976387023925781, 0.996264636516571, 0.9938259720802307, 0.9677019715309143, 0.9964175224304199, 0.9924418926239014, 0.9982190728187561, 0.9881523251533508, 0.9949361085891724, 0.999828577041626, 0.9995879530906677, 0.9559773802757263, 0.9897167086601257, 0.2607443332672119, 0.9868888854980469, 0.9932559728622437, 0.22759516537189484, 0.2286081165075302, 0.228701651096344, 0.21772174537181854, 0.9725381135940552, 0.9552626013755798, 0.9765233397483826, 0.9794476628303528, 0.8107390999794006, 0.9427196383476257, 0.7444972395896912, 0.8340206742286682, 0.8671581745147705, 0.22146205604076385, 0.213896706700325, 0.21750560402870178, 0.21872074902057648, 0.9982407093048096, 0.9483453631401062, 0.5626922249794006, 0.9474088549613953, 0.9579979777336121, 0.9809093475341797, 0.9888108968734741, 0.9693490266799927, 0.9607858657836914, 0.9622983932495117, 0.27362677454948425, 0.33665722608566284, 0.9952995777130127, 0.9870714545249939, 0.9585759043693542, 0.3548390567302704, 0.21637926995754242, 0.29288578033447266, 0.21692273020744324, 0.8487083911895752, 0.9965910911560059]\n",
      "Epoch 7/200 - Train Loss: 0.5544 | Test Loss: 0.7069 | Test Acc: 0.7451 | Test Error: 0.2549\n",
      "[0.8987024426460266, 0.8004320859909058, 0.88799649477005, 0.8782203793525696, 0.8780929446220398, 0.8947018384933472, 0.9161081314086914, 0.8915384411811829, 0.8676097393035889, 0.920444905757904, 0.9745298624038696, 0.8999525308609009, 0.8733702898025513, 0.5855926275253296, 0.6426852345466614, 0.9603363275527954, 0.8599099516868591, 0.8322930932044983, 0.8453440070152283, 0.33580482006073, 0.46509525179862976, 0.8545608520507812, 0.9442770481109619, 0.8921987414360046, 0.9311423897743225, 0.921538770198822, 0.9793239831924438, 0.9012140035629272, 0.32593852281570435, 0.36501768231391907, 0.3483010530471802, 0.26200780272483826, 0.8707848191261292, 0.3346911370754242, 0.9817010760307312, 0.9551544785499573, 0.3294656276702881, 0.9512895345687866, 0.9379647374153137, 0.9439936280250549, 0.834862232208252, 0.9296775460243225, 0.8746451735496521, 0.915626585483551, 0.9195101261138916, 0.9305050373077393, 0.9439926743507385, 0.9079822301864624, 0.9693953990936279, 0.983253002166748, 0.985481321811676, 0.892021656036377, 0.9511776566505432, 0.8947027921676636, 0.9690923690795898, 0.9704731702804565, 0.9819064140319824, 0.9896789789199829, 0.9969070553779602, 0.8948658108711243, 0.933893084526062, 0.41712772846221924, 0.9322915077209473, 0.9466218948364258, 0.33517155051231384, 0.3502799868583679, 0.36476537585258484, 0.3077045679092407, 0.909925639629364, 0.9271741509437561, 0.9205095171928406, 0.9593738913536072, 0.7857159376144409, 0.845847487449646, 0.7598118185997009, 0.7925848364830017, 0.8134483695030212, 0.31873852014541626, 0.3043147623538971, 0.3088166415691376, 0.2893354296684265, 0.9704673290252686, 0.8866326808929443, 0.7436468005180359, 0.873218297958374, 0.8989217281341553, 0.9204258322715759, 0.9347342252731323, 0.8907333612442017, 0.8857662081718445, 0.879622757434845, 0.3919319808483124, 0.3975239098072052, 0.9297444224357605, 0.9425370693206787, 0.8869460225105286, 0.5731381177902222, 0.339942067861557, 0.5646330714225769, 0.3238391578197479, 0.7225623726844788, 0.9562358856201172]\n",
      "Epoch 8/200 - Train Loss: 0.5381 | Test Loss: 0.8831 | Test Acc: 0.7941 | Test Error: 0.2059\n",
      "[0.9738191962242126, 0.8174929022789001, 0.9527558088302612, 0.9349865913391113, 0.9262245297431946, 0.966361939907074, 0.9794180393218994, 0.9736959934234619, 0.9018899202346802, 0.9882808327674866, 0.9980012774467468, 0.9576326012611389, 0.944301187992096, 0.16150245070457458, 0.17261192202568054, 0.9955299496650696, 0.8373944163322449, 0.7390311360359192, 0.78351891040802, 0.14032791554927826, 0.1485026627779007, 0.9470930695533752, 0.9980387091636658, 0.9431557059288025, 0.9894716143608093, 0.9842797517776489, 0.9997091889381409, 0.9645150303840637, 0.14079201221466064, 0.14068135619163513, 0.14127101004123688, 0.1400240957736969, 0.9558930993080139, 0.14402668178081512, 0.9998288154602051, 0.9961684346199036, 0.14448870718479156, 0.9947913885116577, 0.9925372004508972, 0.9960532188415527, 0.8299597501754761, 0.9818885922431946, 0.9352989196777344, 0.9973799586296082, 0.9897627830505371, 0.9884821176528931, 0.9980738162994385, 0.9803333878517151, 0.9996658563613892, 0.9993762373924255, 0.9999468326568604, 0.9878540635108948, 0.9984303116798401, 0.9905160069465637, 0.9995259046554565, 0.9967992305755615, 0.9991338849067688, 0.9999877214431763, 0.9999233484268188, 0.99273681640625, 0.9981817007064819, 0.1434875875711441, 0.9864590167999268, 0.9974192380905151, 0.1414416879415512, 0.14276666939258575, 0.14412365853786469, 0.14055483043193817, 0.9597830176353455, 0.9944210648536682, 0.9926378726959229, 0.9992595314979553, 0.6498843431472778, 0.8615612387657166, 0.6338273882865906, 0.671292781829834, 0.7460957169532776, 0.1410994827747345, 0.14057736098766327, 0.140939399600029, 0.14609214663505554, 0.9998863935470581, 0.9736213684082031, 0.21369685232639313, 0.9285560846328735, 0.9620778560638428, 0.9873360991477966, 0.9961133003234863, 0.9744082093238831, 0.9614285230636597, 0.9440451860427856, 0.1452140361070633, 0.24074514210224152, 0.9935531616210938, 0.9849956631660461, 0.9671803116798401, 0.155068501830101, 0.14310790598392487, 0.14661134779453278, 0.14012658596038818, 0.7140554189682007, 0.9977684020996094]\n",
      "Epoch 9/200 - Train Loss: 0.5389 | Test Loss: 1.4924 | Test Acc: 0.7941 | Test Error: 0.2059\n",
      "[0.9980097413063049, 0.9717349410057068, 0.9980594515800476, 0.9976048469543457, 0.9968659281730652, 0.9983299374580383, 0.9996891021728516, 0.998482882976532, 0.9575293064117432, 0.9998679161071777, 0.999956488609314, 0.9976732134819031, 0.9976181387901306, 0.23152990639209747, 0.27094998955726624, 0.999962329864502, 0.9919914603233337, 0.9790919423103333, 0.9861944913864136, 0.147142231464386, 0.16834397614002228, 0.9680095314979553, 0.9999842643737793, 0.9987363219261169, 0.9999828338623047, 0.9997134804725647, 0.9999980926513672, 0.9994981288909912, 0.1498018503189087, 0.15196293592453003, 0.14965473115444183, 0.14807966351509094, 0.9954288005828857, 0.15198123455047607, 0.998742401599884, 0.9999773502349854, 0.15523885190486908, 0.999954104423523, 0.9999361038208008, 0.9999631643295288, 0.9908807277679443, 0.9976596832275391, 0.9981757402420044, 0.9997026324272156, 0.9998995065689087, 0.9982219338417053, 0.9999657869338989, 0.9995372295379639, 0.9999897480010986, 0.9999866485595703, 0.9999061822891235, 0.998696506023407, 0.9999905824661255, 0.9999904632568359, 0.9999926090240479, 0.9998143315315247, 0.9999786615371704, 0.9999997615814209, 0.9999994039535522, 0.9939131140708923, 0.9998652935028076, 0.15851233899593353, 0.9996318817138672, 0.9999642372131348, 0.15375809371471405, 0.16052141785621643, 0.16477076709270477, 0.14859150350093842, 0.9995813965797424, 0.9920238256454468, 0.9994997978210449, 0.9978851675987244, 0.9797194600105286, 0.9973068237304688, 0.8947793841362, 0.9677438735961914, 0.9820491671562195, 0.14890649914741516, 0.14863437414169312, 0.14863702654838562, 0.15920157730579376, 0.9999921321868896, 0.9956296682357788, 0.3961295485496521, 0.9925014972686768, 0.9977717995643616, 0.9994114637374878, 0.9999363422393799, 0.9986072182655334, 0.9971708655357361, 0.9978103041648865, 0.14994701743125916, 0.27819374203681946, 0.9999845027923584, 0.99974125623703, 0.9985615611076355, 0.1845928430557251, 0.15298627316951752, 0.15609976649284363, 0.14747998118400574, 0.9815759658813477, 0.9999921321868896]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "\n",
    "class FlagellarDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_csv, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels.iloc[idx]\n",
    "        file_path = os.path.join(self.data_dir, row.filename)\n",
    "        volume = np.load(file_path)  # shape: (128, 128, 128), float32\n",
    "        label = int(row.is_motor)\n",
    "\n",
    "        # add channel dim\n",
    "        volume = np.expand_dims(volume, axis=0)  # (1, 128, 128, 128)\n",
    "        volume = torch.from_numpy(volume)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            volume = self.transform(volume)\n",
    "\n",
    "        return volume, label\n",
    "\n",
    "\n",
    "def set_bn_momentum(module: nn.Module):\n",
    "    \"\"\"\n",
    "    Recursively set momentum=0.01 for all BatchNorm3d layers in the model.\n",
    "    \"\"\"\n",
    "    for child in module.children():\n",
    "        if isinstance(child, nn.BatchNorm3d):\n",
    "            child.momentum = 0.01\n",
    "        else:\n",
    "            set_bn_momentum(child)\n",
    "\n",
    "\n",
    "def build_resnet3d(num_classes=2):\n",
    "    # Load a ResNet-18 3D model without pretrained weights\n",
    "    model = r3d_18(pretrained=False)\n",
    "    # Modify first conv layer to accept single channel input\n",
    "    orig_conv = model.stem[0]\n",
    "    model.stem[0] = nn.Conv3d(\n",
    "        in_channels=1,\n",
    "        out_channels=orig_conv.out_channels,\n",
    "        kernel_size=orig_conv.kernel_size,\n",
    "        stride=orig_conv.stride,\n",
    "        padding=orig_conv.padding,\n",
    "        bias=orig_conv.bias is not None\n",
    "    )\n",
    "    # Replace the final fully-connected layer\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Recursively update BatchNorm3d momentum\n",
    "    set_bn_momentum(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            all_preds.append(outputs)\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    error_rate = 1.0 - accuracy\n",
    "    return avg_loss, accuracy, error_rate\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    train_dir = r\"D:\\flagellar\\3d\\train\"\n",
    "    test_dir = r\"D:\\flagellar\\3d\\test\"\n",
    "    train_csv = os.path.join(train_dir, \"labels.csv\")\n",
    "    test_csv = os.path.join(test_dir, \"labels.csv\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    epochs = 200\n",
    "    batch_size = 4\n",
    "    lr = 1e-3\n",
    "\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Datasets and Loaders\n",
    "    train_dataset = FlagellarDataset(train_dir, train_csv)\n",
    "    test_dataset = FlagellarDataset(test_dir, test_csv)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Model, Loss, Optimizer\n",
    "    model = build_resnet3d(num_classes=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | \"\n",
    "              f\"Test Acc: {test_acc:.4f} | Test Error: {test_err:.4f}\")\n",
    "        print(predict(model,test_loader,device))\n",
    "\n",
    "        model.to('cpu')\n",
    "        fls.dill_save(fls.model_dir + '3d_model_n' + str(epoch) + '.pickle', model)\n",
    "        model.to(device)\n",
    "        \n",
    "\n",
    "    # Final evaluation\n",
    "    test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"\\nFinal Test Loss: {test_loss:.4f} | Final Test Acc: {test_acc:.4f} | \"\n",
    "          f\"Final Test Error: {test_err:.4f}\")\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    \"\"\"\n",
    "    Runs the model on all data in `loader` and returns the probability of the positive class (is_motor)\n",
    "    for each sample in the loader, in the same order.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    probabilities = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)                            # raw logits, shape (B, 2)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]         # probability of class “1” (motor present)\n",
    "            probabilities.extend(probs.cpu().tolist())\n",
    "    return probabilities\n",
    "\n",
    "# Claim GPU and run\n",
    "fls.claim_gpu('pytorch')\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
