{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b4b630-bd17-4d7f-97ef-001707dcf970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n",
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core')\n",
    "sys.path.append('/flagellar/input/my-flg-library/')\n",
    "import flg_support as fls\n",
    "import importlib\n",
    "import numpy as np\n",
    "import flg_diagnostics\n",
    "import flg_numerics\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import copy\n",
    "import flg_preprocess\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "importlib.reload(fls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8e63f9-2dfe-4af8-8a4b-d290e5c7c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = fls.load_all_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f72ba8-254f-4566-96a4-5444fec4be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner = fls.dill_load(fls.result_dir + '/many_abbr_res - Copy/Baseline_0_d7f7501f_.81 _a.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eae514f-3620-46df-9b6b-455c0545ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 128\n",
    "# voxel_target = 20.\n",
    "# def add_motor(dat,lab, is_motor, is_train):\n",
    "#     this_mat = mat[ pad_size+lab['z']-size_to_extract//2:pad_size+lab['z']+size_to_extract//2+1, \n",
    "#                     pad_size+lab['y']-size_to_extract//2:pad_size+lab['y']+size_to_extract//2+1 , \n",
    "#                     pad_size+lab['x']-size_to_extract//2:pad_size+lab['x']+size_to_extract//2+1]\n",
    "    \n",
    "\n",
    "#     this_mat = cp.array(this_mat, dtype=cp.float32)\n",
    "#     this_mat = (this_mat-cp.nanmean(this_mat))/cp.nanstd(this_mat)\n",
    "\n",
    "#     this_mat[cp.isnan(this_mat)] = 0.\n",
    "\n",
    "#     this_mat=flg_numerics.fourier_resample_nd(this_mat, (size,size,size))\n",
    "\n",
    "#     # plt.figure()\n",
    "#     # plt.imshow(cp.asnumpy(cp.mean(this_mat[this_mat.shape[0]//2-5:this_mat.shape[0]//2+6,...],axis=0)), cmap='bone')\n",
    "#     # plt.colorbar()\n",
    "#     # plt.title(is_motor)\n",
    "    \n",
    "#     # plt.pause(0.0001)\n",
    "\n",
    "#     this_mat = cp.asnumpy(this_mat)\n",
    "\n",
    "#     global i_file\n",
    "#     if is_train:\n",
    "#         d = train_dir\n",
    "#     else:\n",
    "#         d = test_dir\n",
    "#     filename = str(i_file)+'.npy'\n",
    "#     np.save(d+filename, this_mat)\n",
    "#     i_file += 1\n",
    "\n",
    "#     if is_train:\n",
    "#         train_labels['filename'].append(filename)\n",
    "#         train_labels['is_motor'].append(is_motor)\n",
    "#     else:\n",
    "#         test_labels['filename'].append(filename)\n",
    "#         test_labels['is_motor'].append(is_motor)\n",
    "        \n",
    "    \n",
    "\n",
    "# train_dir = 'd:/flagellar/3d/train/'\n",
    "# test_dir = 'd:/flagellar/3d/test/'\n",
    "# fls.remove_and_make_dir(train_dir)\n",
    "# fls.remove_and_make_dir(test_dir)\n",
    "# #dirs = glob.glob('D:/flagellar/data/train/*')\n",
    "# r = np.random.default_rng(seed=0)\n",
    "# train_labels = dict()\n",
    "# train_labels['filename'] = []\n",
    "# train_labels['is_motor'] = []\n",
    "# test_labels = dict()\n",
    "# test_labels['filename'] = []\n",
    "# test_labels['is_motor'] = []\n",
    "# train_names = [d.name for d in runner.train_data]\n",
    "# test_names = [d.name for d in runner.test_data]\n",
    "# fls.claim_gpu('cupy')\n",
    "# i_file = 0\n",
    "# for dat in tqdm(data):\n",
    "#     resize_factor = dat.voxel_spacing/voxel_target\n",
    "#     size_to_extract = np.round(size/resize_factor).astype(int)\n",
    "    \n",
    "#     dat.load_to_memory()   \n",
    "#     mat = copy.deepcopy(dat.data.astype(np.float16))\n",
    "#     dat.unload()\n",
    "#     pad_size = size_to_extract//2+3\n",
    "    \n",
    "#     mat = np.pad(mat, size_to_extract//2+3, constant_values=np.nan)\n",
    "\n",
    "    \n",
    "\n",
    "#     if dat.name in train_names:\n",
    "#         is_train = True\n",
    "#     else:\n",
    "#         is_train = False\n",
    "#         assert dat.name in test_names\n",
    "#     for lab in dat.labels.iterrows():\n",
    "#         if lab[1]['suspect']==0.0:\n",
    "#             add_motor(dat,lab[1],True,is_train)\n",
    "\n",
    "#     for lab in dat.negative_labels.iterrows():\n",
    "#         if lab[1]['suspect']==0.0:\n",
    "#             add_motor(dat,lab[1],False,is_train)\n",
    "\n",
    "#     # for f in files[::len(files)//scale_fac][1:-1]:\n",
    "#     #     fname = dat.name+'__'+os.path.basename(f)\n",
    "#     #     if dat.name in train_names:\n",
    "#     #         shutil.copyfile(f,train_dir+'/'+fname)\n",
    "#     #         train_labels['filename'].append(fname)\n",
    "#     #         train_labels['voxel_spacing'].append(dat.voxel_spacing)\n",
    "#     #     else:\n",
    "#     #         assert dat.name in test_names\n",
    "#     #         shutil.copyfile(f,test_dir+'/'+fname)\n",
    "#     #         test_labels['filename'].append(fname)\n",
    "#     #         test_labels['voxel_spacing'].append(dat.voxel_spacing)\n",
    "# pd.DataFrame(train_labels).to_csv(train_dir + '/labels.csv', index=False)\n",
    "# pd.DataFrame(test_labels).to_csv(test_dir + '/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aaf19d-8179-413a-94e7-7d5a4a6f0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jeroe\\anaconda3\\envs\\jupyterlab-debugger2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Train Loss: 0.6509 | Test Loss: 55.4777 | Test Acc: 0.5980 | Test Error: 0.4020\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999979734420776, 0.9999946355819702, 1.0, 1.0, 1.0, 1.0, 0.7286659479141235, 0.9969670176506042, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7238283157348633, 0.6742013096809387, 0.8101024031639099, 0.9675608277320862, 1.0, 0.9951319694519043, 1.0, 1.0, 0.9109011292457581, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5379687547683716, 1.0, 1.0, 0.35641536116600037, 0.4328460097312927, 0.4014161229133606, 0.49757120013237, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9125345349311829, 0.9106975197792053, 0.9018351435661316, 0.7401432991027832, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6795100569725037, 1.0, 1.0, 1.0, 1.0, 0.9938777089118958, 0.45604127645492554, 0.8098257780075073, 0.44374746084213257, 1.0, 1.0]\n",
      "Epoch 2/200 - Train Loss: 0.6111 | Test Loss: 2.2376 | Test Acc: 0.5784 | Test Error: 0.4216\n",
      "[0.3342631757259369, 0.9262995719909668, 0.9592564105987549, 0.6850321888923645, 0.9999959468841553, 0.9999209642410278, 0.9999992847442627, 0.9998443126678467, 0.9999407529830933, 0.9174106121063232, 0.9458414316177368, 0.9752434492111206, 0.9994713664054871, 0.8430221080780029, 0.9383838176727295, 0.8706979751586914, 0.7916186451911926, 0.9967148303985596, 0.999342143535614, 0.880256175994873, 0.9838840365409851, 0.9975646734237671, 0.9999909400939941, 0.9633284211158752, 0.9994731545448303, 0.994059681892395, 1.0, 0.9999973773956299, 0.47356411814689636, 0.5533104538917542, 0.554494321346283, 0.2812422513961792, 0.8908231258392334, 0.5624575018882751, 0.9999957084655762, 0.996945321559906, 0.5981053709983826, 0.9998486042022705, 0.9999923706054688, 0.9999997615814209, 0.9976935982704163, 0.9954978227615356, 0.9973419308662415, 0.9999966621398926, 0.9999978542327881, 0.9211824536323547, 0.9999759197235107, 0.9999996423721313, 1.0, 0.8323646783828735, 0.9979185461997986, 0.9999959468841553, 0.9999676942825317, 0.9999126195907593, 1.0, 0.9989475607872009, 0.9573834538459778, 0.9999977350234985, 0.9997100234031677, 0.995196521282196, 0.9999996423721313, 0.7934920787811279, 0.9934129118919373, 0.9994275569915771, 0.6296730041503906, 0.6806994676589966, 0.8079438805580139, 0.6496167778968811, 0.9615049958229065, 0.9999924898147583, 0.9569712281227112, 0.9999773502349854, 0.9998598098754883, 0.9951174259185791, 0.9996381998062134, 0.99779212474823, 0.9983969330787659, 0.4354219138622284, 0.5258843898773193, 0.4673377275466919, 0.3752859830856323, 1.0, 0.9998860359191895, 0.9665971994400024, 0.9992262125015259, 1.0, 0.9998270869255066, 1.0, 0.9999865293502808, 0.9999972581863403, 0.9999982118606567, 0.7891547083854675, 0.6536380648612976, 0.9999997615814209, 0.997187077999115, 0.9999994039535522, 0.7405648231506348, 0.9732263684272766, 0.9637123346328735, 0.9349051713943481, 0.5447978973388672, 0.9983730316162109]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from glob import glob\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torchvision\n",
    "# from torchvision.models.video import r3d_18\n",
    "\n",
    "\n",
    "# class FlagellarDataset(Dataset):\n",
    "#     def __init__(self, data_dir, labels_csv, transform=None):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.labels = pd.read_csv(labels_csv)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.labels.iloc[idx]\n",
    "#         file_path = os.path.join(self.data_dir, row.filename)\n",
    "#         volume = np.load(file_path)  # shape: (128, 128, 128), float32\n",
    "#         label = int(row.is_motor)\n",
    "\n",
    "#         # add channel dim\n",
    "#         volume = np.expand_dims(volume, axis=0)  # (1, 128, 128, 128)\n",
    "#         volume = torch.from_numpy(volume)\n",
    "#         label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "#         if self.transform:\n",
    "#             volume = self.transform(volume)\n",
    "\n",
    "#         return volume, label\n",
    "\n",
    "\n",
    "# def set_bn_momentum(module: nn.Module):\n",
    "#     \"\"\"\n",
    "#     Recursively set momentum=0.01 for all BatchNorm3d layers in the model.\n",
    "#     \"\"\"\n",
    "#     for child in module.children():\n",
    "#         if isinstance(child, nn.BatchNorm3d):\n",
    "#             child.momentum = 0.01\n",
    "#         else:\n",
    "#             set_bn_momentum(child)\n",
    "\n",
    "\n",
    "# def build_resnet3d(num_classes=2):\n",
    "#     # Load a ResNet-18 3D model without pretrained weights\n",
    "#     model = r3d_18(pretrained=False)\n",
    "#     # Modify first conv layer to accept single channel input\n",
    "#     orig_conv = model.stem[0]\n",
    "#     model.stem[0] = nn.Conv3d(\n",
    "#         in_channels=1,\n",
    "#         out_channels=orig_conv.out_channels,\n",
    "#         kernel_size=orig_conv.kernel_size,\n",
    "#         stride=orig_conv.stride,\n",
    "#         padding=orig_conv.padding,\n",
    "#         bias=orig_conv.bias is not None\n",
    "#     )\n",
    "#     # Replace the final fully-connected layer\n",
    "#     in_features = model.fc.in_features\n",
    "#     model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "#     # Recursively update BatchNorm3d momentum\n",
    "#     set_bn_momentum(model)\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, targets in loader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "#     return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# def evaluate(model, loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     all_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             preds = outputs.argmax(dim=1)\n",
    "#             correct += (preds == targets).sum().item()\n",
    "#             all_preds.append(outputs)\n",
    "#     avg_loss = running_loss / len(loader.dataset)\n",
    "#     accuracy = correct / len(loader.dataset)\n",
    "#     error_rate = 1.0 - accuracy\n",
    "#     return avg_loss, accuracy, error_rate\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Paths\n",
    "#     train_dir = r\"D:\\flagellar\\3d\\train\"\n",
    "#     test_dir = r\"D:\\flagellar\\3d\\test\"\n",
    "#     train_csv = os.path.join(train_dir, \"labels.csv\")\n",
    "#     test_csv = os.path.join(test_dir, \"labels.csv\")\n",
    "\n",
    "#     # Hyperparameters\n",
    "#     epochs = 200\n",
    "#     batch_size = 4\n",
    "#     lr = 1e-3\n",
    "\n",
    "#     # Device\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Datasets and Loaders\n",
    "#     train_dataset = FlagellarDataset(train_dir, train_csv)\n",
    "#     test_dataset = FlagellarDataset(test_dir, test_csv)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "#     # Model, Loss, Optimizer\n",
    "#     model = build_resnet3d(num_classes=2).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#         test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "#         print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | \"\n",
    "#               f\"Test Acc: {test_acc:.4f} | Test Error: {test_err:.4f}\")\n",
    "#         print(predict(model,test_loader,device))\n",
    "\n",
    "#         model.to('cpu')\n",
    "#         fls.dill_save(fls.model_dir + '3d_model_n' + str(epoch) + '.pickle', model)\n",
    "#         model.to(device)\n",
    "        \n",
    "\n",
    "#     # Final evaluation\n",
    "#     test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "#     print(f\"\\nFinal Test Loss: {test_loss:.4f} | Final Test Acc: {test_acc:.4f} | \"\n",
    "#           f\"Final Test Error: {test_err:.4f}\")\n",
    "\n",
    "# def predict(model, loader, device):\n",
    "#     \"\"\"\n",
    "#     Runs the model on all data in `loader` and returns the probability of the positive class (is_motor)\n",
    "#     for each sample in the loader, in the same order.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     probabilities = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, _ in loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             outputs = model(inputs)                            # raw logits, shape (B, 2)\n",
    "#             probs = torch.softmax(outputs, dim=1)[:, 1]         # probability of class “1” (motor present)\n",
    "#             probabilities.extend(probs.cpu().tolist())\n",
    "#     return probabilities\n",
    "\n",
    "# # Claim GPU and run\n",
    "# fls.claim_gpu('pytorch')\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083722e2-714e-4332-943c-af59e89e51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "\n",
    "class FlagellarDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_csv, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels.iloc[idx]\n",
    "        file_path = os.path.join(self.data_dir, row.filename)\n",
    "        volume = np.load(file_path).astype(np.float32)  # (128,128,128)\n",
    "        label = int(row.is_motor)\n",
    "\n",
    "        volume = np.expand_dims(volume, axis=0)  # (1,128,128,128)\n",
    "        volume = torch.from_numpy(volume)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            volume = self.transform(volume)\n",
    "\n",
    "        return volume, label\n",
    "\n",
    "\n",
    "def set_bn_momentum(module: nn.Module):\n",
    "    \"\"\"\n",
    "    Recursively set momentum=0.01 for all BatchNorm3d layers.\n",
    "    \"\"\"\n",
    "    for child in module.children():\n",
    "        if isinstance(child, nn.BatchNorm3d):\n",
    "            child.momentum = 0.01\n",
    "        else:\n",
    "            set_bn_momentum(child)\n",
    "\n",
    "\n",
    "def build_resnet3d(num_classes=2):\n",
    "    # 3D ResNet-18 without pretrained weights\n",
    "    model = r3d_18(pretrained=False)\n",
    "    # Adapt first conv to single channel\n",
    "    orig = model.stem[0]\n",
    "    model.stem[0] = nn.Conv3d(\n",
    "        in_channels=1,\n",
    "        out_channels=orig.out_channels,\n",
    "        kernel_size=orig.kernel_size,\n",
    "        stride=orig.stride,\n",
    "        padding=orig.padding,\n",
    "        bias=(orig.bias is not None)\n",
    "    )\n",
    "    # Final FC for 2 classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    # Set BatchNorm momentum\n",
    "    set_bn_momentum(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device, clip_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Mixed precision forward\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        # Scaled backward\n",
    "        scaler.scale(loss).backward()\n",
    "        # Unscale and clip\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "        # Step optimizer\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            total_loss += criterion(outputs, targets).item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return avg_loss, accuracy, 1.0 - accuracy\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    \"\"\"\n",
    "    Infer positive-class probabilities via mixed precision.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    probs_list = []\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            logits = model(inputs)\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            probs_list.extend(probs.cpu().tolist())\n",
    "    return probs_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    train_dir = r\"D:\\flagellar\\3d\\train\"\n",
    "    test_dir = r\"D:\\flagellar\\3d\\test\"\n",
    "    train_csv = os.path.join(train_dir, \"labels.csv\")\n",
    "    test_csv = os.path.join(test_dir, \"labels.csv\")\n",
    "\n",
    "    # Hyperparams\n",
    "    epochs = 200\n",
    "    batch_size = 4\n",
    "    lr = 1e-3\n",
    "    clip_norm = 1.0\n",
    "\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data\n",
    "    train_ds = FlagellarDataset(train_dir, train_csv)\n",
    "    test_ds = FlagellarDataset(test_dir, test_csv)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Model, loss, optimizer, scaler\n",
    "    model = build_resnet3d(2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, clip_norm)\n",
    "        test_loss, test_acc, test_err = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | Test Error: {test_err:.4f}\")\n",
    "        print(predict(model,test_loader,device))\n",
    "\n",
    "        # Save model checkpoint\n",
    "        model_cpu = model.to('cpu')\n",
    "        fls.dill_save(fls.model_dir + '3d_model_e' + str(epoch) + '.pickle', model_cpu)\n",
    "        model_cpu.to(device)\n",
    "\n",
    "    # Final eval\n",
    "    tl, ta, te = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"\\nFinal Test Loss: {tl:.4f} | Final Test Acc: {ta:.4f} | Final Test Error: {te:.4f}\")\n",
    "\n",
    "# Claim GPU and run\n",
    "fls.claim_gpu('pytorch')\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
