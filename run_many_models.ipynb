{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a837d78-5dff-48d9-9753-37e382d9f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('d:/flagellar/code/core')\n",
    "sys.path.append('/flagellar/code/core/')\n",
    "sys.path.append('/kaggle/input/my-flagellar-library/')\n",
    "import flg_support as fls\n",
    "import flg_runner\n",
    "import importlib\n",
    "import flg_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "fast_mode = (fls.env=='local')\n",
    "clear_data = True\n",
    "dataset_str = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee156f6e-b2e1-423b-becd-381c3151b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare datasets\n",
    "if fls.env=='vast':\n",
    "    if not fast_mode:\n",
    "        fls.download_kaggle_dataset('jeroencottaar/byu-many-models' +dataset_str+ '/', fls.result_dir + '/many_full/', skip_download=clear_data)\n",
    "        fls.download_kaggle_dataset('jeroencottaar/byu-many-models-abbreviated' +dataset_str+ '/', fls.result_dir + '/many_abbr/', skip_download=clear_data)\n",
    "    else:\n",
    "        if clear_data:\n",
    "            fls.remove_and_make_dir(fls.result_dir + '/many_full/')\n",
    "            fls.remove_and_make_dir(fls.result_dir + '/many_abbr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81947e-e1cc-441f-b2a8-1559d632d8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting seed  0\n",
      "1926 5\n",
      "100 5\n",
      "{'seed': 0, 'use_best_epoch': True, 'extra_data': False, 'trust_neg': -1, 'model_name': 'yolov8s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpawnPoolWorker-1\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "Clearing pytorch\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 28 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 2 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: /flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: /flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at /flagellar/temp/training.yaml\n",
      "Using YAML file: /flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: /flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.127 available 😃 Update with 'pip install -U ultralytics'\n",
      "WARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=None, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/flagellar/temp/training.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=motor_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/flagellar/temp//yolo_weights/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/flagellar/temp/yolo_weights/motor_detector, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2265.3±666.0 MB/s, size: 77.1 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1695.1±1041.5 MB/s, size: 91.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/train... 144 images, 0 backgrounds, 0 corrupt: 100%|██████████| 144/144 [00:00<00:00, 2842.43it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/val... 9 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9/9 [00:00<00:00, 1695.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/val.cache\n",
      "Plotting labels to /flagellar/temp/yolo_weights/motor_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2      2.75G      5.144      104.7      2.401         16        640: 100%|██████████| 12/12 [00:01<00:00, 11.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.42it/s]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2      2.79G      4.591      46.61      2.018         23        640: 100%|██████████| 12/12 [00:00<00:00, 18.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 38.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          0          0          0          0\n",
      "\n",
      "2 epochs completed in 0.001 hours.\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /flagellar/temp/yolo_weights/motor_detector/weights/best.pt...\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          0          0          0          0\n",
      "Speed: 0.1ms preprocess, 10.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "ratio:  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cupy\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "        z    y    x  confidence\n",
      "0      90  686  692    0.703125\n",
      "1      89  697  705    0.648926\n",
      "2     198  718  698    0.642578\n",
      "3      66  665  687    0.630859\n",
      "4      41  694  716    0.625000\n",
      "...   ...  ...  ...         ...\n",
      "2544   62  769  756    0.140869\n",
      "2545   82  471  753    0.140869\n",
      "2546  253  767  733    0.140869\n",
      "2547  314  734  813    0.140869\n",
      "2548  779  695  550    0.140869\n",
      "\n",
      "[2549 rows x 4 columns]\n",
      "\n",
      "tomo_512f98 total infer time: 11.504594326019287\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram ycw2013-01-03-27 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    273  800  828    0.509766\n",
      "1    275  793  785    0.476562\n",
      "2    273  829  815    0.445557\n",
      "3    274  764  685    0.403564\n",
      "4    272  796  796    0.394287\n",
      "..   ...  ...  ...         ...\n",
      "195  278  859  762    0.102844\n",
      "196  280  362  829    0.102844\n",
      "197  267  625  841    0.102661\n",
      "198  280  153  897    0.102661\n",
      "199  281  863  801    0.102112\n",
      "\n",
      "[200 rows x 4 columns]\n",
      "\n",
      "ycw2013-01-03-27 total infer time: 1.295520544052124\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_79756f (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "        z    y    x  confidence\n",
      "0     209  105  227    0.078918\n",
      "1     198  106  216    0.069153\n",
      "2     206  106  279    0.060211\n",
      "3     202  107  311    0.057709\n",
      "4     210  107  191    0.055206\n",
      "...   ...  ...  ...         ...\n",
      "3167  252  565  867    0.015839\n",
      "3168  264  663  572    0.015839\n",
      "3169  264  865  377    0.015839\n",
      "3170  283  281  415    0.015839\n",
      "3171  294  781  300    0.015839\n",
      "\n",
      "[3172 rows x 4 columns]\n",
      "\n",
      "tomo_79756f total infer time: 6.95374608039856\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram mba2012-01-13-11 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   195  314  710    0.163940\n",
      "1   208  400  538    0.148315\n",
      "2   207  321  541    0.135864\n",
      "3   200  295  548    0.101074\n",
      "4   193  272  717    0.077637\n",
      "5   192  244  719    0.058655\n",
      "6   197  298  383    0.044525\n",
      "7   207  456  530    0.039490\n",
      "8   203  282  714    0.038177\n",
      "9   192  282  559    0.037323\n",
      "10  193  324  671    0.036896\n",
      "11  206  445  535    0.036499\n",
      "12  205  426  535    0.036224\n",
      "13  199  296  460    0.034882\n",
      "\n",
      "mba2012-01-13-11 total infer time: 1.3969693183898926\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram aba2014-04-10-9 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    446  717  162    0.132080\n",
      "1    448  734  142    0.128784\n",
      "2    443  709  183    0.109314\n",
      "3    451  585  855    0.093201\n",
      "4    445  709  153    0.092529\n",
      "..   ...  ...  ...         ...\n",
      "192  437  914  362    0.026703\n",
      "193  435  637  333    0.026657\n",
      "194  440  757  781    0.026550\n",
      "195  445  601  839    0.026550\n",
      "196  436  643   98    0.026459\n",
      "\n",
      "[197 rows x 4 columns]\n",
      "\n",
      "aba2014-04-10-9 total infer time: 1.0948381423950195\n",
      "0.0,\n",
      "Starting seed  1\n",
      "1926 5\n",
      "100 5\n",
      "{'seed': 1, 'use_best_epoch': True, 'extra_data': True, 'trust_neg': -1, 'model_name': 'yolov8s'}\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpawnPoolWorker-2\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Clearing pytorch\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 100 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 5 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: /flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: /flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at /flagellar/temp/training.yaml\n",
      "Using YAML file: /flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: /flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.127 available 😃 Update with 'pip install -U ultralytics'\n",
      "WARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=None, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/flagellar/temp/training.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=motor_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/flagellar/temp//yolo_weights/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/flagellar/temp/yolo_weights/motor_detector, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=1, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2158.9±1253.8 MB/s, size: 91.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/train... 775 images, 0 backgrounds, 0 corrupt: 100%|██████████| 775/775 [00:00<00:00, 2757.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1485.1±904.4 MB/s, size: 117.1 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/val... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<00:00, 2176.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /flagellar/temp/yolo_weights/motor_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2       2.8G      4.038      17.19      1.694         19        640: 100%|██████████| 65/65 [00:03<00:00, 16.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         34         34      0.216      0.265      0.131     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2      3.13G      3.065      2.777      1.203         10        640: 100%|██████████| 65/65 [00:03<00:00, 21.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         34         34      0.431      0.412      0.409      0.146\n",
      "\n",
      "2 epochs completed in 0.002 hours.\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /flagellar/temp/yolo_weights/motor_detector/weights/best.pt...\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         34         34       0.39      0.412      0.384      0.146\n",
      "Speed: 0.1ms preprocess, 6.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "ratio:  0.8\n",
      "Clearing cupy\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   636  675  352    0.403564\n",
      "1   635  576  324    0.385010\n",
      "2   493  893  754    0.381104\n",
      "3   390  270  180    0.374756\n",
      "4   709   63  108    0.364746\n",
      "..  ...  ...  ...         ...\n",
      "90  691  164  327    0.082092\n",
      "91  573  161  464    0.081787\n",
      "92  677  173  349    0.081543\n",
      "93  494  110  106    0.080933\n",
      "94  519  404  618    0.080933\n",
      "\n",
      "[95 rows x 4 columns]\n",
      "\n",
      "tomo_512f98 total infer time: 8.485135316848755\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram ycw2013-01-03-27 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  269  192  403    0.517578\n",
      "1  275  140  710    0.251709\n",
      "2  268  122   98    0.166138\n",
      "3  267  248  563    0.124207\n",
      "\n",
      "ycw2013-01-03-27 total infer time: 1.3752658367156982\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_79756f (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   211  794  233    0.649414\n",
      "1   133  341  737    0.309814\n",
      "2    64  549  562    0.303223\n",
      "3    36  762  541    0.285400\n",
      "4   183  773  642    0.271973\n",
      "5   268  177  613    0.231567\n",
      "6     7  270  213    0.182373\n",
      "7   217  823  293    0.177856\n",
      "8    67  571  538    0.163940\n",
      "9   127  783  180    0.160278\n",
      "10  267  372  258    0.160278\n",
      "11   13  527  724    0.156128\n",
      "12   48  597  487    0.152588\n",
      "13  147   83  891    0.144165\n",
      "14  217  176  613    0.139893\n",
      "15  157  774  644    0.136597\n",
      "16   91  342  732    0.136108\n",
      "17  166  195  683    0.135254\n",
      "18   63  558  552    0.133911\n",
      "\n",
      "tomo_79756f total infer time: 4.906919479370117\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram mba2012-01-13-11 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  202  435  563    0.212036\n",
      "1  192  454  549    0.155640\n",
      "2  192  766  360    0.094666\n",
      "3  192  454  560    0.083618\n",
      "4  204  594  506    0.065125\n",
      "5  192  779  358    0.053802\n",
      "\n",
      "mba2012-01-13-11 total infer time: 0.932070255279541\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram aba2014-04-10-9 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  437  347  425    0.521484\n",
      "1  442  850  865    0.279053\n",
      "2  446  916  838    0.149048\n",
      "3  444  446  595    0.147583\n",
      "\n",
      "aba2014-04-10-9 total infer time: 1.2275373935699463\n",
      "0.75\n",
      "Starting seed  2\n",
      "1926 5\n",
      "100 5\n",
      "{'seed': 2, 'use_best_epoch': False, 'extra_data': False, 'trust_neg': 0, 'model_name': 'yolov8l'}\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpawnPoolWorker-3\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "Clearing pytorch\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 28 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 2 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: /flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: /flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at /flagellar/temp/training.yaml\n",
      "Using YAML file: /flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: /flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83.7M/83.7M [00:00<00:00, 193MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.127 available 😃 Update with 'pip install -U ultralytics'\n",
      "WARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=None, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/flagellar/temp/training.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=motor_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/flagellar/temp//yolo_weights/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/flagellar/temp/yolo_weights/motor_detector, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=2, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2168.3±528.6 MB/s, size: 83.5 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/train... 163 images, 19 backgrounds, 0 corrupt: 100%|██████████| 163/163 [00:00<00:00, 2862.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1538.8±947.1 MB/s, size: 91.9 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/val... 10 images, 1 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1639.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /flagellar/temp/yolo_weights/motor_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046875), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2      6.87G      5.703      70.44      2.488         10        640: 100%|██████████| 14/14 [00:02<00:00,  6.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10          9          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2       6.9G      4.092      19.02      1.671          5        640: 100%|██████████| 14/14 [00:01<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10          9      0.011      0.667    0.00936    0.00116\n",
      "\n",
      "2 epochs completed in 0.001 hours.\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating /flagellar/temp/yolo_weights/motor_detector/weights/best.pt...\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10          9    0.00804      0.667     0.0068   0.000845\n",
      "Speed: 0.1ms preprocess, 11.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "ratio:  0.8\n",
      "Clearing cupy\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    716  127  724    0.052521\n",
      "1    435  863  420    0.043365\n",
      "2    480  867  484    0.042816\n",
      "3    475  866  425    0.042725\n",
      "4    565  126  775    0.042572\n",
      "..   ...  ...  ...         ...\n",
      "281   47   91  422    0.010567\n",
      "282  494   72  771    0.010567\n",
      "283   21   83  810    0.010529\n",
      "284  615  877  407    0.010529\n",
      "285  721  869  494    0.010529\n",
      "\n",
      "[286 rows x 4 columns]\n",
      "\n",
      "tomo_512f98 total infer time: 9.967836856842041\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram ycw2013-01-03-27 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   281  757   25    0.035675\n",
      "1   268   76  854    0.021942\n",
      "2   266   61  849    0.021118\n",
      "3   266   70  880    0.016724\n",
      "4   266  126  854    0.016663\n",
      "5   267  105  605    0.014954\n",
      "6   269  111  478    0.014839\n",
      "7   267  104  543    0.013954\n",
      "8   274  109  509    0.013069\n",
      "9   267  112  126    0.012100\n",
      "10  277   73  847    0.011330\n",
      "11  275  104  189    0.011292\n",
      "12  277   63  718    0.010948\n",
      "13  274  112  426    0.010902\n",
      "14  270  111  169    0.010208\n",
      "15  276  115  141    0.009933\n",
      "16  269  114  378    0.009636\n",
      "17  276  112  566    0.009338\n",
      "18  269   71  172    0.009163\n",
      "19  268  348  262    0.008949\n",
      "20  272   68  510    0.008881\n",
      "21  271   71  610    0.008812\n",
      "22  271  112  712    0.008812\n",
      "23  270  131  867    0.008675\n",
      "24  267   72  128    0.008614\n",
      "25  277   69  523    0.008446\n",
      "26  274  111  329    0.008415\n",
      "27  281  112  526    0.008286\n",
      "28  273  128  882    0.008186\n",
      "29  268  120  578    0.008156\n",
      "30  267  348  221    0.007904\n",
      "31  265  107  192    0.007874\n",
      "32  272  121  545    0.007843\n",
      "33  276  105  339    0.007637\n",
      "34  268  111  406    0.007488\n",
      "35  269  120  450    0.007462\n",
      "36  269  751  247    0.007462\n",
      "37  279  119  837    0.007462\n",
      "38  271   73  701    0.007431\n",
      "39  269  404  331    0.007374\n",
      "40  275   67  583    0.007347\n",
      "41  281  105  294    0.007290\n",
      "42  280  320  200    0.007233\n",
      "\n",
      "ycw2013-01-03-27 total infer time: 1.2954764366149902\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_79756f (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0    78   76  285    0.068665\n",
      "1    84   70  269    0.058655\n",
      "2   110   73  317    0.055511\n",
      "3    88   77  287    0.052124\n",
      "4   161   65  415    0.051941\n",
      "..  ...  ...  ...         ...\n",
      "77  172  304  293    0.014336\n",
      "78  183  126  503    0.014282\n",
      "79   83  102  280    0.014229\n",
      "80   92  105  398    0.013847\n",
      "81  166  120  542    0.013794\n",
      "\n",
      "[82 rows x 4 columns]\n",
      "\n",
      "tomo_79756f total infer time: 5.864284992218018\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram mba2012-01-13-11 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   200  112  594    0.045105\n",
      "1   201  113  621    0.043610\n",
      "2   201  214  513    0.041931\n",
      "3   202  217  543    0.040680\n",
      "4   206  213  639    0.037048\n",
      "5   199  215  531    0.036560\n",
      "6   205  217  656    0.036560\n",
      "7   208  116  533    0.036072\n",
      "8   207  218  627    0.035736\n",
      "9   203  221  593    0.035217\n",
      "10  206  115  577    0.035004\n",
      "11  207  116  555    0.034760\n",
      "12  200  185  614    0.034698\n",
      "13  198  187  643    0.034485\n",
      "14  205  114  646    0.034027\n",
      "15  195  125  738    0.029541\n",
      "16  197  154  752    0.029541\n",
      "17  197  115  656    0.026062\n",
      "18  192  155  727    0.019196\n",
      "19  206  242  631    0.018585\n",
      "20  192  128  324    0.018402\n",
      "21  205  139  644    0.018127\n",
      "22  192  128  705    0.017105\n",
      "23  205  241  658    0.017105\n",
      "24  194  131  687    0.016785\n",
      "25  195  130  662    0.016525\n",
      "26  201  134  568    0.016159\n",
      "27  202  134  578    0.016159\n",
      "28  196  140  672    0.016022\n",
      "29  197  144  640    0.015717\n",
      "30  192  212  280    0.015671\n",
      "31  198  144  592    0.015602\n",
      "32  195  226  714    0.015076\n",
      "33  194  180  522    0.015015\n",
      "34  207  154  636    0.015015\n",
      "35  198  235  637    0.014671\n",
      "36  193  227  762    0.014008\n",
      "37  192  234  750    0.013954\n",
      "38  194  221  736    0.013954\n",
      "39  206  160  619    0.013847\n",
      "40  194  200  520    0.013428\n",
      "41  206  276  772    0.009300\n",
      "42  197  140  304    0.009270\n",
      "43  200  238  771    0.009193\n",
      "44  201  255  762    0.009163\n",
      "45  194  201  502    0.009125\n",
      "\n",
      "mba2012-01-13-11 total infer time: 1.0593369007110596\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram aba2014-04-10-9 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   442   74  524    0.044189\n",
      "1   442  148  599    0.040466\n",
      "2   440  125  580    0.030563\n",
      "3   438   78  736    0.025558\n",
      "4   438  144  765    0.019943\n",
      "5   443  130  564    0.016220\n",
      "6   438   93  704    0.014229\n",
      "7   436  135  780    0.013123\n",
      "8   444  129  629    0.013123\n",
      "9   435  132  760    0.011375\n",
      "10  442   87  718    0.011032\n",
      "11  439  134  544    0.010735\n",
      "12  435  101  115    0.010696\n",
      "13  438   96  151    0.010612\n",
      "14  442  123  695    0.010529\n",
      "15  443   83  701    0.010246\n",
      "16  437  148  752    0.009483\n",
      "17  435   74  555    0.009300\n",
      "\n",
      "aba2014-04-10-9 total infer time: 1.0133013725280762\n",
      "0.0,\n",
      "Starting seed  3\n",
      "1926 5\n",
      "100 5\n",
      "{'seed': 3, 'use_best_epoch': False, 'extra_data': False, 'trust_neg': -1, 'model_name': 'yolov8l'}\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpawnPoolWorker-4\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]\n",
      "Clearing pytorch\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 28 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 2 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: /flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: /flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at /flagellar/temp/training.yaml\n",
      "Using YAML file: /flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: /flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.127 available 😃 Update with 'pip install -U ultralytics'\n",
      "WARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=None, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/flagellar/temp/training.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=motor_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/flagellar/temp//yolo_weights/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/flagellar/temp/yolo_weights/motor_detector, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=3, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2392.8±697.6 MB/s, size: 85.6 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1623.6±986.1 MB/s, size: 90.9 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/train... 144 images, 0 backgrounds, 0 corrupt: 100%|██████████| 144/144 [00:00<00:00, 3277.88it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/val... 9 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9/9 [00:00<00:00, 1494.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /flagellar/temp/yolo_weights/motor_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046875), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2       6.9G      5.406      47.55       2.42         16        640: 100%|██████████| 12/12 [00:01<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2      6.94G      3.914      8.881      1.579         23        640: 100%|██████████| 12/12 [00:01<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          0          0          0          0\n",
      "\n",
      "2 epochs completed in 0.001 hours.\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating /flagellar/temp/yolo_weights/motor_detector/weights/best.pt...\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.014      0.667     0.0169     0.0033\n",
      "Speed: 0.1ms preprocess, 13.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "ratio:  0.8\n",
      "Clearing cupy\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   571   16  108    0.917480\n",
      "1   734  624   97    0.407227\n",
      "2   725  639   94    0.395020\n",
      "3   794   16  107    0.336426\n",
      "4   299  719  101    0.264648\n",
      "5   761   16  109    0.254883\n",
      "6   745   16  107    0.226807\n",
      "7   693  629   94    0.213379\n",
      "8   638   16  109    0.212769\n",
      "9   682  683   97    0.207886\n",
      "10  326  683   96    0.206543\n",
      "11  325  702   99    0.201172\n",
      "12  763  637  115    0.191284\n",
      "\n",
      "tomo_512f98 total infer time: 9.775667428970337\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram ycw2013-01-03-27 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "      z    y    x  confidence\n",
      "0   281  804  111    0.096558\n",
      "1   281  738   82    0.089294\n",
      "2   266  751   89    0.081970\n",
      "3   272  776   95    0.081543\n",
      "4   271  787   78    0.078613\n",
      "5   270  764   84    0.063354\n",
      "6   278  718   85    0.059662\n",
      "7   265  771   74    0.057190\n",
      "8   279  752   85    0.055206\n",
      "9   268  790   88    0.053589\n",
      "10  275  815  104    0.046204\n",
      "11  267  301   62    0.045197\n",
      "12  266  714   64    0.043701\n",
      "13  280  792  149    0.039490\n",
      "14  275  278   84    0.039185\n",
      "15  268  670  773    0.038696\n",
      "16  266  378   66    0.035828\n",
      "17  265  426   68    0.032837\n",
      "18  270  324   84    0.032349\n",
      "19  274  426   96    0.032043\n",
      "20  265  791  116    0.031982\n",
      "21  275  365   89    0.031433\n",
      "22  271  334   78    0.029541\n",
      "23  268  590  774    0.028702\n",
      "24  278  698   63    0.028061\n",
      "25  273  399   85    0.026505\n",
      "26  281  464   66    0.026413\n",
      "27  270  729  778    0.026199\n",
      "28  281  725  760    0.025620\n",
      "29  265  705   72    0.025177\n",
      "30  272  731  767    0.024994\n",
      "31  275  362   99    0.024612\n",
      "32  275  523   59    0.024048\n",
      "33  265  602   61    0.023697\n",
      "34  274  321   93    0.023697\n",
      "35  272  354   86    0.022934\n",
      "36  266  289   69    0.022797\n",
      "37  268  471  100    0.022369\n",
      "38  273  511   78    0.022079\n",
      "39  278  370  113    0.021698\n",
      "40  267  397   73    0.021652\n",
      "41  266  538   62    0.021530\n",
      "42  273  705  755    0.021210\n",
      "43  270  628   56    0.020798\n",
      "44  269  417   85    0.020218\n",
      "45  265  531   70    0.020172\n",
      "46  266  174  751    0.019608\n",
      "47  280  845  160    0.019501\n",
      "\n",
      "ycw2013-01-03-27 total infer time: 1.2092416286468506\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram tomo_79756f (1/1)\n",
      "Processing 300 out of 300 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "       z    y    x  confidence\n",
      "0    153  475  301    0.662598\n",
      "1    244   14   92    0.660156\n",
      "2     98  521  611    0.628906\n",
      "3    158  536  640    0.602051\n",
      "4     91  538  558    0.556641\n",
      "..   ...  ...  ...         ...\n",
      "99   189  385  649    0.138916\n",
      "100  204  474  353    0.137939\n",
      "101  216  461  329    0.137939\n",
      "102  157  463  675    0.135742\n",
      "103  153  496  358    0.133423\n",
      "\n",
      "[104 rows x 4 columns]\n",
      "\n",
      "tomo_79756f total infer time: 5.548919200897217\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram mba2012-01-13-11 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "     z   y    x  confidence\n",
      "0  194  28  189    0.166992\n",
      "\n",
      "mba2012-01-13-11 total infer time: 1.0582911968231201\n",
      "Clearing pytorch\n",
      "Clearing cupy\n",
      "Processing tomogram aba2014-04-10-9 (1/1)\n",
      "Processing 17 out of 17 slices (CONCENTRATION=1)\n",
      "FINAL\n",
      "     z    y    x  confidence\n",
      "0  442  724   90    0.233032\n",
      "1  441  737   94    0.183350\n",
      "2  444  662   97    0.143921\n",
      "3  443  713   92    0.133911\n",
      "4  451  696   79    0.133667\n",
      "5  451  767   79    0.091248\n",
      "6  445  753  122    0.070435\n",
      "7  442  732  143    0.058350\n",
      "8  447  556  753    0.058014\n",
      "9  436  678   95    0.049225\n",
      "\n",
      "aba2014-04-10-9 total infer time: 0.9669241905212402\n",
      "0.0,\n",
      "Starting seed  4\n",
      "1926 5\n",
      "100 5\n",
      "{'seed': 4, 'use_best_epoch': True, 'extra_data': True, 'trust_neg': 1, 'model_name': 'yolov8l'}\n",
      "Clearing pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.11/site-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpawnPoolWorker-5\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CompletedProcess(args=['pip', 'uninstall', '-y', 'albumentations'], returncode=0)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Clearing pytorch\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\n",
      "Preprocessing Complete:\n",
      "- Training data: 100 tomograms, 0 motors, 0 slices\n",
      "- Validation data: 5 tomograms, 0 motors, 0 slices\n",
      "- Dataset directory: /flagellar/temp//yolo_dataset/\n",
      "- YAML configuration: /flagellar/temp//yolo_dataset/dataset.yaml\n",
      "\n",
      "Ready for YOLO training!\n",
      "Starting YOLO training process...\n",
      "Created new YAML at /flagellar/temp/training.yaml\n",
      "Using YAML file: /flagellar/temp/training.yaml\n",
      "YAML contents:\n",
      "names:\n",
      "  0: motor\n",
      "path: /flagellar/temp//yolo_dataset/\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "\n",
      "Starting YOLO training...\n",
      "New https://pypi.org/project/ultralytics/8.3.127 available 😃 Update with 'pip install -U ultralytics'\n",
      "WARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=None, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/flagellar/temp/training.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=motor_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/flagellar/temp//yolo_weights/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/flagellar/temp/yolo_weights/motor_detector, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=4, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1932.3±1481.3 MB/s, size: 68.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/train... 832 images, 57 backgrounds, 0 corrupt: 100%|██████████| 832/832 [00:00<00:00, 2533.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1503.4±1243.2 MB/s, size: 116.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /flagellar/temp/yolo_dataset/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /flagellar/temp/yolo_dataset/labels/val... 37 images, 3 backgrounds, 0 corrupt: 100%|██████████| 37/37 [00:00<00:00, 2677.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /flagellar/temp/yolo_weights/motor_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046875), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2      6.91G      3.885      11.09       1.58          6        640: 100%|██████████| 70/70 [00:09<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         37         34    0.00526      0.324    0.00307    0.00119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2      8.07G      3.018      2.758       1.19         10        640: 100%|██████████| 70/70 [00:07<00:00,  8.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         37         34      0.323      0.547      0.467      0.191\n",
      "\n",
      "2 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from /flagellar/temp/yolo_weights/motor_detector/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating /flagellar/temp/yolo_weights/motor_detector/weights/best.pt...\n",
      "Ultralytics 8.3.126 🚀 Python-3.11.10 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         37         34      0.859      0.235      0.393      0.172\n",
      "Speed: 0.1ms preprocess, 7.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/flagellar/temp/yolo_weights/motor_detector\u001b[0m\n",
      "ratio:  0.8\n",
      "Clearing cupy\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "Processing tomogram tomo_512f98 (1/1)\n",
      "Processing 800 out of 800 slices (CONCENTRATION=1)\n"
     ]
    }
   ],
   "source": [
    "#fls.profiling=True\n",
    "import git \n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_commit_id = repo.head.object.hexsha\n",
    "for i in itertools.count(start=0):\n",
    "    print('Starting seed ', i)\n",
    "    r = flg_runner.baseline_runner(fast_mode=fast_mode)\n",
    "    # if single_settings:\n",
    "    #     r.use_missing_value = True\n",
    "    #     r.modifier_dict['n_ensemble'].missing_value = 1\n",
    "    #     r.modifier_dict['scale_percentile_value'].missing_value = 3.\n",
    "    #     r.modifier_dict['scale_std_clip_value'].missing_value = 2.\n",
    "    #     r.modifier_dict['n_epochs'].missing_value = 50\n",
    "    #     r.modifier_dict['use_best_epoch'].missing_value = False\n",
    "    #     r.modifier_dict['model_name'].missing_value = 'yolov9s'\n",
    "    #     r.modifier_dict['fix_norm_bug'].missing_value = True\n",
    "    #     r.modifier_dict['alternative_slice_selection'].missing_value = True\n",
    "    #     r.modifier_dict['negative_slice_ratio'].missing_value = 0.1\n",
    "    #     r.modifier_dict['ratio_of_motors_allowed'].missing_value = 0.5\n",
    "    #r.use_missing_value = True\n",
    "    # r.label = 'Test ensemble'\n",
    "    # r.modifier_dict = dict()\n",
    "    # r.modifier_dict['n_ensemble'] = flg_runner.pm(1, lambda r:(r.integers(4,5)).item(), flg_runner.yolo)    \n",
    "    # r.base_model = flg_model.ThreeStepModelLabelBased()\n",
    "    # r.base_model.train_data_selector.datasets = ['tom']\n",
    "    # r.base_model.run_in_parallel = False\n",
    "    # if fast_mode: r.base_model.step1Labels.n_epochs = 1\n",
    "    r.git_commit_id = git_commit_id\n",
    "    r.env = fls.env\n",
    "    r.seed = i\n",
    "    #r.base_model.train_data_selector.datasets = 'tom'\n",
    "    #r.base_model.run_in_parallel = False\n",
    "    if r.use_missing_value:\n",
    "        base_filename = r.label + '_' + str(r.seed) + 'M_' + git_commit_id[:8]   \n",
    "    else:\n",
    "        base_filename = r.label + '_' + str(r.seed) + '_' + git_commit_id[:8]   \n",
    "        if len(glob.glob(fls.result_dir + '/many_full/' + r.label + '_' + str(r.seed) + '*'))>=1:\n",
    "             print('Skipping')\n",
    "             continue\n",
    "    r.run()\n",
    "\n",
    "    score_str = str(r.cv_score[2])[2:5]\n",
    "    print(str(r.cv_score)[1:5])\n",
    "    output_file_full = fls.result_dir + '/many_full/' + base_filename + '_' + score_str +' _f.pickle'\n",
    "    output_file_abbr = fls.result_dir + '/many_abbr/' + base_filename + '_' + score_str +' _a.pickle'\n",
    "    \n",
    "    fls.dill_save(output_file_full, r)\n",
    "    r.trained_model = 0\n",
    "    fls.dill_save(output_file_abbr, r)\n",
    "    if not fast_mode and fls.env=='vast':\n",
    "       fls.upload_kaggle_dataset(fls.result_dir + '/many_full/')\n",
    "       fls.upload_kaggle_dataset(fls.result_dir + '/many_abbr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b13f8-4f88-4d49-8267-8b4c25b32559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "isSourceIdPinned": false,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 6925042,
     "sourceId": 11204341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6949538,
     "sourceId": 11204343,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211097053,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 229283084,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
